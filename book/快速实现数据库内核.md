# 前言

为了让更多的人快速入门数据内核研发，以实施tpch基准测试为入口，探索快速实现单机事务数据库内核的方法。

围绕这一目的，编写了较完整的数据内核系统，并完成tpch基准测试得出正确结果。
本文结合代码着重介绍数据库内核具体实现方案。而对数据库一般基本原理按需介绍。
整体含两部分内容：计算引擎，存储引擎。

计算引擎围绕生成plan和执行plan的主题，介绍了语义分析、优化器、执行器等具体实现方法。

存储引擎围绕读写数据的主题，介绍了内存数据组织、事务MVCC、索引、checkpoint等具体实施方案。

与其他数据库内核教学方案相比，有显著的优势：
- 单一任务。围绕tpch任务，实现内核方案。
- 目标具体。仅支持tpch 22条query 需要的数据类型、函数、算子等
- 选择关键算法的依据：清晰、直观、透明。不为追求极致性能，牺牲算法的易读性。
- 准工业化。参考duckdb的工业级方案，简化实现。
- 体系完整。涵盖计算引擎、存储引擎的经典内容。
- 实战性强。基于本文和代码，实现属于自己的数据库。
- 对于初级学习者。在数据库内核的完整性和需要的知识储备之间取得平衡。
- 对于进阶学习者。以此为基础进一步研读duckdb的生产级源码设计，甚至二次开发。
- 配套代码。 https://github.com/daviszhen/plan
- 本文链接：[快速实现数据库内核](https://github.com/daviszhen/plan/blob/main/book/%E5%BF%AB%E9%80%9F%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E5%BA%93%E5%86%85%E6%A0%B8.md)

# 目录

第一部分 计算引擎
- 第一章 bind
- 第二章 生成plan
- 第三章 优化plan
- 第四章 vector
- 第五章 执行plan

第二部分 存储引擎
- 第六章 表的内存结构
- 第七章 事务
- 第八章 插入数据
- 第九章 update数据
- 第十章 delete数据
- 第十一章 读数据与MVCC
- 第十二章 catalog
- 第十三章 索引
- 第十四章 stats

# 第一部分 计算引擎
# 第一章 bind
## 简介
整体介绍select的bind过程。bind实质是对语法树做语义分析的过程。检测语义上是否有效合法。
聚焦在tpch 22个query的语义分析过程。尽管在框架上做到了通用，但是目前还不能支持任意类型的query。

bind依次分析每个语法单元。过程有出错，整个分析提前结束。

bind涉及的组件：
- Builder。语义分析的driver。每个select对应一个Builder。驱动整个分析过程。也记录了部分分析结果。
- Binding。表示关系（表、子查询）的定义。关系的属性、名称。
- BindContext。对应一个作用域，记录这个作用域中有多少关系。BindContext之间有层次结构。
- Expr。结果表达式。除了关系外都转成表达式。

bind的结果最终存入Builder和BindContext。结果包含:Binding，各种结果表达式Expr
## bind过程
按语法单元逐个介绍分析过程。

重要的部分：
- 解析表定义。获取表的属性定义。
- 解析表达式。分析表达式是否合法。相当多语法单元的分析都可归结为分析表达式。

整体分析过程：
- 预处理Cte。
- 分析from。解析表定义、join类型、join条件等。
- 展开`*`表达式
- 预处理select list
- 分析where
- 分析group by
- 分析having
- 分析select list
- 分析order by
- 分析limit

分析where，group by，having，select list，order by都属于表达式分析的范围。区别在于它们能访问到的语义是不一样的。会优先讲表达式解析的整体过程，再介绍不同语法单元的差异点。


```go
func(Builder)buildSelect(select,ctx,depth)error{
	//cte
	buildWith(select.WithClause,ctx,depth);

	//from 
	b.fromExpr, err = b.buildTables(select.FromClause, ctx, depth)

	//展开 * 表达式
	for _, expr := range targetList {  
	    ret, err := b.expandStar(expr.GetResTarget())
    }

	//预处理select list
	for i, expr := range newSelectExprs {
		...
	}

	//分析where
	b.whereExpr, err = b.bindExpr(ctx,  IWC_WHERE,  select.WhereClause,  depth)

	//分析groupby
	for _, expr := range select.GroupClause {  
	    retExpr, err = b.bindExpr(ctx, IWC_GROUP, expr, depth)  
	}

	//分析having
	retExpr, err = b.bindExpr(ctx, IWC_HAVING, select.HavingClause, depth)

	//分析select list
	for i, expr := range newSelectExprs {  
	    retExpr, err = b.bindExpr(ctx, IWC_SELECT, expr.GetVal(), depth)
    }

	//分析order by
	for _, expr := range select.SortClause {  
	    retExpr, err = b.bindExpr(ctx, IWC_ORDER, expr, depth)
    }

	//分析limit
	b.limitCount, err = b.bindExpr(ctx, IWC_LIMIT, select.LimitCount, depth)

}
```

## 预处理cte
将cte的定义记录到BindContext中。在解析表时，如果判断表是个cte，再解析cte。

### 解析表定义
from子句的语法成分：
- 单个表
- 子查询
- 表join
- 上面的语法单元混用。情况比较复杂

from子句bind后的结果是一个表达式。

整体是个递归过程：分治向下到单个表。
- 单个表，直接解析。
- 多个表。拆分成前面N-1个，递归处理。最后1个，直接解析。最后merge两部分内容。
```go
func(Builder)buildTables(
	tables []*pg_query.Node, 
	ctx *BindContext, 
	depth int){
	if tables 空 {
		报错;
	}else if tables 单个表{
		buildTable(tables[0], ctx, depth);
	}else{
		nodeCnt := len(tables)  
		
		leftCtx := NewBindContext(ctx)  
		//left  
		left, err := b.buildTables(tables[:nodeCnt-1], leftCtx, depth)

		rightCtx := NewBindContext(ctx)  
		//right  
		right, err := b.buildTable(tables[nodeCnt-1], rightCtx, depth)
		
		//合并BindContext。生成叉乘表达式
		b.mergeTwoTable(  
		    leftCtx,  
		    rightCtx,  
		    left,  
		    right,  
		    ET_JoinTypeCross,  
		    ctx,  
		    depth)
	}
}
```

解析单个表。在语法上的单个节点，实质上也可能是多个表：
- 单个表。真实的单个表。或者cte
- 子查询
- 两表join

解析过程也是递归的。
- 单个表。
	- 如果表是cte，将cte改写为子查询递归解析。
	- 将表定义从catalog中拿出，生成Binding记录在BindContext中表示对表一次引用。
	- 如果没有报错。
- 两表join
	- 解析左表，右表。
	- 有on子句，也要解析。
	- 再merge 两表的解析结果。
- 子查询
	- 创建新的Builder和BindContext。递归构建子查询。
	- 构建结果也会形成Binding，记录在BindContext。
	
```go
func(Builder)buildTable(
	table *pg_query.Node, 
	ctx *BindContext, 
	depth int,
){
	swith table{
	case 单表:
		cte := b.findCte(tableName,ctx)
		if 是cte {
			cte 改写为 子查询;
			buildTable(子查询，ctx,depth);
		}else{
			catalog取表定义，没有报错;
			创建Binding,记录到BindContext，表示对表的引用；
			形成表引用表达式；
		}
	case 两表join:
		left = buildTable(左表,leftCtx);
		right = buildTable(右表,rightCtx);
		if on 条件{
			解析表达式;
		}
		形成join表达式;
	case 子查询：
		创建子查询需要的Builder和BindContext;
		subBuilder.buildSelect(subquery,subContext);//递归过程
		子查询也是关系;
		创建Binding,记录到BindContext，表示对子查询的引用；
		形成子查询引用表达式；
	}
}
```

merge两个BindContext，实质是将两个作用域的内容合并到外层作用域的过程。将Binding都合并到外层BindContext，并形成join表达式。
```go
func(Builder)mergeTwoTable(
	leftCtx, rightCtx *BindContext,  
	left, right *Expr,
	ctx *BindContext,
){
	leftCtx.bindings => ctx;
	rightCtx.bindings => ctx;
	形成join表达式；
}
```
### 解析表达式
表达式解析是bind的最复杂的过程。有多种原因：
- 种类多，每种的语法结构不同。
- 可以递归定义。意味着要递归处理。
- 非常灵活性。表达式可以简单也可以很复杂。
- 又有限制性。某些子句中是不能用某些表达式的。
- 类型转换。只有符合条件的类型间才能计算。表达式之间不一定能直接计算。在计算前要先转化类型。
- 函数选择。
	- 运算符也用函数实现。不同的数据类型需要不同的函数实现。
	- 并且在解析过程中确定合适函数实现。需要考虑类型和优先级。 

表达式解析的输入：表达式语法树
表达式解析的输出：Expr，表示解析完成的逻辑表达式。

表达式解析也是递归过程。依据表达式的不同类型递归拆解。
先介绍表达式分析的整体过程。再介绍每种表达式的解析方式。最后再介绍函数注册相关的内容。

表达式种类：
- 列引用。对表字段的引用。
- 常数。字符串、浮点数、整数值。
- 子查询。select list，where中是可以放子查询的。IN，ANY，EXISTS,NOT IN,NOT EXISTS。
- 函数。聚合函数和非聚合函数。
- 布尔。and，or，not。
- 二元运算符。
	- 比较。=，<>,>,>=,<,<=
	- 数值。+，-，*，/
	- 相似。LIke，NOT LIKE
	- 范围。IN,NOT IN,BETWEEN
- cast。
- 表达式list（元组）。
- Case...When。

整个函数表达式解析的结构是大switch再分类处理，再递归。

在`bindExpr`递归处理之后，加`decideResultType`和`AddCastToType`是标准过程。其目的是对齐数据类型。
其原理后续会单独讲：
- `decideResultType`。确定结果类型
- `AddCastToType`。cast过程

```go
func(Builder)bindExpr(
	ctx *BindContext,  
	iwc InWhichClause,  
	expr *pg_query.Node, depth int
){
	switch {
	case 列引用：
		从ctx中找出列名所在的Binding（即表引用）。
		生成列引用表达式;
	case 布尔：
		bindBoolExpr();
	case 子查询:
		bindSubquery();
	case 二元运算符：
		bindAExpr();
	case 常数：
		提取字符串，整数和浮点数 字面值。
	case 函数：
		bindFuncCall();
	case order by://实质是子表达式+asc/desc
		child, err := b.bindExpr(ctx, iwc, expr.Node, depth)
	case cast://cast (expr type)
		//子表达式
		retExpr, err = b.bindExpr(ctx, iwc, expr.Arg, depth)
		//cast到目标类型
		retExpr, err = AddCastToType(retExpr, resultTyp,)
	case 表达式list://元组
		//循环解析每个表达式
		for _, item := range expr.Items {  
		    itemExpr, err := b.bindExpr(ctx, iwc, item, depth)  
		}
	case "case ... when":
		bindCaseWhen();
	}
}
```

#### 列引用的解析
在tpch的查询里面，列引用是相对简单。实际列引用既灵活又限制。
- where 的列引用通常只能引用关系的属性。这里的关系范围：实体表，cte，子查询。但是where中列引用通常不能引用select list中的别名。因为where通常先执行，select list后执行。
- groupby和having中的列引用。通常不能引用select list中的别名。因为aggr通常先执行，select list后执行。
- order by中的列引用。通常能引用select list中的别名。因为select list可以先执行，然后对其结果排序。

#### 布尔表达式的解析
相对比较容易理解。特别的是pg语法树，布尔表达式可能不止两个子表达式。
先解析第一个表达式，再依次遍历第2，3，...个表达式。并不断的与第一个表达式对齐数据类型。最终的表达式形式：
```text
and : e1,e2,e3
=>
(and (and e1 e2) e3)

```
```go
func(Builder)bindBoolExpr(){
	确定布尔运算符类型;
	//注意：
	left = bindExpr(子表达式);
	//从子表达式1构建
	for i = 1 ... N-1 {
		cur, err = b.bindExpr(ctx, iwc, 子表达式i, depth)；
		//确定结果类型
		resultTyp = decideResultType(left.DataTyp, cur.DataTyp)  
		//cast到结果类型
		left, err = AddCastToType(left, resultTyp)  
		cur, err = AddCastToType(cur, resultTyp)  

		// 确定布尔表达式
		left, err = b.bindFunc(  
			et.String(),  
			et,  
			expr.String(),  
			[]*Expr{left, cur},  
			[]common.LType{left.DataTyp, cur.DataTyp},  
			false)
	}
	left是最终表达式。	
}
```

#### 子查询表达式的解析
子查询表达式类型
- `a IN subquery`
- `a  = ANY subquery`。可以改写为第一种。
- scalar。类似：select subquery as a
- `exists subquery` ,`not exists subquery`
第1，2种是需要配对的表达式`testexpr`。结果是布尔类型。
第3种就是单独的值。与值的类型相同。
第4种是布尔类型。

解析过程：
- 如果有`testexpr`，解析`testexpr`。
- 递归解析子查询。
```go
func(Builder)bindSubquery(){
	if testexpr{
		testExpr, err = b.bindExpr(ctx, iwc, expr.Testexpr, depth)
	}
	err = subBuilder.buildSelect(expr.Subselect.GetSelectStmt(), subBuilder.rootCtx, 0)
	根据子查询类型，构建子查询表达式。
}

```

#### 二元运算符的解析
语法形式:`e1 x e2`。通用解析方式是先做`e1`，再做`e2`。
`IN`和`BETWEEN`单独处理，会改写形式。

```go
func(Builder)bindAExpr(){
	switch
	{
	case IN : bindInExpr()
	case BETWEEN : bindBetweenExpr
	}

	//其它通用做法
	left, err = b.bindExpr(ctx, iwc, expr.Lexpr, depth)  
 
	right, err = b.bindExpr(ctx, iwc, expr.Rexpr, depth)  
		resultTyp = decideResultType(left.DataTyp, right.DataTyp)  
	  
	//cast  
	left, err = AddCastToType(left, resultTyp, )     
	right, err = AddCastToType(right, resultTyp,)  
	  
	bindFunc, err := b.bindFunc(
		et.String(),
		et,
		expr.String(),
		[]*Expr{left, right}, 
		[]common.LType{left.DataTyp, right.DataTyp}, false)  
	构建二元表达式。
}

```

将`IN`表达式打散。不是语法上的改写，而是结果的表达式的改写。`a IN (e1,e2,e3)`改写为`a IN e1 or a IN e2 or a IN e3`。
```go
func(Builder)bindInExpr(){
	//a
	in, err = b.bindExpr(ctx, iwc, expr.Lexpr, depth)  
	//元组(e1,e2,e3)
	listExpr, err = b.bindExpr(ctx, iwc, expr.Rexpr, depth)  
	//对齐数据类型。
	maxType := in.DataTyp  
	for i := 0; i < len(argsTypes); i++ {  
	    maxType = common.MaxLType(maxType, argsTypes[i])  
	}

	castIn, err := AddCastToType(in, maxType, false)    
	params = append(params, castIn)  
	paramTypes = append(paramTypes, castIn.DataTyp)  
	for _, child := range children {  
	    castChild, err := AddCastToType(child, maxType, false)  
	    params = append(params, castChild)  
	    paramTypes = append(paramTypes, castChild.DataTyp)  
	}

	//改写为a IN e1 or a IN e2 or a IN e3
	orChildren := make([]*Expr, 0)  
	for i, param := range params {  
	    if i == 0 {  
	       continue  
	    }  
	    equalParams := []*Expr{params[0], param}  
	    equalTypes := []common.LType{paramTypes[0], paramTypes[i]}  
	    ret0, err := b.bindFunc(et.String(), et, expr.String(), equalParams, equalTypes, false)  
	    orChildren = append(orChildren, ret0)  
	}  
	//结果的IN表达式。
	bigOrExpr := combineExprsByOr(orChildren...)
}
```

`BETWEEN`其实时三元表达式。`a BETWEEN b AND c`结果表达式在逻辑上改写为`a >= b AND a <= c`
```go
func(Builder)bindBetweenExpr(){
	//a
	betExpr, err = b.bindExpr(ctx, iwc, expr.Lexpr, depth)  
	//b,c
	listExppr, err = b.bindExpr(ctx, iwc, expr.Rexpr, depth)  
	//对齐数据类型
	resultTyp = decideResultType(betExpr.DataTyp, left.DataTyp)  
	
	resultTyp = decideResultType(resultTyp, right.DataTyp)  
	//cast  
	betExpr, err = AddCastToType(betExpr, resultTyp, false)    
	left, err = AddCastToType(left, resultTyp, false)    
	right, err = AddCastToType(right, resultTyp, false)  
	
	//改写为：a >= b AND a <= c
	//>=  
	params := []*Expr{betExpr, left}  
	paramsTypes := []common.LType{betExpr.DataTyp, left.DataTyp}  
	ret0, err := b.bindFunc(ET_GreaterEqual.String(), ET_GreaterEqual, expr.String(), params, paramsTypes, false)  
	  
	//<=  
	params = []*Expr{betExpr, right}  
	paramsTypes = []common.LType{betExpr.DataTyp, right.DataTyp}  
	ret1, err := b.bindFunc(ET_LessEqual.String(), ET_LessEqual, expr.String(), params, paramsTypes, false)  
	  
	// >= && <=  
	params = []*Expr{ret0, ret1}  
	paramsTypes = []common.LType{ret0.DataTyp, ret1.DataTyp}  
	  
	ret, err := b.bindFunc(ET_And.String(), ET_And, expr.String(), params, paramsTypes, false)  
}
```

#### 函数表达式的解析
完整的函数表达式的处理其实是的比较复杂。
- 获取函数定义。由函数签名确定函数定义。在这里讲到。
- 函数注册和查询。在后面细讲，这里先跳过。

函数的使用也有些限制：
- where中通常不能用聚合函数。
- having中通常不能用非聚合函数。
- 有group by时，投影列中非分组列通常用在聚合函数中
- 聚合函数通常不能嵌套。

解析步骤：
- 解析参数表达式
- 获取函数定义。

```go
func (Builder) bindFuncCall(){
	//参数表达式
	for _, arg := range expr.Args {  
	    child, err = b.bindExpr(ctx, iwc, arg, depth)  
	    args = append(args, child)  
	    argsTypes = append(argsTypes, child.DataTyp)  
	}
	//确定函数定义
	ret, err = b.bindFunc(  
	    name,  
	    ET_SubFunc,  
	    expr.String(),  
	    args,  
	    argsTypes,  
	    expr.AggDistinct)
}
```

#### Case...When的解析
在逻辑上是switch语义。

语法结构:
```sql
case 
when a1 then b1
when a2 then b2
[else] c
```

解析过程：
- 分析所有的when ... then
- 分析else

```go
func (Builder)bindCaseWhen(){
	//解析case ... then
	for i := 0; i < len(astWhen); i++ {  
	    temp, err = b.bindExpr(ctx, iwc, astWhen[i], depth)  
	    when[i*2] = temp.Children[0]  //case
	    when[i*2+1] = temp.Children[1]  //then
	}  
	  
	//解析else
	els, err = b.bindExpr(ctx, iwc, expr.Defresult, depth)  

	retTyp := els.DataTyp  
	//decide result types  
	//max type of the THEN expr  
	for i := 0; i < len(when); i += 2 {  
	    retTyp = common.MaxLType(retTyp, when[i+1].DataTyp)  
	}  
	  
	//case THEN to  
	for i := 0; i < len(when); i += 2 {  
	    when[i+1], err = AddCastToType(when[i+1], retTyp,)  
	}  
	  
	//cast ELSE to  
	els, err = AddCastToType(els, retTyp,)  
	if err != nil {  
	    return nil, err  
	}
	//构建case表达式
	ret, err := b.bindFunc(ET_Case.String(), ET_Case, expr.String(), params, paramsTypes, false)
}

```



### 数据类型

数据类型相关的几个方面：
- 数据类型的表达
- 类型转化规则。显式的，隐式的。

数据类型的表示方式：
- 逻辑类型。简单理解是sql层面的类型。
- 物理类型。物理存储方式。多个逻辑类型可能会实质对应同一个物理类型。

逻辑类型的组成部分：
- 类型id。一种编号。隐藏了一种优先级关系。
- 物理类型ID。一种编号。
- 数值宽度。因数据类型不同意义也不同。
- scale 或精度。

```go
type LType struct {  
    Id    LTypeId  
    PTyp  PhyType  
    Width int  
    Scale int  
}
```

目前只关注tpch 用到的数据类型：INT，BIGINT，VARCHAR，DECIMAL，DATE，INTERVAL。

#### 决定结果类型
在不考虑运算符的情况下，由两个输入类型确定结果的类型。

决策过程由一系列的判断条件构成。大的规则：
- 两个都是数值类型，单独处理。
- 两个都是非数值类型。
	- id不同时，id大的是结果类型。date，interval单独处理。
		- 一个是date，一个是interval，结果是date
	- id相同时，第一个类型是结果类型。enum，varchar，decimal再单独处理。decimal有数值宽度和精度的问题。


两个数值类型`t1`,`t2`，判断结果类型：
- `t1`能隐式转到`t2`。结果类型时`t2`。隐式规则是预先定义好的数值类型相互转换规则。这里不细说。
- `t2`能隐式转到`t1`。结果类型时`t1`。
- 两个同类型，符号不同的。向高一级精度转化。例如：uint和int，向int64转。
- 其它情况报错。

上面介绍的规则构成了类型判断的核心逻辑：
```go
func decideResultType(left common.LType, right common.LType) common.LType
{
	resultTyp := MaxLType(left,right)
	resultTyp是decimal，再调整数值宽度和精度。
	resultTyp是varchar，也再调整。
}

func MaxLType(left, right LType) LType

```

### 函数
sql里的聚合函数，标量函数和运算符，最终都用函数的形式展示。在这里只讲函数语义方面的内容（定义，类型，查找等），函数实现在执行器会再讲。

函数的组成结构：
- 名称
- 参数个数和类型
- 返回类型
- 函数类型：标量，聚合和运算符。
- 函数体：完成功能的执行代码
	- 标量函数，运算符。只需要函数实现代码
	- 聚合函数。还包含聚合状态的初始化、更新和终结。

用结构体`FunctionV2`表示函数定义：
```go
type FunctionV2 struct {  
    _name         string  
    _args         []common.LType  
    _retType      common.LType  
    _funcTyp      FuncType
	_scalar        ScalarFunc  
	_init      aggrInit  
	_update    aggrUpdate  
	_finalize  aggrFinalize
}
```

函数有重载特性：同名，但是不同参数个数或类型会有不同的实现。`FunctionSet`表示同名重载函数。系统里面有很多不同名称的函数，这些函数都记录在`FunctionList`中。
```go
type FunctionSet struct {  
    _name      string  
    _functions []*FunctionV2  
    _funcTyp   FuncType  
}

type FunctionList map[string]*FunctionSet
```

聚合函数有单独的实现框架。标量函数和运算符是一套框架。这些都与执行器强相关，会在讲执行器时再介绍。

定义函数并注册到系统中，实质是让系统中的某个`FunctionList`记录此函数及其重载。

#### 函数表达式解析
目的是确定函数的具体实现。

解析步骤：
- 确定函数类型。标量函数，聚合函数。聚合函数的解析入口不同，实质逻辑差不多。
- 确定函数的所有重载实现。确定`FunctionSet`
- 确定匹配输入参数的最佳实现。
	- 遍历重载实现，用输入参数类型 与 每个重载实现的参数类型对比，给每个重载实现计算一个分数，分数最低的为最佳的重载实现。
- 生成结果函数表达式。

函数解析关键函数：
```go
func (Builder) bindFunc(){
	if aggr {
		BindAggrFunc()
	}else{
		BindScalarFunc()
	}
}

func (FunctionBinder) BindAggrFunc(){}

func (FunctionBinder) BindScalarFunc(){}
```
#### cast
`cast`函数的应用形式`cast(expr,targetTyp)`。可以显式使用，也可以隐式使用。
在表达式类型和目标类型不一致时，需要将表达式值类型转成目标类型。`cast`函数是这类转换函数的总称。不是指单个转换函数。
两两数据类型之间能否转换、以及转换方式都是事先确定好的。简单说，`cast`函数对应了转换矩阵。矩阵的两个维度分别对应两种数据类型。矩阵元素是具体的转换函数。
转换函数如何实现。在介绍执行器框架时再讲，这里不细讲


## 小结
整体介绍了bind的过程。重点介绍了表达式的解析过程。确定结果类型、函数表达式解析和`cast`还有诸多细节没讲。一方面是琐碎难以讲清楚。另外是先把表达式执行框架讲清楚了之后再讲。更容易理解。

# 第二章 生成plan

## 简介
介绍从bind过程的结果物出发构建逻辑查询计划的过程。实质是规划查询执行的步骤，形成一个查询计划节点构成的树。而bind过程的结果物会被分散到这棵节点树上。
bind过程的结果物有：Builder,BindContext,Binding,Expr。

生产过程是按照语法单元的bind顺序，逐步构建完整的查询计划树：
- 为from生成查询节点
- 为where生成查询节点
- 为聚合函数和groupby生成查询节点
- 为having生成查询节点
- 为project生成查询节点
- 为orderby生成查询节点
- 为limit生成查询节点

查询节点结构：
- 类型。scan,filter,project,join,agg,order,limit等
- 子节点引用数组。
- 附加字段。不同的节点类型附加字段也不同。

```go

type LogicalOperator struct {  
    Typ              LOT  
    Children         []*LogicalOperator
    ...
    附加字段
}
```

## 生成查询计划
### 生成table scan节点
table scan节点表示对某种关系读取数据。

from表达式的结构：
- 单表
- 两表join
- 子查询
- values list。insert语句的values子句。
- 由这些基本结构组成的递归结构。

对from表达式进行递归处理，构建子树：
```go
func (Builder) createFrom(expr *Expr, root *LogicalOperator) *LogicalOperator{
	switch expr.Typ{
	case 单表：
		取表对象
		构建scan节点;
	case join:
		left, err = b.createFrom(expr.Children[0], root)    
		right, err = b.createFrom(expr.Children[1], root)
		join类型;
		on条件;
		构建join节点;
	case 子查询:
		_, root, err = b.createSubquery(expr, root)//后续单独讲
	case values list:
		确定列名称和类型，values list;
		构建scan节点;
	}

}
```


由单表通常生成table scan节点。
- 从catalog拿到表对象。
- 拿到表的统计信息。

scan节点形式：
```go
LogicalOperator{  
    Typ:       LOT_Scan,  
    Index:     expr.Index,  //关系序号
    Database:  expr.Database,  //schema name
    Table:     expr.Table,  //table name
    Alias:     expr.Alias,    //alias
    Stats:     stats,  //统计信息
    TableEnt:  tabEnt,  //表对象
}
```

由join通常生成join 节点。递归生成
- 生成左、右子节点的查询树
- 确定join类型。inner，left，cross
- 确定join on条件表达式。

```go
LogicalOperator{  
    Typ:      LOT_JOIN,  
    Index:    uint64(b.GetTag()),  //关系序号
    JoinTyp:  jt,  //join 类型
    OnConds:  []*Expr{onExpr.copy()},  //join ... on
    Children: []*LogicalOperator{left, right},  //子节点
}
```

为子查询生成查询树，比较复杂，会在后面单独讲，这里跳过。

由values list生成scan节点。没有表对象，数据从values list中读取。并且额外增加列名称和类型。
```go
LogicalOperator{  
    Typ:         LOT_Scan,  
    TableIndex:  int(expr.Index),  
    ScanTyp:     ScanTypeValuesList,  
    Types:       expr.Types,  
    Names:       expr.Names,  
    Values:      expr.Values,  
    ColName2Idx: expr.ColName2Idx,  
}

```

### 转换子查询

子查询可以出现在投影列、where子句和from子句中。tpch的查询中常用子查询。在为这些子句的表达式生成查询节点时，子查询展开是最复杂的环节，必须先讲清楚。

子查询又分为关联子查询和非关联子查询。关联子查询指子查询引用外层查询的列。

最基础的子查询执行方式：外层查询执行一条记录，执行一次子查询。这样执行性能低。
展开子查询的目的就是将子查询与外层查询融合起来，解决这种低效的子查询执行方式。

在展开子查询之前，子查询的完整查询计划树是已经生成的。在外层处理过程中，遇到子查询表达式时，就开始展开子查询。

不是每个表达式都是子查询，遇到表达式时，对表达式分类处理。

表达式递归处理过程：
- 子查询。先生成子查询的plan，展开子查询。
- 函数。对每个参数表达式，处理子查询。再产生新的结果表达式。对`IN`,`NOT IN`，会改写结果表达式。
- 其它。原样返回。
```go 
func (Builder) createSubquery(
	expr *Expr, 
	root *LogicalOperator) (*Expr, *LogicalOperator){
	switch expr{
	case 子查询:
		subRoot = 为子查询创建查询计划树;//递归过程
		//展开子查询
		apply(expr,root,subRoot);
	case 函数:
		//处理参数表达式
		for child := expr.Children{
			childExpr,root = createSubquery(child,root)
		}
		//对IN,NOT IN改写表达式
		生产结果表达式;
	case 其它:
		不做处理；
	}
}

```
#### 展开子查询
采用论文`Orthogonal Optimization of Subqueries and Aggregation`中提到的`apply`算法展开子查询。

这里介绍算法的工程实现，与原始的算法有差别。

算法输入与输出：
- 输入1：`expr`. 子查询表达式
- 输入2：`root`. 外层查询已经形成的部分查询计划子树。
- 输入3：`subRoot`. 子查询完整的查询计划树
- 输出1: 结果表达式，替换子查询表达式。
- 输出2: 展开后的查询计划树。融合了外层和子查询的查询计划树。

算法过程：
- 确认关联列。从子查询查询计划树中，找出所有的关联列。
- 如果没有关联列，是非关联子查询。处理方式：
	- 标量子查询。转成cross join节点,`children = {root,subRoot}`。
	- `IN`子查询。转成semi join节点,`children = {root,subRoot}`。
	- `NOT IN`子查询。转成anti join节点,`children = {root,subRoot}`。
- 如果有关联列，是关联子查询。处理方式：
	- **上拉关联表达式**。关联filter`子查询.t1.a = 外层查询.t2.b`。最终是将这样的filter拉出子查询与外层查询融合。
	- **从关联表达式中，消除关联列**。存在有些关联列消除不掉的情况。
	- **改写子查询**。
		- 标量子查询。用新列引用替换子查询。新列引用去引用子查询投影列。
		- `exists`，`not exists`子查询。
			- 在上一步，已经改写为mark join和anti mark join。
			- 在mark join和anti mark join之上，加一个标志列，表示某行的值是否存在。具体mark join和anti mark join是怎么计算的，在讲join算子时，会再讲。

上拉关联表达式的逻辑：
- 存在一个问题:`子查询.t1.a`这部分是不能直接拉出子查询的，拉出来就是有问题的。但是又要保持filter的语义不变。
- 因此在上拉过程中，`子查询.t1.a`这部分会进入`project`,`aggr` 节点，并间接引用`project`,`aggr`。并将filter 改写为  `间接引用 = 外层查询.t2.b`。有点抽象，请看后面的伪代码。
- 对于`filter`节点。将filter节点中的关联表达式切出来。
```go
func (Builder) removeCorrFilters(
	subRoot *LogicalOperator,
) (*LogicalOperator, []*Expr){//返回新subRoot和关联表达式
	//对子节点递归处理
	for i, child := range subRoot.Children {  
	    subRoot.Children[i], childFilters, err = b.removeCorrFilters(child)
	}
	switch {
	case project://上拉经过project
		for filter := childFilters{
			递归处理(filter){
				if filter无关联列 {//进入project投影列。并间接引用此列
					idx := len(subRoot.Projects)  
					subRoot.Projects = append(subRoot.Projects, filter)
					间接引用此列{Column,subRoot.Index,idx}
				}else{
					递归处理filter的子节点。
				}
			}
		}
	case agg://上拉经过agg
		for filter := childFilters{
			递归处理(filter){
				if filter无关联列 {//进入project投影列。并间接引用此列
					idx := len(subRoot.GroupBys)  
					subRoot.GroupBys = append(subRoot.GroupBys, filter)
					间接引用此列{Column,subRoot.Index,idx}
				}else{
					递归处理filter的子节点。
				}
			}
		}
	case fiter://将filter节点中的关联表达式切出来
		for _, filter := range subRoot.Filters {  
		    if filter是关联表达式 {  
		       corrFilters = append(corrFilters, filter)  
		    } else {  
		       leftFilters = append(leftFilters, filter)  
		    }  
		}
	}
}

```

消除关联列。递归处理，将表达式中的深度大于0的列引用的深度都减去1。
- 列引用。深度大于0（`expr.Depth > 0`），`expr.Depth - 1`。
- 函数表达式。对参数表达式，递归处理。
经过递归消除后，有些关联列消除为非关联列，依然有些关联列没消除掉。
对递归消除后的结果进行处理：
- 非关联列（由关联列消除而得）。这些非关联列，成为join on条件。
	- 标量子查询。转为inner join节点。非关联列是on条件。
	- `exists`子查询。转为mark join节点。非关联列是on条件。
	- `not exists`子查询。转为anti mark join节点。非关联列是on条件。
- 关联列（由关联列消除后，依然是关联列）。成为filter节点。

### 生成filter节点
filter节点的内容：表达式数组。数组内元素语义上是and。

产生filter节点的场景：
- `where`,`having` 表达式
- 展开子查询。消除关联项之后。
- 优化器优化过程中。例如：filter下推

`where`,`having` 表达式有显著的区别。`where`中不能用聚合函数。`having`可以用。本文没有区分这一点。两者转filter节点的逻辑都是相同的。

`where`,`having` 表达式转filter节点的过程：
- 转换成合取范式。单个表达式=>表达式数组。用and将大表达式切分成小表达式。相对简单不细说。
- 对每个小表达式，转换子查询。展开子查询已在前面讲过。
- 对每个小表达式，处理分配律，方便后续优化。`(a and b1) or (a and b2) or (a and b3) => a and (b1 or b2 or b3)`。

```go
func (Builder) createWhere(expr *Expr, root *LogicalOperator) (*LogicalOperator){
	//按and拆分。
	filters := splitExprByAnd(expr)
	//展开子查询
	for _, filter := range filters {  
	    newFilter, root, err = b.createSubquery(filter, root)
	}
	//
	newFilters = distributeExprs(newFilters...)
}
```

表达式，分配律（类似提取公因子）处理逻辑：
- 转成析取范式。用or将大表达式切分成小表达式。
- 将每个小表达式，再转换成合取范式。
- 找出所有合取范式中，相同的表达式。抽出来。
- 再重组。

### 生成Agg节点
查询中有聚合函数和group by，要生成Agg节点。agg节点的内容：聚合函数表达式，group by表达式。
生成过程简单不细说。

### 生成Project节点
为投影列表生成project节点。project节点内容：投影表达式。
投影列是可以用子查询的。
```go
func (Builder) createProject(root *LogicalOperator) (*LogicalOperator){
	for _, expr := range b.projectExprs {  
	    newExpr, root, err = b.createSubquery(expr, root)
	}
}
```


### 生成order节点
为order by子句生order节点。order节点内容：order by表达式。
生成过程简单不细说。

### 生成limit节点
为limit子句生limit节点。limit节点内容：limit表达式。
生成过程简单不细说。

## 小结
展开子查询是生成查询计划树中最复杂的环节。涉及到表达式变换、改写、替换，过程抽象容易理解出错。实际上本文介绍的展开子查询的算法 不能 展开任意子查询。

# 第三章 优化plan

## 简介
优化逻辑查询计划以提升查询性能。

优化过程复杂，有很多原因：
- 不同的优化规则，复杂度不同。
- 优化过程中，涉及查询树和表达式的变换。基本是递归操作。
- 对关系代数有一定的要求。

本文介绍的优化规则：
- filter下推
- join定序
- 列裁剪

整体的优化过程：
- filter下推
- join定序
- filter下推
- 列裁剪
- 生成引用计数
- 生成输出表达式

## filter下推
查询计划树上，filter离scan节点越近，越能及早过滤掉不必要的数据。filter下推就是将树上层的filter尽可能的往下推。整体看，filter下推过程比较清晰。

下推输入与输出：
- 输入1: 查询计划树
- 输入2: 上个节点传下来要下推的filter
- 返回1：新的查询计划树
- 返回2：不能下推的filter

下推是递归完成的。不同节点下推filter的做法不同。
- scan节点。引用当前表的filter保留在scan节点。
- join节点。确定filter表达式，哪些只引用了左子树的表。哪些只引用了右子树的表。哪些左右子树的表都引用了。
	- 分别向左、右子树下推。
	- 下推不了的生成新的filter节点。或者形成join on条件。
- agg节点。如果filter是引用了agg节点上的表达式，是不能下推的。这些得保留。
- filter和project节点。表达式只需要做初步处理，即可下推。
```go
func (b *Builder) pushdownFilters(root *LogicalOperator, filters []*Expr) (*LogicalOperator, []*Expr){
	switch root.Typ{
	case scan:
		for _, f := range filters {
			如果filter只引用了此节点，保留。
			其它，返回。
		}
	case join:
		收集左子树的表;
		收集右子树的表;
		for i, filter := range fitlers {  
		    确定filter仅在左、右子树还是左右都占;
		} 
		
		for i, filter := range fitlers {
			switch filter{
			case 左右都不粘:
				如果是inner join，左右都下推;
				如果是left join，左边下推;
				其它，不下推，此filter返回；
			case 左:
				左边下推;
			case 右:
				右边下推;
			case 左右都粘:
				如果是inner join或 left join，可以转换成join on条件.
				其它，不下推，此filter返回；
			}
		}
		//左边下推
		childRoot, childLeft, err = b.pushdownFilters(root.Children[0], leftNeeds)  
		if len(childLeft) > 0 {  
			 下推不了的，形成新filter节点；
		} 
		root.Children[0] = childRoot

		childRoot, childLeft, err = b.pushdownFilters(root.Children[1], rightNeeds)    
		if len(childLeft) > 0 {  
			下推不了的，形成新filter节点；
		}  
		root.Children[1] = childRoot
		
	case agg:
		//预处理
		for _, f := range filters {
			如果filter引用了agg的表达式，不能下推。保留在agg节点上。
			如果filter间接引用了group by的表达式，间接引用要先替换成实质的group by 表达式。
		}
		childRoot, childLeft, err = b.pushdownFilters(root.Children[0], needs)  
		if len(childLeft) > 0 {  
			 下推不了的，形成新filter节点；
		} 
		root.Children[0] = childRoot
	case project:
		//预处理
		for _, f := range filters {
			如果filter间接引用了project的表达式，间接引用要先替换成实质的project表达式。
		}
		childRoot, childLeft, err = b.pushdownFilters(root.Children[0], needs)  
		if len(childLeft) > 0 {  
			 下推不了的，形成新filter节点；
		} 
		root.Children[0] = childRoot
	case filter:
		合并filter节点本身的filter表达式 与 父节点传下来的filter表达式;
		childRoot, childLeft, err = b.pushdownFilters(root.Children[0], needs)  
		if len(childLeft) > 0 {  
			root.Children[0] = childRoot
			下推不了的，合并到filter节点；
		}else{
			都下推了，无需此filter节点;
		}
	case limit:
		不下推；
	case 其它:
		如果是双子节点，不下推；
		如果是单子节点，尝试下推；下推不了的，形成新filter节点；
	}
}
```

## join定序
相当复杂的处理过程。

本文介绍的join定序具有的特点：
- 递归过程
- 前期要多步准备
- 引入新的概念和数据结构
- 贪心算法
- 抽象，不易理解

### join order 优化框架
join定序优化入口。
定序由多个环节组成。
- step1 ～step 2。准备join定序的SingleJoinRelation。每个表示一个基础关系。
- step3 。基于filter构建图和边。
	- 图结点是JoinRelationSet。其是relation id的集合。与SingleJoinRelation不是同个概念
- step4～step 6。准备join定序的运算对象。有NodeOp,JoinNode构建的初始plan结点。
- step7～step8。执行join定序算法。选出最优的plan结点
- step9。基于plan结点，生成最终的plan树。

```go
//join定序优化
func (joinOrder *JoinOrderOptimizer) Optimize(root *LogicalOperator) (*LogicalOperator, error) {
	//step 1: 抽取relations
	noReorder, filterOps, err :=joinOrder.extractJoinRelations(root, nil)

	//step 2：从filterOps收集filters
	遍历filterOps，将filter整理到joinOrder.filters

	//step 3：基于filter构建无向图。
	//图结构：
	//  结点：左、右子表达式中引用到的table index数组对应的relation id数组。
	//  边：(左子表达式关联的relation id数组， 右子表达式关联的relation id数组)构成了一条边
	//
	//可以认为图中只有relation id信息了。直接看不到table index信息了。
	对joinOrder.filters的每个filter处理：
		//step 3.1 构建整个filter的信息：filterInfo
		抽取filter关联的relation id数组filterRelations:
			joinOrder.collectRelation
		借助JoinRelationSetManager将relation id数组转化为JoinRelationSet；
			joinOrder.setManager.getRelation(filterRelations)
		//step 3.2 用filter创建图和边
		joinOrder.createEdge(filter的左子表达式, filter的右子表达式, filterInfo)

	//step 4：构建join tree的叶结点（单结点的plan）和其基数。及单个relation id表示一个树结点
	//nodes_ops []NodeOp
	为每个SingleJoinRelation创建叶结点：
		node(JoinRelationSet) := joinOrder.setManager.getRelation(relation id)
		NodeOp{JoinNode{node,SingleJoinRelation.op}}

	//step 5: 为每个叶结点NodeOp初始化基数
	err = joinOrder.estimator.InitCardinalityEstimatorProps(nodesOpts, joinOrder.filterInfos)

	//step 6： 基于叶结点，初始化基础plan
	//这个plan记录在映射：JoinRelationSet => JoinNode
	joinOrder.plans.set(nodeOp.node.set, nodeOp.node)

	//step 7：对基础plan应用join order算法，确定最终的plan。
	err = joinOrder.solveJoinOrder()

	//step 8: 生成结果plan结点
	//join order优化后的理想结果是：
	//	joinOrder.plans中有JoinRelationSet完整数组组成的plan结点。此时说明图能形成一棵新的完整plan结点。
	final := joinOrder.plans.get(set)  
	if final == nil {  
		//step 8.1 无完整plan结点
		//为JoinRelationSet数组两两元素，在图中构建一条边
	    joinOrder.generateCrossProduct()  
	    //再重新执行join order算法
	    err = joinOrder.solveJoinOrder()  
	    //一定能拿到新的完整的plan结点
	    final = joinOrder.plans.get(set)  
	}

	//step 9：基于结果plan结点，生成最终的plan树。
	//注意：plan结点指 JoinNode构成的。
	// plan树指 LogicalOperator构成的。
	return joinOrder.rewritePlan(root, final)
}

```

### extractJoinRelations
准备join定序的SingleJoinRelation。收集基础关系。在join定序过程中无法被任意交换的关系。
```go 
//递归过程。搜索plan子树，寻找所有符合条件的节点，生成所有SingleJoinRelation。
//输入： plan子树
//输出：
//  nonReorder：不能做reorder操作。
//  filterOps：有过滤条件的结点。
//  relations： SingleJoinRelation结点
//  relationMapping：table index -> relation id
func (joinOrder *JoinOrderOptimizer) 
	extractJoinRelations(root, parent *LogicalOperator) 
	(nonReorder bool, filterOps []*LogicalOperator, err error) {
	//step 1：
	遍历子树，寻找第一个符合条件的节点：
	  不是project
	  不是scan
	  且有两个子节点的
	遍历过程中，遇到agg节点（符合上述条件），对agg节点子树递归优化(Optimize)。递归优化结束后，停止遍历。

	//step 2：
	跳出上述遍历过程的基本就是project,scan,join,set-op等
	如果节点刚好是join时,
		如果不是inner join又不是cross join时，不能对子树进行reorder操作，需要特殊处理。
	
	不能reorder join的特殊处理逻辑：
		对每个子节点，递归优化；
		生成SingleJoinRelation结点；
		取子树的所有table index,同时合并子节点的relation index 与 table index的映射关系。
		返回

	//step 3： 可以reorder的情况
	switch op.Typ{
	case join:
		（join结点本身不产出什么）
		对左、右子结点递归extractJoinRelations;
	case scan:
		生成SingleJoinRelation结点；
	case project:
		对子结点递归优化(Optimize);
		生成SingleJoinRelation结点；
	}
	
	
}

```

### collectRelation
从表达式中确定table index对应的所有relation id。
```go
//从表达式中抽取table index对应的relation id数组
//递归操作
//从(table index,column index)转(relation id,column index)
func (joinOrder *JoinOrderOptimizer) collectRelation(e *Expr, set map[uint64]bool){
	switch e.Typ{
	case colRef:
		relId := joinOrder.relationMapping[index];
		//(table index,column index) => (relation id,column index)
		joinOrder.estimator.AddColumnToRelationMap(relId, e.ColRef[1])
	...
	}

}
```

### createEdge
在图中，基于左，右表达式构建一条边。
生成图结点的过程：表达式=>relation ids =>JoinRelationSet =>图结点。

```go

//基于左，右表达式构建一条边。
func (joinOrder *JoinOrderOptimizer) createEdge(left, right *Expr, info *FilterInfo){
	//左表达式 的table index => leftRelations(relation id数组)
	joinOrder.collectRelation(left,leftRelations)
	//右表达式 的table index => rightRelations(relation id数组)
	joinOrder.collectRelation(right,rightRelations)
	//如果leftRelations,rightRelations都不为空时，创建图的边
	//将leftRelations(relation id数组)转化为JoinRelationSet
	info.leftSet = joinOrder.setManager.getRelation(leftRelations)  
	//将rightRelations(relation id数组)转化为JoinRelationSet
	info.rightSet = joinOrder.setManager.getRelation(rightRelations)
	//如果leftRelations(JoinRelationSet),rightRelations(JoinRelationSet)不相交，创建图里面的边。
	//结点：info.leftSet，info.rightSet
	//边：无向图两条边
	joinOrder.queryGraph.CreateEdge(info.leftSet, info.rightSet, info)  
	joinOrder.queryGraph.CreateEdge(info.rightSet, info.leftSet, info)	
	
}
```

### join order贪心算法
基于图query graph. 图以JoinRelationSet为结点，以filter构建边。
初始的plan的结点，在映射：joinOrder.plans {JoinRelationSet => JoinNode}

算法复杂度：O(N^3)

算法初始化：
- 初始结点数组。单个relation id构成的JoinRelationSet数组。

算法框架：
- 在初始JoinRelationSet数组上，进行迭代运算。
	- 枚举 i,j 分别对应两个不同元素。共有N（N-1）种情况
	- 如果图中，有i,j对应的JoinRelationSet构成的边，
		- 两个JoinRelationSet融合，并构建新的plan结点。
- 直到，数组中只有单个JoinRelationSet结点。

```go
// 贪心join order算法
func (joinOrder *JoinOrderOptimizer) solveJoinOrder() error {  
    return joinOrder.greedy()  
}

//join order贪心算法
func (joinOrder *JoinOrderOptimizer) greedy() (err error) {
	//step 1：算法初始化
	生成由单个relation id构成的JoinRelationSet数组。

	//step 2：直到数组只有一个元素为止
	for 数组元素个数 > 1 {
		//最佳的结点，以及对应的JoinRelationSet
		best = nil.
		bestLeft,bestRight = 0,0
		//step 2.1 找出cost最低的两两组合
		for i := 0...len{
			for j := i+1...len{
				if i,j对应的JoinRelationSet有边{
					node = joinOrder.emitPair(i,j的JoinRelationSet结点,边);
					更新best,bestLeft,bestRight = node,i,j；
				}
			}
		}
		//处理特殊情况：没有best,多种原因。
		//硬加一条边
		if best == nil{
			从数组中，取两个基数最低的i,j；
			在图中为它们增加边：joinOrder.queryGraph.CreateEdge(left, right, nil);
			在为i,j生成新结点：best, err = joinOrder.emitPair(left, right, conns);
		}
		//step 2.2 将最优的两两组合从数组中删掉
		//并插入组合后的JoinRelationSet
		joinRelations = util.Erase(joinRelations, bestRight)  
		joinRelations = util.Erase(joinRelations, bestLeft)  
		joinRelations = append(joinRelations, best.set)
	}
}



```

### emitPair
融合有边的两个JoinRelationSet，并生成新的plan结点

```go

//构建新的plan结点
//left,right会融合成新的JoinRelationSet
func (joinOrder *JoinOrderOptimizer) emitPair(left, right *JoinRelationSet, info []*neighborInfo) (*JoinNode, error){
	//step 1: 取left,right对应的plan结点。
	//从joinOrder.plans {JoinRelationSet => JoinNode}中取结点
	leftPlan, err := joinOrder.getPlan(left)  
	rightPlan, err := joinOrder.getPlan(right)
	//step 2：融合left,right形成新JoinRelationSet
	newSet := joinOrder.setManager.union(left, right)  
	//step 3：基于融合的JoinRelationSet和leftPlan,rightPlan，创建新的Join plan结点
	newPlan, err := joinOrder.createJoinTree(newSet, info, leftPlan, rightPlan)
	//step 4：新plan结点更新到joinOrder.plans
	joinOrder.plans.set(newSet, newPlan)
}

```
### getRelation
JoinRelationSetManager： 
	relation id序列组成的trie树
	trie树叶结点是JoinRelationSet
	
JoinRelationSet：
	relation id数组
```go
//relation id数组 => JoinRelationSet
func (jrsm *JoinRelationSetManager) getRelation(relations UnorderedSet) *JoinRelationSet{
	...
}

```

### generateCrossProduct
补充query图的边

```go

//为JoinRelationSet数组两两元素，在图中构建一条边
func (joinOrder *JoinOrderOptimizer) generateCrossProduct(){
	for i := 0...len{
		for j := 0...len{
			if i != j{
				joinOrder.queryGraph.CreateEdge(left, right, nil)  
				joinOrder.queryGraph.CreateEdge(right, left, nil)
			}
		}
	}

}

```

### rewritePlan
生成新plan数据

```go

//基于最优plan结点重新生成新plan树
func (joinOrder *JoinOrderOptimizer) rewritePlan(root *LogicalOperator, node *JoinNode) (*LogicalOperator, error) {
	//step 1:
	extractedRelations = 取出每个SingleJoinRelation关联的LogicalOperator，形成数组；
	
	//step 2:基于extractedRelations和plan结点，生成新的join 结点
	//joinTree是结果的join tree
	joinTree, err := joinOrder.generateJoins(extractedRelations, node)
	//step 3： 处理剩余的filters
	//step 4：上移结果joinTree的位置。
}

//递归生成join 结点树
func (joinOrder *JoinOrderOptimizer) generateJoins(extractedRels []*LogicalOperator, node *JoinNode) (*GenerateJoinRelation, error) {
	if node有双子结点 {
		//构建为新join结点
		//先对左，右子结点递归生成
		left, err := joinOrder.generateJoins(extractedRels, node.left)  
		right, err := joinOrder.generateJoins(extractedRels, node.right)
		//依据filter个数分为cross join和inner join
		//结果是：
		//    结果的JoinRelationSet是左，右子结点的JoinRelationSet合并的结果
		//    结果的LogicalOperator是新生成的join结点
	}else{
		//结果是：
		//    结果的JoinRelationSet是结点的JoinRelationSet
		//    结果的LogicalOperator是结点的JoinRelationSet对应的第一个
	}
	//如果join结点，还有剩余的filter，要带上，不能丢弃
	
}

```
## 列裁剪
将非根结点的输出列个数减到最少。只要某个结点的输出列没有被祖先结点所引用都应该删除掉。

从根结点往下遍历plan树，递归处理过程：
- 记录结点的表达式的所有的列引用
- 在project,scan,agg结点时，
	- 递归先序遍历时，记录要删除的列。
	- 对子结点进行处理。
	- 递归后序遍历时，彻底删除列。

记录列引用的映射：
```go
//列引用 => 表达式数组
type ReferredColumnBindMap map[ColumnBind][]*Expr
```

递归过程：
```go

func (cp *ColumnPrune) prune(root *LogicalOperator) (*LogicalOperator, error) {
	switch root.Typ{
	case order:
		记录order by表达式中的列引用;
	case project:
		处理影列表达式list：
			如果列表达式{project结点index,i}，
				没在祖先结点中被引用，此列为不再需要的；
				已经被引用，那么记录列表达式中的列引用。
				并计算旧列引用{project结点index,i}对应的新列引用{project结点index,j}；
		递归对子结点裁剪；
		删除不再需要的列；
		对记录的表达式，将旧列引用都替换为新列引用；
		返回；
	case aggr:
		记录group bys,filters表达式中的列引用；
		处理聚合表达式list：
			如果列表达式{aggr结点index2,i}，
				没在祖先结点中被引用，此列为不再需要的；
				已经被引用，那么记录列表达式中的列引用。
				并计算旧列引用{aggr结点index2,i}对应的新列引用{aggr结点index2,j}；
		递归对子结点裁剪；
		删除不再需要的列；
		对记录的表达式，将旧列引用都替换为新列引用；
	case join:
		记录on表达式中的列引用；
	case scan:
		记录filters表达式中的列引用；
		处理scan结点列表达式list：
			如果列表达式{scan结点index,i}，
				没在祖先结点中被引用，此列为不再需要的；
				已经被引用，那么记录列表达式中的列引用。
				并计算旧列引用{scan结点index,i}对应的新列引用{scan结点index,j}；
		删除不再需要的列；
		对记录的表达式，将旧列引用都替换为新列引用；
	case filter:
		记录filters表达式中的列引用；
	}


	//对子结点递归裁剪
	for i, child := range root.Children {  
	    root.Children[i], err = cp.prune(child)
	}
}

```

## 生成列引用计数
计算每个结点要输出的列引用，列引用的引用个数和列引用的输出位置序号。这些值在生成输出表达式时需要。

从根结点往下遍历plan树，递归处理过程：
- 删除祖先结点引用此结点的列引用个数
- 统计结点的表达式的所有的列引用个数
- 统计子结点的列用个数
- 在project,agg,join结点时，
	- 递归先序时，先从引用计数中，删除对此结点的引用。因为此结点的子结点中不可能再引用此结点。
	- 递归后序时，再加山对此结点的引用。如此才能保证引用个数的正确


实际记录列引用个数的函数是updateCounts。

```go
func (update *countsUpdater) generateCounts(root *LogicalOperator, upCounts 
ColumnBindCountMap) (*LogicalOperator, error) {

	updateCounts ：=func(){
		记录结点表达式的列引用个数；
		递归更新子结点的引用个数；
		resCount，upcounts恢复祖先结点对引用此结点的引用个数；
		resCount中删除祖先结点不需要的列引用；
		resCount，upcounts删除结点表达式的列引用个数；
	}

	switch root.Typ{
	case limit:
	case order:
		updateCounts（order by表达式）；
	case project:
		从upcounts中删除，对此结点的引用个数；
		updateCounts（投影表达式）;
	case aggr:
		从upcounts中删除，对此结点的引用个数；
		updateCounts（group by,aggr,filter表达式）;
	case join:
		从upcounts中删除，对此结点的引用个数；
		updateCounts（on表达式）
	case scan:
		resCounts = upCounts;
		基于resCounts生成此结点的引用个数；
	case filter:
		updateCounts（filter表达式）；
	}
}

```


## 生成输出表达式
结点的投影表达式和输出表达式。
它们的不同点：
- 存在与否。投影表达式，不是每个结点都有。输出表达式每个结点都会被补上。
- 列引用形式。投影表达式，引用实际结点index. 输出表达式，只引用直接子结点的输出列。

输出表达式 方便执行器生成数据。

输出表达式的类型：
- 祖先结点引用此结点的列引用
- 祖先结点引用此结点的子结点的列引用。子结点的列引用数据会透传给祖先结点。

生成输出表达式的整体递归过程：
- 对子结点递归生成输出表达式；
- 结点表达式的列引用替换为对子结点输出表达式的列引用；
- 基于结点的引用计数，生成输出表达式：
	- 引用此结点本身，列引用表达式引用此列位置
	- 引用子结点，引用左右子结点的输出表达式的列位置。
	- aggr结点的特殊性：其输出表达式，按情况集中输出，依次排开。
		- 引用aggr结点
		- 引用aggr 聚合函数结果
		- 其它情况。
	- join结点的特殊性：其输出表达式，先是左右子结点，再是此结点。
		- 引用左右子结点
		- 引用join结点

```go

func (update *outputsUpdater) generateOutputs(root *LogicalOperator) (*LogicalOperator, error) {
	
	switch root.Typ{
	case limit:
		递归子结点生成输出表达式；
		生成输出表达式；
	case order:
		递归子结点生成输出表达式；
		order by表达式的列引用替换为对子结点输出表达式的列引用；
		生成输出表达式；
	case project:
		递归子结点生成输出表达式；
		投影表达式的列引用替换为对子结点输出表达式的列引用；
		生成输出表达式；
	case aggr:
		递归子结点生成输出表达式；
		group by,aggrs,filters表达式的列引用替换为对子结点输出表达式的列引用；
		生成输出表达式；
	case join:
		递归子结点生成输出表达式；
		on表达式的列引用替换为对子结点输出表达式的列引用；
		为左右子结点生成输出表达式；
		生成输出表达式；
	case scan:
		生成输出表达式；
	case filer:
		递归子结点生成输出表达式；
		filters表达式的列引用替换为对子结点输出表达式的列引用；
		生成输出表达式；
	}
}

```


## 小结
介绍filter下推，join定序，列裁剪三种基础的优化算法实现方案。

# 第四章 vector

## 简介
介绍向量执行器需要的列式内存结构：vector,chunk和unified format。

## vector
vector逻辑上表示元素数组，固定个数。
vector数据结构关键组成：
- 元素的数据类型。int,float,string等
- 物理表示方案：数据在内存中的组织方式。
	- 不同场景需要不同方案。
	- 节省内存
	- 逻辑上和物理上可能不一致。
- 内存空间。

物理表示方案：
- FLAT。连续数组。与逻辑表示相同。也是默认的表示方案。
- CONSTANT。所有元素相同。物理上只存一份。
- DICTIONARY。字典形式。元素实质是执行字典值的索引。类似指针。组成方式：select vector和child vector（字典）。取元素的方式：用select vector[i]的值在child vector中取最终值。
- SEQUENCE。序列值。组成方式：base（基础值）和increment（递增值）。取元素的方式：base + increment * i。
- unified format。通用格式。 连续数据。与flat相比，多了select vector作为指针。用于开发基于vector的通用算法，避免为具体的物理表示写特殊代码。上面的物理类型都可转成unified format。

```go

type Vector struct {  
    _PhyFormat PhyFormat  //物理表示
    _Typ       common.LType  //数据类型
    Mask       *util.Bitmap  //NULL值
    //内存
    Data       []byte  
    Buf        *VecBuffer  
    Aux        *VecBuffer  
}

```

使用vector方式，有对应的接口：
- 基础接口：
	- Init。为某种数据类型分配数组内存。
	- Reset。
- 物理表示转换接口：
	- Flatten
	- ToUnifiedFormat
- 元素引用接口：
	- slice
	- SetValute/GetValue
	- GetSliceInPhyFormatXXX
	- GetMaskInPhyFormatXXX
- 数据移动接口：
	- copy。

讲一些复杂的接口实现。

### flatten
物理表示转成flat。可以理解为拍平。通常用在执行器算法的某一步。转成flat后，方便后续处理。

目前支持的源物理表示：
- flat。不需要转换。
- constant。将单个常数展开为元素数组。

constant转flat的实现方案：
- 按flat要求分配内存
- 数据复制。单个元素复制到flat数组的每个元素。
```go

func (vec *Vector) Flatten(cnt int) {
	//constant => falt
	按flat要求分配内存;
	如果值是NULL,设置mask；
	constant值 复制 到flat数组的全部元素。

}

```

###  ToUnifiedFormat
物理表示转成unified format.

unified format格式的关键成分：
- select vector。select vector[i]对于的是实际位置下标。
- data。内存。
- mask。null位图。
- 与flat相比，多了select vector作为指针。
```go
type UnifiedFormat struct {  
    Sel      *SelectVector  
    Data     []byte  
    Mask     *util.Bitmap  
    InterSel SelectVector  
    PTypSize int  
}

```

转成unified format具体过程，实质上是确定其关键成分。简单说，是把dict这层vector给去掉，直接引用child vector.
dict转unified format稍微麻烦些。
具体方案：
```go
func (vec *Vector) ToUnifiedFormat(count int, output *UnifiedFormat) {
	switch vec的物理表示{
	case dict:
		select vector 为vec.sel；
		if child vector是flat {
			直接引用child vector的select vector, 内存和mask；
		} else {
			child vector先flatten；
			再引用child vector的select vector, 内存和mask；
		}
	case constant:
		select vector的值都为0。指向第一个元素；
		直接引用内存和mask；
	case flat:
		select vector的值都为0～N-1。
		直接引用内存和mask；
	}

}

```

### slice
slice对vector的切片操作。有多种具体实现。

- SliceOnSelf
基于select vector对vector本身进行slice。如果vector的物理表示是dict和flat，结果vector的物理表示是dict. 如果是constant,结果不变。

```go

func (vec *Vector) SliceOnSelf(sel *SelectVector, count int) {
	
	if 物理表示是constant {
		什么都不做；
	}else if dict{
		//dict
		用输入的select vector对dict的select vector进行slice，生成新的select vector；（新的select vector[i] = dict.select vector[sel[i]]。简单理解成二级指针）
			
	}else {
		//flat
		物理表示转为dict；
		dict的select vector为输入的select vector；
		dict的child vector指向vec本身；
	}

}

```

- Slice, Slice2, Slice3

Slice是引用另一个vector，并用select vector进行slice。
Slice2是对当前vector，用select vector进行slice。
Slice3也是引用另一个vector，并用下标区间[offset,end]进行slice。与Slice相比，接口不同，实现有些区别。意义确实一样的。

实现上，Slice和Slice2，最终使用SliceOnSelf。Slice3却是直接对内存进行切片。具体实现都不复杂，不再细说。

```go

func (vec *Vector) Slice(other *Vector, sel *SelectVector, count int){
...
}

func (vec *Vector) Slice2(sel *SelectVector, count int) {
...
}

func (vec *Vector) Slice3(other *Vector, offset uint64, end uint64) {
    ...
    }

```

### SetValute/GetValue
SetValue(idx,value)给vector指定位置设置新值。
GetValue(idx)从vector指定位置取值。

 - GetValue(idx)
```go
func (vec *Vector) GetValue(idx int) *Value {
	switch{
	case constant:
		//constant vector只有一个元素
		idx = 0；
	case flat:
	case dict:
		从child vector的位置select vector[idx]处取值；
	case sequence:
		返回值为start + idx * increment
	}
	如果idx是努力了，返回；
	返回 内存idx处的元素；
}

```

- SetValue（idx,value)
镜像操作，实现不复杂。
### GetSliceInPhyFormatXXX
取出vector的底层元素数组。XXX包括flat,constant,sequence，unified format。不包含dict.
实现上是简单的范型转换。

### GetMaskInPhyFormatXXX
取出vector的mask（NULL位图）。实现简单。

### Copy
从源vector复制数据到目的vector.  要求目的vector是flat.

copy接口：
```go

func Copy(  
    srcP *Vector,  //源vector
    dstP *Vector,  //目的vector
    selP *SelectVector,  //源select vector
    srcCount int,  //要复制的源元素个数
    srcOffset int,  //要复制的源头开始位置
    dstOffset int,  //目的开始位置
){
	//step 1：确定实际的源vector和select vector
	dict类型源vector：
		源vector是child vector；
		源select vector是输入selP对dict select vector切片后的结果。
	constant类型源vector：
		源select vector每个值为0.

	//step 2：复制Mask
	//step 3: 复制实际数组元素
	dst vector[dstOffset + i] = src vector[selP[srcOffset + i]]
	
}

```

## chunk
一组元素个数相同的vector组成chunk. 执行器的输入，输出以chunk为单位。
chunk上的操作，最终都转为对每个vector的操作。因此没有特别要细说的。

## 小结
介绍vector的特点和主要接口的实现方式。

# 第五章 执行plan

## 简介
介绍物理查询计划执行原理。

整体结构：
- 向量化火山执行框架。
- 表达式执行器。
- 关系算子的实现。

## 执行框架
采用向量化火山执行模型。容易理解实现。

物理查询计划是一个物理算子树。

物理算子执行方式：
- 每次调用生成一批结果。
- 先执行子结点的算子，拿到一批结果。
- 利用子结点算子的结果，执行本结点算子。
- 生成本结点算子的一批结果
- 返回

算子执行接口及其实现Runner
```go
type OperatorExec interface {  
    Init() error  
    Execute(input, output *chunk.Chunk, 
	    state *OperatorState) (OperatorResult, error)  
    Close() error  
}

type Runner struct {
	op    *PhysicalOperator
	...
}

```

初始化执行框架：
- 为物理查询计划的根结点创建Runner对象。
- 递归初始化Runner.
	- 初始化子结点
	- 依据算子的类型，执行对应的init函数
```go
func (run *Runner) Init() error {  
	//step 1: 初始化子结点
    err := run.initChildren()  
    //step 2：初始化具体的算子
    switch run.op.Typ {  
    case POT_Scan:  
       return run.scanInit()  
    case POT_Project:  
       return run.projInit()  
    case POT_Join:  
       return run.joinInit()  
    case POT_Agg:  
       return run.aggrInit()  
    case POT_Filter:  
       return run.filterInit()  
    case POT_Order:  
       return run.orderInit()  
    case POT_Limit:  
       return run.limitInit() 
    }  
}

//初始化算子子结点
func (run *Runner) initChildren() error {  
    run.children = []*Runner{}  
    for _, child := range run.op.Children {  
	    //初始化算子子结点
       childRun := &Runner{  
          op:    child,  
          Txn:   run.Txn,  
          state: &OperatorState{},  
          cfg:   run.cfg,  
       }  
       err := childRun.Init()  
       run.children = append(run.children, childRun)  
    }  
    return nil  
}
```

类似，执行算子逻辑：
```go
func (run *Runner) Execute(input, output *chunk.Chunk, state *OperatorState) (OperatorResult, error) {  
	//step 1：初始化输出chunk
    output.Init(run.outputTypes, util.DefaultVectorSize)  
    //step 2：执行每种类型的算子
    switch run.op.Typ {  
    case POT_Scan:  
       return run.scanExec(output, state)  
    case POT_Project:  
       return run.projExec(output, state)  
    case POT_Join:  
       return run.joinExec(output, state)  
    case POT_Agg:  
       return run.aggrExec(output, state)  
    case POT_Filter:  
       return run.filterExec(output, state)  
    case POT_Order:  
       return run.orderExec(output, state)  
    case POT_Limit:  
       return run.limitExec(output, state)    
    }  
}

```


## 表达式执行器
表达式求值是算子执行的重要部分。几乎每个算子都需要对表达式求值。通常，表达式的值作为进一步运算的基础。初始化算子时，必须初始化需要的表达式执行器。

表达式执行器的组成部分：
- 表达式。一组要执行的表达式。
- 输入数据。
- 执行状态。中间值和结果。
	- 树形结构。与表达式的结构同构。
	- 组成部分：
		- 表达式
		- 子表达式的执行状态和数据类型
		- 子表达式的执行结果

```go

type ExprExec struct {  
    _exprs      []*Expr //表达式 
    _chunk      []*chunk.Chunk //输入数据 
    _execStates []*ExprExecState  //执行状态
}

type ExprExecState struct {  
    _root *ExprState  
    _exec *ExprExec  
}  

//执行状态
type ExprState struct {  
    _expr               *Expr  
    _execState          *ExprExecState  
    _children           []*ExprState  
    _types              []common.LType  
    _interChunk         *chunk.Chunk  
    _trueSel, _falseSel *chunk.SelectVector //for CASE WHEN  
}

```

### 初始化
表达式执行器初始化过程：
- 不停的向表达式执行器中增加表达式
- 为表达式初始化执行状态

表达式是一种递归结构。也需要递归初始化表达式的执行状态。
- 列引用，常数表达式。直接初始化。
- 函数
	- 初始化当前状态。
	- 再初始化子表达式的状态。

```go
func initExprState(expr *Expr, eeState *ExprExecState) (ret *ExprState) {
	switch typ{
	case column ref,constant expr:
		初始化执行状态；
	case 函数：
		初始化执行状态；
		初始化参数表达式的执行状态；
		
	}
	初始化子表达式的结果空间。
}

```

### 执行
两个入口：
- 常规入口。输入一组chunk，得出表达式的结果chunk。
- select入口。用于执行filter表达式。结果是那些行被留下，那些行被过滤掉

#### 常规入口

依次执行每个表达式。输入数据都是相同的。

```go
func (exec *ExprExec) executeExprs(data []*chunk.Chunk, result *chunk.Chunk) error {
	for i := 0; i < len(exec._exprs); i++ {  
	    err := exec.executeExprI(data, i, result.Data[i])  
	}
}

func (exec *ExprExec) executeExprI(data []*chunk.Chunk, exprId int, result *chunk.Vector) error {  
    exec._chunk = data  
    return exec.execute(  
       exec._exprs[exprId],  
       exec._execStates[exprId]._root,  
       nil,  
       cnt,  
       result,  
    )  
}
```

实质执行表达式，并得出结果的是execute函数。按表达式类型分别执行
- 列引用。从输入数据中取对应的列vector。
- 函数。细分为case...when和普通函数。
- 常数。取常数值。

列引用和常数简单，不细说。
```go
func (exec *ExprExec) execute(expr *Expr, eState *ExprState, sel *chunk.SelectVector, count int, result *chunk.Vector) error {  
    if count == 0 {  
       return nil  
    }  
    switch expr.Typ {  
    case 列引用:  
       return exec.executeColumnRef(expr, eState, sel, count, result)  
    case 函数:  
       if expr.SubTyp == ET_Case {  //case ... when
          return exec.executeCase(expr, eState, sel, count, result)  
       } else {  
          return exec.executeFunc(expr, eState, sel, count, result)  
       }  
    case 常数:  
       return exec.executeConst(expr, eState, sel, count, result)  
    }  
}

```

普通函数的执行（case...when是运算符。都用函数表达。除此之外的函数。）
- 执行参数表达式，获取参数值。
- 执行函数体，得到函数结果。函数体执行复杂后续专门讲。
```go
func (exec *ExprExec) executeFunc(expr *Expr, eState *ExprState, sel *chunk.SelectVector, count int, result *chunk.Vector) error {  
	//执行参数表达式
    for i, child := range expr.Children {  
       err = exec.execute(child,  //参数表达式
          eState._children[i],  //参数表达式的执行状态
          sel,  
          count,  
          eState._interChunk.Data[i])   //参数表达式结果
    }  

	//执行函数体。
	expr.FunImpl._scalar(eState._interChunk, eState, result)  
    return nil  
}

```

case...when的执行。不容易理解。
首先要理解case...when的执行过程：
- 输入数据为vector,有多行数据。vector的每行输入数据，
	- 逐个执行when表达式，直到其值为true. 此时，执行对应的then表达式。其结果为此行输入数据的计算结果。
	- 如果没有when表达式值为true。那么执行else表达式。其结果为此行输入数据的计算结果。
	- vector的不同行输入数据，对同一个when表达式，其结果可能不同。那么，每执行完一个when表达式。只需要在下一个when表达式上输入那些到目前为止都为false的行。
case...when的执行，需要用到select入口（下一节会讲，这里不细说）。
```go

func (exec *ExprExec) executeCase(expr *Expr, eState *ExprState, sel *chunk.SelectVector, count int, result *chunk.Vector) error {
	//step 1：
	逐个执行when表达式：
		tCnt, err := exec.execSelectExpr(  
		    when,  
		    whenState,  
		    curSel,  
		    curCount,  
		    curTrueSel,  
		    curFalseSel,  
		)
		if vector的所有行在此when表达式上都为true {
			对vector所有行执行then表达式，得出最终结果；
			返回；
		}else{
			对when表达式结果为true的行执行then表达式，得出这些行的最终结果；
			并且这些行不会再输入后续的when表达式；
		}
		到目前为止when表达式值都为false的行进入下一个when表达式；
		如果没有，执行结束；

	//step 2：情况
	//情况1：when表达式都执行完了。还有数据行在所有when表达式上都为false.
	//情况2：所有数据行都得出false.
	//或者上述一起发生
	//为false的数据行，输入else表达式，得出最终结果；
}

```

##### 函数体框架
参数值vector可能有多种物理表示。设计一套通用的函数体框架妥善表达函数实现，且兼顾性能和维护性。

这里仅考虑scalar函数的实现。聚合函数是不同的实现方案。

###### scalar函数

scalar函数的实现结构。以二元函数为例子，介绍其方案。

二元函数的抽象为下面的接口。左右参数和结果。`BinaryWrapper` 辅助对象接口，暂时不用关注。
```go
type BinaryOp[T any, S any, R any] func(left *T, right *S, result *R)

type BinaryWrapper[T any, S any, R any] interface {  
    operation(left *T, right *S, result *R, mask *util.Bitmap, idx int,  
       fun BinaryFunc[T, S, R])  
  
    addsNulls() bool  
}
```
再以加法为例。两个元素的加法实现：
```go
func addInt8(left, right, result *int8) {  
    *result = *left + *right  
}  
  
func addInt16(left, right, result *int16) {  
    *result = *left + *right  
}  
  
func addInt32(left, right, result *int32) {  
    *result = *left + *right  
}
...
```

二元函数框架，分为几层：
- 左右参数的物理表达。constant,flat,dict等
	- 左右都是constant
	- 左为constant,右为flat
	- 左为flat,右为constant
	- 左为flat,右为flat
	- 其他情况

参数意义：
- left,right 二元函数参数
- result 结果
- count 参数值个数
- fun 二元函数单行元素的实现
- wrapper 辅助类


 重点介绍`binaryExecFlat`和`binaryExecGeneric` 
```go
func binaryExecSwitch[T any, S any, R any](  
    left, right, result *chunk.Vector,  
    count int,  
    fun BinaryFunc[T, S, R],  
    wrapper BinaryWrapper[T, S, R],  
) {  
    if 左右都是constant {  
       binaryExecConst[T, S, R](...)  
    } else if 左为flat,右为constant {  
       binaryExecFlat[T, S, R](...,false, true)  
    } else if 左为constant,右为flat {  
       binaryExecFlat[T, S, R](..., true, false)  
    } else if 左为flat,右为flat {  
       binaryExecFlat[T, S, R](..., false, false)  
    } else {  
       binaryExecGeneric[T, S, R](...)  
    }  
}
```

####### `binaryExecFlat`的结构

参数意义：
- lconst,rconst。 左参数为constant。右参数为constant

优先处理NULL和Mask.

分类情况：
- 左参数constant且值为NULL。结果是NULL
- 右参数constant且值为NULL。结果是NULL
- 左参数constant。结果Mask是右参数的Mask
- 右参数constant。结果Mask是左参数的Mask
- 其它情况，结果Mask是左右参数的Mask的合并

```go
func binaryExecFlat[T any, S any, R any](  
    left, right, result *chunk.Vector,  
    count int,  
    fun BinaryFunc[T, S, R],  
    wrapper BinaryWrapper[T, S, R],  
    lconst, rconst bool,  
){
	//左参数constant且值为NULL 或 右参数constant且值为NULL，结果是NULL
	//左参数constant。结果Mask是右参数的Mask
	//右参数constant。结果Mask是左参数的Mask
	//其它情况，结果Mask是左右参数的Mask的合并
	binaryExecFlatLoop(...)
}


```

主体在函数`binaryExecFlatLoop`中完成。
参数意义：
- ldata,rdata,resData 左右参数、结果参数的数组。
- mask 参数NULL值

实现思路：
- 结果部分为NULL时，
	- 每8行一组。每组执行。
		- 全不为NULL时，每行数值，依次执行函数体
		- 全为NULL时，结果为NULL
		- 部分为NULL时，不为NULL的行，执行函数体
- 结果全不为NULL时，每行数值，依次执行函数体
```go
func binaryExecFlatLoop[T any, S any, R any](  
    ldata []T, rdata []S,  
    resData []R,  
    count int,  
    mask *util.Bitmap,  
    fun BinaryFunc[T, S, R],  
    wrapper BinaryWrapper[T, S, R],  
    lconst, rconst bool,  
) {
	if 结果部分为NULL {
		全不为NULL时，每行数值，依次执行函数体
		全为NULL时，结果为NULL
		部分为NULL时，不为NULL的行，执行函数体
	}else{
		结果全不为NULL时，每行数值，依次执行函数体
	}

}
```

####### `binaryExecGeneric`的结构

实现思路：左右参数转为`UnifiedFormat`。
函数主体在`binaryExecGenericLoop`。
函数参数比较多，参数意义：
- lsel,rsel。左右参数的select vector。
- lmask,rmask，resMask。左右参数mask和结果mask。

逻辑结构：
- 左参数不全为NULL。取有效行，计算结果。
- 右参数不全为NULL。取有效行，计算结果。
- 左右参数全不为NULL。取所有行，计算结果。

```go
func binaryExecGenericLoop[T any, S any, R any](  
    ldata []T, rdata []S,  
    resData []R,  
    lsel *chunk.SelectVector,  
    rsel *chunk.SelectVector,  
    count int,  
    lmask *util.Bitmap,  
    rmask *util.Bitmap,  
    resMask *util.Bitmap,  
    fun BinaryFunc[T, S, R],  
    wrapper BinaryWrapper[T, S, R],  
) {  
    if 左参数不全为NULL 或 右参数不全为NULL {  
       取有效行，计算结果。
       ...
	   wrapper.operation(&ldata[lidx], &rdata[ridx], &resData[i], resMask, i, fun)   ...
    } else {  
       //左右参数全不为NULL。
       取所有行，计算结果；
       ...
       wrapper.operation(&ldata[lidx], &rdata[ridx], &resData[i], resMask, i, fun)；   
       ...
    }  
}
```

一元函数与二元函数有类似的方案. 逻辑上要简化很多,这里不再细说.

#### select入口
用于执行filter表达式。得出那些filter值为true行。select执行后，返回值为true的select vector和值为true的个数。

根据运算符，区分执行过程：
- 比较运算符。=，<>,in,not in,<,<=,>,>=等
- and，or。

```go
func (exec *ExprExec) executeSelect(datas []*chunk.Chunk, sel *chunk.SelectVector) (int, error) {
	return exec.execSelectExpr(  
	    exec._exprs[0],  
	    exec._execStates[0]._root,  
	    nil,  
	    card,  
	    sel,  
	    nil,  
	)
}

func (exec *ExprExec) execSelectExpr(expr *Expr, eState *ExprState, sel *chunk.SelectVector, count int, trueSel, falseSel *chunk.SelectVector) (retCount int, err error) {  
    switch expr.Typ {  
    case 函数:  
       switch expr.SubTyp {  
       case 比较运算符:  
          return exec.execSelectCompare(expr, eState, sel, count, trueSel, falseSel)  
       case and运算符:  
          return exec.execSelectAnd(expr, eState, sel, count, trueSel, falseSel)  
       case or运算符:  
          return exec.execSelectOr(expr, eState, sel, count, trueSel, falseSel)  
       } 
    }  
}

```

##### 比较运算符框架
这里仅考虑二元比较运算符。

`execSelectCompare`为比较运算符的执行入口。两个参数值vector的物理表示可能不同。为它们设计一套执行框架。

执行框架的结构：
- 入口分类：函数`selectOperation`。分类的目的是要确定运算符在特定数据类型下的具体实现。
	- 第一层：运算符类型
	- 第二层：数据类型。在bind阶段已经保证左右参数的数据类型相同。
- 左右参数不同物理表示的分类：函数`selectBinary`。分类的目的是根据两种物理表示的组合选择合适的比较运算符的实现。
	- 左右都是constant。函数`selectConst`。
	- 左是constant，右是flat。函数`selectFlat`。
	- 左是flat，右是constant。函数`selectFlat`。
	- 左是flat，右是flat。函数`selectFlat`。
	- 其它组合。函数`selectGeneric`。
- 比较逻辑的实现方案：
	- `selectConst`
	- `selectFlat`
	- `selectGeneric`
```go
func selectOperation(left, right *chunk.Vector, sel *chunk.SelectVector, count int, trueSel, falseSel *chunk.SelectVector, subTyp ET_SubTyp) int {
	switch subTyp {
    case ET_Equal://相等运算符
       switch left.Typ().GetInternalType() {
        case common.INT32:
            return selectBinary[int32](left, right, sel, count, trueSel, falseSel, equalOp[int32]{})
        case ...://其它数据类型
	    }
	case ...://其它运算符
    }
}

func selectBinary[T any](left, right *chunk.Vector, sel *chunk.SelectVector, count int, trueSel, falseSel *chunk.SelectVector, cmpOp CompareOp[T]) int {
    if sel == nil {
        sel = chunk.IncrSelectVectorInPhyFormatFlat()
    }

    if 左右都是constant {
        return selectConst[T](left, right, sel, count, trueSel, falseSel, cmpOp)
    } else if 左是constant，右是flat {
        return selectFlat[T](left, right, sel, count, trueSel, falseSel, cmpOp, true, false)
    } else if 左是flat，右是constant {
        return selectFlat[T](left, right, sel, count, trueSel, falseSel, cmpOp, false, true)
    } else if 左是flat，右是flat {
        return selectFlat[T](left, right, sel, count, trueSel, falseSel, cmpOp, false, false)
    } else {//其它组合
        return selectGeneric[T](left, right, sel, count, trueSel, falseSel, cmpOp)
    }
}
```

###### selectFlat
 
 参数意义：
 - left，right：运算数
 - sel：输入参数的选择器
 - count：运算数的个数
 - trueSel, falseSel：分别记录结果为true，false的选择器
 - cmpOp：运算符的具体实现
 - leftConst, rightConst：左右运算数哪个为常数

 逻辑结构：
 - 分支：左参数 全是NULL。结果全是false。
 - 分支：右参数 全是NULL。类似。
 - 分支：左参数是constant。
 - 分支：右参数是constant。
 - 分支：左、右参数都不是constant。
后面三种情况都是由函数`selectFlatLoopSwitch`完成。

```go
func selectFlat[T any](
	left, right *chunk.Vector,
    sel *chunk.SelectVector,
    count int,
    trueSel, falseSel *chunk.SelectVector,
    cmpOp CompareOp[T],
    leftConst, rightConst bool) int {

	if 左参数 全是NULL {
		...
	}

	if 右参数 全是NULL {
		...
	}

	if 左参数是constant {
		return selectFlatLoopSwitch[T](
			...
            chunk.GetMaskInPhyFormatFlat(right),...)
	}else if 右参数是constant {
        return selectFlatLoopSwitch[T](
	        ...
            chunk.GetMaskInPhyFormatFlat(left),...)
	}else{
		//左、右参数都不是constant
        merge := chunk.GetMaskInPhyFormatFlat(left)
        rMask := chunk.GetMaskInPhyFormatFlat(right)
        merge.Combine(rMask, count)
        return selectFlatLoopSwitch[T](
			...
            merge,...)
	}
}
```

`selectFlatLoopSwitch`的逻辑结构：
- 既保留true的结果，又保留false的结果
- 保留true的结果
- 保留false的结果

具体实现基于函数`selectFlatLoop`。
```go
func selectFlatLoopSwitch[T any](
    ldata, rdata []T,
    sel *chunk.SelectVector,
    count int,
    mask *util.Bitmap,
    trueSel, falseSel *chunk.SelectVector,
    cmpOp CompareOp[T],
    leftConst, rightConst bool) int {
    if trueSel != nil && falseSel != nil {
        return selectFlatLoop[T](
			...
			true, true)
    } else if trueSel != nil {
        return selectFlatLoop[T](
			...
            true, false)
    } else {
        return selectFlatLoop[T](
			...
            false, true)
    }
}
```

`selectFlatLoop`与`selectFlat` 不同的参数的意义：
- ldata, rdata。参数数组。
- mask。左参数的mask与右参数的mask组合后的mask，表示最终的NULL情况。
- hasTrueSel, hasFalseSel。trueSel是否为nil。falseSel是否为nil。

`selectFlatLoop`的实现思路
- 8行一组。依次处理每个组。组内结果行的情况：全不是NULL,全是NULL,部分是NULL.
- 全不是NULL
	- 取每行的两个参数值
	- 执行运算符：`res := cmpOp.operation(&ldata[lidx], &rdata[ridx])`。
	- 结果为true,记录true的行。结果为false,记录false的行。
- 全是NULL
	- 结果全是false。记录所有行为false值。
- 部分是NULL
	- 只取有效行的两个参数值。
	- 执行运算符：`res := cmpOp.operation(&ldata[lidx], &rdata[ridx])`。
	- 结果为true,记录true的行。结果为false,记录false的行。
- 返回值：
	- 如果有trueSel,返回true的行数。
	- 如果没有trueSel,返回非false的行数。

```go
func selectFlatLoop[T any](  
    ldata, rdata []T,  
    sel *chunk.SelectVector,  
    count int,  
    mask *util.Bitmap,  
    trueSel, falseSel *chunk.SelectVector,  
    cmpOp CompareOp[T],  
    leftConst, rightConst bool,  
    hasTrueSel, hasFalseSel bool,  
) int {  
    trueCount, falseCount := 0, 0  
    baseIdx := 0  
    entryCount := util.EntryCount(count)  
    //按8行分组。
    for eidx := 0; eidx < entryCount; eidx++ {  
       entry := mask.GetEntry(uint64(eidx))  
       next := min(baseIdx+8, count)  
       if 全不是NULL {  
          //all valid: perform operation  
          for ; baseIdx < next; baseIdx++ {  
             取每行的两个参数值； 
             res := cmpOp.operation(&ldata[lidx], &rdata[ridx])  
             ...
             trueSel.SetIndex(trueCount, resIdx)  
             ...
             falseSel.SetIndex(falseCount, resIdx)  
             ...
          }  
       } else if 全是NULL {  
	      ...
          falseSel.SetIndex(falseCount, resIdx)  
          ...
          continue  
       } else {  
          //部分是NULL
          start := baseIdx  
          for ; baseIdx < next; baseIdx++ {  
             只取有效行的两个参数值;
             res := util.RowIsValidInEntry(entry, uint64(baseIdx-start)) &&  
                cmpOp.operation(&ldata[lidx], &rdata[ridx])  
             ...
             trueSel.SetIndex(trueCount, resIdx)  
             ...
             falseSel.SetIndex(falseCount, resIdx)  
             ...  
          }  
       }  
    }  
	如果有trueSel,返回true的行数。
	如果没有trueSel,返回非false的行数。
}
```

###### selectGeneric

比较运算逻辑的通用处理方式。

参数意义：
 - left，right：运算数
 - sel：输入参数的选择器
 - count：运算数的个数
 - trueSel, falseSel：分别记录结果为true，false的选择器
 - cmpOp：运算符的具体实现

`selectGeneric` 依据参数类型也分为好几层。

第一层，vector转UnifiedFormat：
- left,right 转成UnifiedFormat。UnifiedFormat的重要内容：数值数组、选择器和Mask。
- 调用下一层接口：`selectGenericLoopSwitch`

```go
func selectGeneric[T any](left, right *chunk.Vector, sel *chunk.SelectVector, count int, trueSel, falseSel *chunk.SelectVector, cmpOp CompareOp[T]) int {  
    var ldata, rdata chunk.UnifiedFormat  
    left.ToUnifiedFormat(count, &ldata)  
    right.ToUnifiedFormat(count, &rdata)  
    lslice := chunk.GetSliceInPhyFormatUnifiedFormat[T](&ldata)  
    rslice := chunk.GetSliceInPhyFormatUnifiedFormat[T](&rdata)  
    return selectGenericLoopSwitch[T](...)  
}
```

第二层，按mask的NULL值情况进行分类：
- 左参数部分为NULL、或右参数部分为NULL
- 全不为NULL
```go
func selectGenericLoopSwitch[T any](  
    ldata, rdata []T,  
    lsel, rsel *chunk.SelectVector,  
    resSel *chunk.SelectVector,  
    count int,  
    lmask, rmask *util.Bitmap,  
    trueSel, falseSel *chunk.SelectVector,  
    cmpOp CompareOp[T]) int {  
    if !lmask.AllValid() || !rmask.AllValid() {  
       return selectGenericLoopSelSwitch[T](..., false)  
    } else {// 全不为NULL
       return selectGenericLoopSelSwitch[T](..., true)  
    }  
}
```

第三层，按trueSel是否为nil和falseSel是否为nil再分类
- trueSel不为nil和falseSel不为nil
- trueSel不为nil
- 其它情况
```go
func selectGenericLoopSelSwitch[T any](  
    ldata, rdata []T,  
    lsel, rsel *chunk.SelectVector,  
    resSel *chunk.SelectVector,  
    count int,  
    lmask, rmask *util.Bitmap,  
    trueSel, falseSel *chunk.SelectVector,  
    cmpOp CompareOp[T],  
    noNull bool,  
) int {  
    if trueSel != nil && falseSel != nil {  // trueSel不为nil和falseSel不为nil
       return selectGenericLoop[T](  
	      ...,
          true, true,  
       )  
    } else if trueSel != nil {  
       return selectGenericLoop[T](  
          ...,  
          true, false,  
       )  
    } else {  
       return selectGenericLoop[T](  
          ...,  
          false, true,  
       )  
    }  
}
```

第四层，实际比较逻辑
- 取参数值，检查NULL情况。
- 执行运算符
- 返回值：
	- 如果有trueSel, 返回true的行数。
	- 如果没有trueSel, 返回非false的行数。
```go
func selectGenericLoop[T any](  
    ldata, rdata []T,  
    lsel, rsel *chunk.SelectVector,  
    resSel *chunk.SelectVector,  
    count int,  
    lmask, rmask *util.Bitmap,  
    trueSel, falseSel *chunk.SelectVector,  
    cmpOp CompareOp[T],  
    noNull bool,  
    hasTrueSel, hasFalseSel bool,  
) int {  
    for i := 0; i < count; i++ {  
       if (noNull || 
	       lmask.RowIsValid(uint64(lidx)) && 
	       rmask.RowIsValid(uint64(ridx))) &&  
          cmpOp.operation(&ldata[lidx], &rdata[ridx]) {  
          ...
          trueSel.SetIndex(trueCount, resIdx)  
          ...
       } else {  
		  ...
          falseSel.SetIndex(falseCount, resIdx)  
          ...
       }  
    }  
	如果有trueSel,返回true的行数。
	如果没有trueSel,返回非false的行数。
}

```

###### 比较运算符

在上面的执行框架上，对运算符和数据类型，实现相应的逻辑。

比较运算符接口：
```go
type CompareOp[T any] interface {  
    operation(left, right *T) bool  
}
```

举相等运算符为例子。
```go
//可直接比较的数值数据类型
type equalOp[T comparable] struct {  
}  
  
func (e equalOp[T]) operation(left, right *T) bool {  
    return *left == *right  
}

//字符串类型
type equalStrOp struct {  
}  
  
func (e equalStrOp) operation(left, right *common.String) bool {  
    return left.Equal(right)  
}

func (s *String) Equal(o *String) bool {  
    if s.Len != o.Len {  
       return false  
    }  
    sSlice := util.PointerToSlice[byte](s.Data, s.Len)  
    oSlice := util.PointerToSlice[byte](o.Data, o.Len)  
    return bytes.Equal(sSlice, oSlice)  
}
```


##### 逻辑运算符

###### and运算符

输入是true/false,输出也是true/false。

逻辑与有短路特性。只要碰到false,计算结果一定是false,计算过程结束。
借助true select vector实现这种短路特性。

实现方案：
- 计算第一个子表达式。计算结果有两个：`trueCount`- true的个数；`trueSel`-结果为true的行。
- 从第二个子表达式开始，计算的输入是：前一个子表达式的计算结果`trueCount`和`trueSel`。因为短路特性，只需要前一个子表达式的计算结果为true的行。
- 如此，直到结果都是false或子表达式都计算完。

```go
func (exec *ExprExec) execSelectAnd(expr *Expr, eState *ExprState, sel *chunk.SelectVector, count int, trueSel, falseSel *chunk.SelectVector) (int, error) {  
    var err error  
    curSel := sel  
    curCount := count  
    falseCount := 0  
    trueCount := 0  
	...
    for i, child := range expr.Children {  
       //计算第i个子表达式
       trueCount, err = exec.execSelectExpr(child,  
          eState._children[i],  
          curSel,  
          curCount,  
          trueSel,  
          tempFalse)  
       //结果为false的行个数
       fCount := curCount - trueCount  
       if fCount > 0 && falseSel != nil {  
          //记录结果为false的行
          ...
          falseSel.SetIndex(falseCount, tempFalse.GetIndex(j))
          ...
       }  
       //结果为true的行个数
       curCount = trueCount  
       if curCount == 0 {  
          break  
       }  
       //还有结果为true的行，进入下一轮计算
       if curCount < count {  
          curSel = trueSel  //为true的行，才需要进入下一轮计算
       }  
    }  
	//返回结果为true的行个数
    return curCount, nil  
}

```

###### or运算符

逻辑或有短路特性。只要碰到true,计算结果一定是true,计算过程结束。
借助false select vector实现这种短路特性。

实现方案：
- 计算第一个子表达式。计算结果有两个：`trueCount`- true的个数；`falseSel`-结果为false的行。
- 从第二个子表达式开始，计算的输入是：前一个子表达式的计算结果`falseCount`和`falseSel`。因为短路特性，只需要前一个子表达式的计算结果为false的行。
- 如此，直到结果都是true或子表达式都计算完。

```go
func (exec *ExprExec) execSelectOr(expr *Expr, eState *ExprState, sel *chunk.SelectVector, count int, trueSel, falseSel *chunk.SelectVector) (int, error) {  
    var err error  
    curSel := sel  
    curCount := count  
    resCount := 0  
    trueCount := 0  
    ...
    for i, child := range expr.Children {  
	   //计算第i个子表达式
       trueCount, err = exec.execSelectExpr(  
          child,  
          eState._children[i],  
          curSel,  
          curCount,  
          tempTrue,  
          falseSel)  
       //结果行为true的行个数
       if trueCount > 0 {  
          if trueSel != nil {  
             //记录结果为true的行
             ...
             trueSel.SetIndex(resCount, tempTrue.GetIndex(j))  
             ...  
          }  
          //false count
          curCount -= trueCount  
          //结果为false的数据行
          curSel = falseSel  
       }  
    }  
	//返回结果为true的行个数
    return resCount, nil  
}
```
## 算子
优先介绍最复杂的算子:agg, order, join. 详解他们的实现方案.

### agg

在深入具体实现之前，先明确一些必要的概念：
- group by表达式。select语句中提供的。
- grouping set。常规的是仅对group by分组聚合。如果要在同一个select语句中，对多个不同子分组分别聚合，用grouping set表达。

例子：
```sql
SELECT city, street_name, avg(income) 
FROM addresses 
GROUP BY GROUPING SETS ((city, street_name), (city), (street_name), ());
```

agg整体执行过程：
- 构建hash表阶段
- 取聚合结果阶段
```go
func (run *Runner) aggrExec(output *chunk.Chunk, ,,,) {
	if 构建hash表阶段 {
		for {
			//读取子节点数据
			childChunk := &chunk.Chunk{}
			res, err = run.execChild(run.children[0], childChunk, state)
			...
			//准备表达式
			err = run.state.groupbyWithParamsExec.executeExprs(
			[]*chunk.Chunk{childChunk, nil, nil}, groupChunk)
			...
			//构建hash表
			run.hAggr.Sink(groupChunk)
		}
	}else{
		//取聚合结果
		for {
			...
			//取聚合结果
			res = run.hAggr.GetData(
				run.state.haScanState, groupAndAggrChunk, childChunk)
			...
			//过滤
			count, err = state.filterExec.executeSelect(
			[]*chunk.Chunk{childChunk, nil, filterInputChunk}, state.filterSel)
			...
			//计算输出值
			err = run.state.outputExec.executeExprs(
			[]*chunk.Chunk{childChunk2, nil, aggrStatesChunk3}, output)
		}
	}
}
```

hash聚合整体实现阶段：
- 初始化。设计数据结构和数据组织方式。
- 填充数据。构建hash表阶段。存储数据。更新聚合函数中间值。
- 用数据。hash表构建完成后。上层算子获取聚合函数的值。

#### 初始化

先看需要哪些内容初始化agg算子。
输入参数：
- agg算子的输出值类型。
- 聚合函数表达式。agg算子要计算的聚合函数。
- group by表达式。分组的依据
- grouping set。group by表达式的再分子分组。每个子分组的实现形式是一样的。
- 子节点的输出值表达式。


agg算子复杂，涉及多个数据结构，容易弄混。初始化过程分为多个层次。需要按层次理解关联的数据结构和初始化过程。

agg管理结构的层次：第一、二层为逻辑结构。第三层为物理结构。
- 第一层：HashAggr。agg最顶层结构。管理一个agg算子的所有内容。一个plan里面有多个agg算子，会有多个HashAggr对象。
- 第二层：相关表达式和存储方式
	- 全局GroupedAggrData。在整个aggr算子中共享。
		- group by表达式 及其类型
		- agg表达式及其参数类型，返回值类型。
		- 子节点输出表达式。
	- DistinctAggrCollectionInfo。distinct聚合函数信息。在整个aggr算子中共享。
		- distinct聚合表达式的index。
	- HashAggrGroupingData。每个grouping set关联的聚合结果
		- RadixPartitionedHashTable。聚合结果包装层。
			- GroupedAggrHashTable。存储聚合结果
		- DistinctAggrData。为每个distinct聚合函数单独存储数据。
			- GroupedAggrData。每个distinct聚合函数关联的groupby,agg,子节点表达式。
			- RadixPartitionedHashTable。每个distinct聚合函数的聚合结果
- 第三层：用行层存储聚合结果
	- GroupedAggrHashTable 存储聚合结果。
		- TupleDataCollection。列存转行存存储。
			- TupleDataLayout。行存的存储格式。
			- TupleDataSegment。行存的实际数据block地址。
		- 哈希表。存储的数据的blockid和block的位置。

关键的数据结构：
- HashAggr
- GroupedAggrData
- DistinctAggrCollectionInfo
- HashAggrGroupingData
- RadixPartitionedHashTable
- GroupedAggrHashTable
- TupleDataCollection
- TupleDataLayout
- TupleDataSegment
- DistinctAggrData

agg算子的初始化实质是构建上述三层结构的关联的数据结构对象。具体每个数据结构有哪些字段，字段的意义，在对agg算子处理数据的过程中来介绍。


#### 输入数据

整体过程：
- 从子节点读取一批数据。
- 数据预处理。计算一些表达式，转化成agg算子需要的输入数据。
- 如果有distinct。数据先进入distinct的逻辑。
- 数据进入hash聚合逻辑。

第一步简单。重点介绍后面的环节。

##### 数据预处理

输入：
- 子节点的输出数据。

输出数据的组织形式，有很多列，分为几段：
- 第一段：group by表达式的值。计算每个group by表达式，得出值。
- 第二段：每个聚合函数输入参数表达式的值。计算每个聚合函数输入参数表达式，得出值。
- 第三段：子节点的输出数据。复制子节点的输出数据。

输出数据组织成一个chunk，每个vector对应上面的一列数据。
```go

group by 0,...,aggr 0 param 0,...,child ouput 0,....

```

##### hash聚合逻辑

聚合逻辑的数据输入入口：
```go
func (haggr *HashAggr) Sink(data *chunk.Chunk) {
	//准备数据
	...
	//处理distinct
	if haggr._distinctCollectionInfo != nil {
		haggr.SinkDistinct(
			data, 
			childrenOutput)
	}

	//处理各个grouping set
	for _, grouping := range haggr._groupings {	
		grouping._tableData.Sink(
			data, 
			payload, 
			childrenOutput, 
			haggr._nonDistinctFilter)
	}
}
```


内部分为三个部分：
- 准备数据。从输入chunk中分离出数据（目前的处理方式不好，有些冗余）
	- payload。聚合函数参数表达式的值。
	- childrenOutput。子节点的输出数据。
- 处理distinct。下一节再讲
- 处理每个grouping set 的聚合。数据经过几层接口进入聚合逻辑。
	- RadixPartitionedHashTable.Sink。
		- 第一次进入时，初始化哈希表和物理组织结构。
		- 分离group by 表达式的值。
		- GroupedAggrHashTable.AddChunk2。
			- 计算group by表达式的值的哈希值。一行值算一个哈希值。因为要按group by表达式的值分组。
			- GroupedAggrHashTable.AddChunk。
				- GroupedAggrHashTable.FindOrCreateGroups。按group by表达式的值进行分组。
				- UpdateStates。更新每个聚合函数的中间状态。

重点介绍数据分组和更新中间状态。
###### 数据分组
`FindOrCreateGroups`完成数据分组功能。

参数：
- groups。group by 表达式的值
- groupHashes。group by表达式的值的哈希值
- addresses。函数返回后，每个组的首地址。
- newGroupsOut。产生的新组。
- childrenOutput。子节点的输出数据。

整体过程：
- 哈希表的扩容（可能）。线性探测法解决冲突。后面会单独讲哈希表的组织方式。
- 从group by哈希值提取。
	- offset。哈希表桶号。`offset = hash % capacity`
	- salt。哈希值的前缀。用于快速判断。`salt = hash >> _hashPrefixShift`。\
- 复合输入数据：作为后续处理的输入。
	- group by 表达式的值。
	- group by hash值。
	- childrenOutput。
	- 复合数据转为UnifiedFormat。方便后续处理。
- 分组逻辑：线性探测法，可能需要多轮扫哈希表。
	- 每轮的逻辑
		- 探测哈希表。有三种结果：
			- 新组。并同时占用空闲hash表元素。
			- salt值相同。需要进一步比较分组值。仅salt值相同，不能完全断定分组值也相同。
			- 没有匹配。由于是线性探测法，不能立即说此值不存在。要移动到下一个位置继续探测。
		- 对`新组`的处理：（后面会单独讲每块内容）
			- 为新组分配存储空间
			- 初始化聚合中间状态
			- 更新哈希表
		- 对`需要再比较分组值`的处理：
			- 取出要进一步比较的存储地址
			- 执行比较逻辑
		- 对`没有匹配`的处理：
			- 指向hash表下一个位置
			- 进入下一轮测试


####### 处理`新组`

agg的聚合状态数据是以行存的形式存储。列存数据要先转行存。先介绍这一转换过程。

先说行存的数据格式。`TupleDataLayout`表示行存的格式。
放进行存的数据有：
- group by 表达式的值。可能多个。非定长字段，保留堆指针。
- 子节点的输出数据。可能多个。非定长字段，保留堆指针。
- 聚合函数中间状态。可能多个。在讲聚合函数实现时再讲。
- bitmap。放NULL值。表示group by表达式和子节点输出数据的NULL值情况。
- heap size。堆空间大小。行中有非定长字段时，需要在堆上分配空间存储溢出的数据。 

`TupleDataLayout` 除了在agg算子中会用到。也用在join算子中。有些数据是可能不存在的。
数据布局: 
- heap size。可选。全是定长字段，无此值。
- 子节点的输出数据。可选
- 聚合函数中间状态。可选
```go

bitmap | heap_size? | group by...| 子节点的输出数据? | 聚合函数中间状态? |

```


**为新组分配存储空间**

入口函数`TupleDataCollection.AppendUnified`。

整体过程：
- 如果有非定长字段，计算heap size
- 为行分配空间
- 填充group by 表达式的值
- 填充子节点的输出数据

1. **heap size计算过程**

两层循环，外层对每列遍历，内层对每列的每一行计算heap size。
因为非定长字段，每一行的数据长度都不同。也就是说，在堆上，变长字段是依次排列。目前支持的变长数据类型是`VARCHAR`。
如果此行非NULL，加上字符串长度。
```go
func (tuple *TupleDataCollection) computeHeapSizes(...) {

	//外层
	//对group by表达式值的每列
	for i := 0; i < data.ColumnCount(); i++ {
		tuple.evaluateHeapSizes(state._heapSizes, data.Data[i], &state._data[i], appendSel, cnt)
	}
	
	//对的子节点的输出数据的每列
	for i := 0; i < childrenOutput.ColumnCount(); i++ {
		colIdx := state._childrenOutputIds[i]
		tuple.evaluateHeapSizes(state._heapSizes, childrenOutput.Data[i], &state._data[colIdx], appendSel, cnt)
	}
}

//内层
func (tuple *TupleDataCollection) evaluateHeapSizes(...) {
	//only care varchar type
	switch pTyp {
	case common.VARCHAR:
		//计算列的每行
		srcSlice := chunk.GetSliceInPhyFormatUnifiedFormat[common.String](srcUni)
		for i := 0; i < cnt; i++ {
			srcIdx := srcSel.GetIndex(appendSel.GetIndex(i))
			if srcMask.RowIsValid(uint64(srcIdx)) {
				heapSizeSlice[i] += uint64(srcSlice[srcIdx].Length())
			} else {
				heapSizeSlice[i] += uint64(common.String{}.NullLen())
			}
		}
	}
}
```

2. **行存空间组织和内存分配**

空间组织：
- TupleDataSegment。至少1个（目前实现只有1个）。
	- TupleDataChunk。每个TupleDataSegment中至少1个。
		- 记录最多2048行。与单个vector的行数对应。
		- TupleDataChunkPart。记录部分行。每个TupleDataChunk中至少1个。
			- 记录内存block的地址。
			- block上的行数
- TupleDataAllocator。内存block分配器。记录已经分配的内存block。
	- TupleDataBlock。内存block的句柄，内存空间使用量，内存总容量。
	

内存分配过程：
- 遍历输入的每一行，为其计算空间：
	- 判断当前TupleDataChunk是否满，满了创建新的TupleDataChunk。
	- 计算当前TupleDataChunk能放的行数
	- 为这些行分配空间TupleDataChunkPart
		- 判断当前TupleDataBlock是否能放下至少一行数据。如果满了，分配新TupleDataBlock。
		- 后续逻辑，整体是确定TupleDataChunPart的关键字段的值
			- 固定行的空间。
				- `_rowBlockIdx` block索引。
				- `_rowBlockOffset` block中的地址偏移
			- 变长字段的空间。
				- `_heapBlockIdx` block索引
				- `_heapBlockOffset` block中的地址偏移
				- `_baseHeapPtr` 内存基地址
				- `_totalHeapSize` 堆空间总大小。
			- `_count` 总行数
		- 分配空间过程：
			-  `_rowBlockIdx`  = 当前TupleDataBlock的索引
			- `_rowBlockOffset` =  当前TupleDataBlock的剩余空间偏移
			- `_count` = 当前TupleDataBlock的剩余空间最多能放的行数
			- 对于不定长的字段：
				- 计算总heap size。 `_count` 行的heap size的总和
				- 如果当前的heap block空间够（也是TupleDataBlock），直接分配。确定`_heapBlockIdx`和`_heapBlockOffset`的值。 否则，分配新heap block再分配。里面有些优化细节，不细说。
				- 计算`_baseHeapPtr` 基地址。
	- 记录TupleDataChunk的索引，以及TupleDataChunkPart的索引
- 确定每一行的首地址。分配的TupleDataChunkPart记录的是一批行的首地址。要将每一行的首地址算出来。
	- 对每个分配的TupleDataChunkPart
		- 计算每行的首地址
		- 如果用到heap，计算每行的heap首地址
	  

函数调用关系：
- TupleDataCollection.Build 入口
	- TupleDataAllocator.Build 分配多个block
		- TupleDataAllocator.BuildChunkPart 分配单个block和heap空间
		- TupleDataAllocator.InitChunkStateInternal 计算每行首地址

```go
func (tuple *TupleDataCollection) Build(...
	) {
	...
	seg._allocator.Build(seg, pinState, chunkState, appendOffset, appendCount)
	...
}

func (alloc *TupleDataAllocator) Build(...
	) {


	offset := uint64(0)	
	//分配空间
	for offset != appendCount {
		...
		//当前TupleDataChunk
		chunk := util.Back(segment._chunks)
		
		//count of rows can be recorded
		next := min(
			appendCount-offset,
			util.DefaultVectorSize-chunk._count,
		)
		
		  
		//分配TupleDataChunkPart
		//allocate space for these rows
		part := alloc.BuildChunkPart(
			pinState,	
			chunkState,		
			appendOffset+offset,
			next,
		)
		
		chunk.AddPart(part, alloc._layout)
		。。。
		chunkPart := util.Back(chunk._parts)
		next = uint64(chunkPart._count)	
		segment._count += next
		offset += next
	}
	...
	//decide the base ptr of rows
	//计算每行的首地址
	alloc.InitChunkStateInternal(
		pinState,
		chunkState,
		appendOffset,
		....
		parts,
	)
}


func (alloc *TupleDataAllocator) BuildChunkPart(...
	) *TupleDataChunkPart {
	//当前的block idx
	result._rowBlockIdx = uint32(len(alloc._rowBlocks) - 1)
	rowBlock := util.Back(alloc._rowBlocks)
	//block offset
	result._rowBlockOffset = uint32(rowBlock._size)
	//block 能放的行数
	result._count = uint32(min(
	rowBlock.RemainingRows(uint64(alloc._layout.rowWidth())),appendCount))
	if !alloc._layout.allConst() {
		//分配heap 空间
		...
	}
}
```

3. **填充数据**

向行存空间中，填充group by 表达式的值和子节点的输出数据。
实质是将每个vector的每行填到对应的位置。
- 确定每行首地址
- 确定列在行的偏移。在`TupleDataLayout`中。
- 将列的值填到偏移位置处。

函数关系：
- TupleDataCollection.scatter 入口。计算非定长字段的堆内存地址
	- TupleDataCollection.scatterVector 包装器
		- TupleDataTemplatedScatterSwitch 数据类型switch
			- TupleDataTemplatedScatter 取每行的值，并填充
				- TupleDataValueStore 将值填到偏移处

```go

func (tuple *TupleDataCollection) scatter(...){
	...
	if !tuple._layout.allConst() {
		//非定长计算堆内存地址
		heapSizeOffset := tuple._layout.heapSizeOffset()
		heapSizes := chunk.GetSliceInPhyFormatFlat[uint64](state._heapSizes)
		for i := 0; i < cnt; i++ {
			util.Store[uint64](heapSizes[i], util.PointerAdd(rowLocations[i], heapSizeOffset))
		}
	}
	...
	//处理每列
	for i, coldIdx := range state._columnIds {
		tuple.scatterVector(state, data.Data[i], coldIdx, appendSel, cnt)
	}
}

func (tuple *TupleDataCollection) scatterVector(...){
	TupleDataTemplatedScatterSwitch(...)
}

func TupleDataTemplatedScatterSwitch(...){
	pTyp := src.Typ().GetInternalType()
	switch pTyp {
	case common.INT32:
		TupleDataTemplatedScatter[int32](
			...		
		)
	
	case common.INT64:
	...
	case common.UINT64:
	...
	case common.VARCHAR:
	...
	case common.INT8:
	...
	case common.DECIMAL:
	...
	case common.DATE:
	...
	case common.DOUBLE:
	...
	case common.INT128:
	...
	default:
	}
}

func TupleDataTemplatedScatter[T any](...){
	...
	//填充每行
	for i := 0; i < cnt; i++ {
		srcIdx := srcSel.GetIndex(appendSel.GetIndex(i))
		//值，行首地址，行内偏移
		TupleDataValueStore[T](srcSlice[srcIdx], targetLocs[i], offsetInRow, &targetHeapLocs[i], nVal)
	}
	...
}
```


**初始化聚合函数状态**

为每个聚合函数维护状态值。在新建分组时，初始化这些状态。这里仅介绍初始化过程，聚合函数实现细节，会在后面介绍聚合函数实现方案时，再细讲。

初始化过程：
- 对每个聚合函数对象，并对每行
	- 确定每行首地址
	- 确定状态在行的偏移。在`TupleDataLayout`中。
	- 在偏移位置处，执行聚合函数对象init函数。

```go

func InitStates(...) {  
	pointers := chunk.GetSliceInPhyFormatFlat[unsafe.Pointer](addresses)
	offsets := layout.offsets()
	aggrIdx := layout.aggrIdx()
	//每个聚合函数对象
	for _, aggr := range layout._aggregates {
		//对每行
		for i := 0; i < cnt; i++ {
			rowIdx := sel.GetIndex(i)
			//行首地址
			row := pointers[rowIdx]
			//init函数
			aggr._func._init(util.PointerAdd(row, offsets[aggrIdx]))
		}
		aggrIdx++
	}
}

```


**更新哈希表**

每组的内存分配后，将block和偏移信息填到每组关联哈希表元素中。后续使用时，只需查询哈希表就能拿到block和偏移信息。

```go

//每组首地址
rowLocations := chunk.GetSliceInPhyFormatFlat[unsafe.Pointer](state._chunkState._rowLocations)

for j := 0; j < newEntryCount; j++ {
	rowLoc := rowLocations[j]
	确定rowLock的block id
	...
	idx := state._emptyVector.GetIndex(j)
	//哈希表元素
	htEntry := &htEntrySlice[htOffsetsPtr[idx]]
	//block id和偏移 回填哈希表元素
	htEntry._pageNr = uint32(blockId + 1)
	htEntry._pageOffset = uint16(util.PointerSub(rowLoc, blockPtr) / int64(aht._tupleSize))
	//记录行地址
	addresessSlice[idx] = rowLoc
}
```

####### 处理`需要再比较分组值`

hash值的salt相同，但是不能确定两组group by表达式的值相同。需要再比较它们的值。

再比较两组值：
- 第一组值：新输入的vector
- 第二组值：已经在行存中的值

计算过程：
- 确定第二组值的行首地址
- 对每一列，对每一行
	- 从vector中取出 第一组值
	- 第二组值 在行存的位置 = 行首地址 + 偏移
	- 对比 第一组值 和 第二组值

函数关系：
- Match 函数入口
	- TemplatedMatch 对每列进行比较
		- TemplatedMatchOp 按照数据类型区分。
			- TemplatedMatchType 对每行比较两组值

```go
func Match(...){
	TemplatedMatch(...)
}

func TemplatedMatch(...){
	//每列
	for i := 0; i < len(predicates); i++ {
		vec := columns.Data[i]
		col := colData[i]
		TemplatedMatchOp(...)
	}
}

func TemplatedMatchOp(...){
	colOffset := layout.offsets()[colNo]
	//区分类型
	switch predTyp {
	case ET_Equal, ET_In:
		pTyp := layout.types()[colNo].GetInternalType()
		switch pTyp {
		case common.INT32:
			TemplatedMatchType[int32](...)
		...
		}
	...
	}
}

func TemplatedMatchType(...){
	//第一组 新输入的值
	dataSlice := chunk.GetSliceInPhyFormatUnifiedFormat[T](col)
	...
	//对每行
	for i := 0; i < *cnt; i++ {
		idx := sel.GetIndex(i)
		row := util.PointerToSlice[uint8](ptrs[idx], rowWidth)
		mask := util.Bitmap{Bits: row}
		isNull := !util.RowIsValidInEntry(mask.GetEntry(entryIdx), idxInEntry)
		colIdx := col.Sel.GetIndex(idx)
		//第二组 行存中的值
		val := util.Load[T](util.PointerAdd(ptrs[idx], colOffset))
		//比较两组值
		if !isNull && cmp.operation(&dataSlice[colIdx], &val) {
			sel.SetIndex(matchCnt, idx)
			matchCnt++
		} else {
			if noMatchSel {
				noMatch.SetIndex(*noMatchCnt, idx)
				(*noMatchCnt)++
			}
		}	
	}
	...
}
```


####### 处理`没有匹配`

用线性探测法移动到下一个哈希表元素位置。进入下一轮测试。

```go

for i := 0; i < noMatchCount; i++ {
	idx := state._noMatchVector.GetIndex(i)
	htOffsetsPtr[idx]++
	if htOffsetsPtr[idx] >= uint64(aht._capacity) {
		htOffsetsPtr[idx] = 0
	}
}

```

####### 哈希表实现方案

哈希表元素结构：
- salt。哈希值前缀
- 数据所在的block和偏移
```go
type aggrHTEntry struct {
	_salt uint16
	_pageOffset uint16
	_pageNr uint32
}
```

哈希表实质是`aggrHTEntry`类型的数组。并用线性探测解决冲突。
随着元素的增加，哈希表数组会出现空间不够的情况。哈希表需要Resize。

Resize过程：
- 输入参数： new size
- 分配数组。
- 重新构建哈希表。实质是将现有的数据重新插入新哈希表。
	- 取出已经分组的每行数据的首地址。数据是在TupleDataCollection,TupleDataSegment，TupleDataChunk,TupleDataChunkPart里面。会涉及到较复杂的scan过程。会在讲取`聚合结果`的地方细节。
	- 取此行的hash值。
	- 由hash值确定元素在新hash表的位置
	- 计算salt，block id和偏移。

函数关系：
```go

func (aht *GroupedAggrHashTable) Resize(size int){
	分配新数组
	...
	for {
		rowLocs := iter.GetRowLocations()
		for i := 0; i < iter.GetCurrentChunkCount(); i++ {
			//行首地址
			rowLoc := rowLocs[i]
			...
			//行hash值
			hash := util.Load[uint64](util.PointerAdd(rowLoc, aht._hashOffset))
			...
			//插入新哈希表。线性探测确定元素位置
			entIdx := hash & aht._bitmask
			for hashesArr[entIdx]._pageNr > 0 {
				entIdx++
				if entIdx >= uint64(aht._capacity) {
					entIdx = 0
				}
			}
			
			htEnt := &hashesArr[entIdx]
			//salt, block id, block offset
			htEnt._salt = uint16(hash >> aht._hashPrefixShift)
			htEnt._pageNr = uint32(1 + blockId)
			htEnt._pageOffset = uint16(util.PointerSub(rowLoc, blockPtr) / int64(aht._tupleSize))
		}
		//下一批行
		next := iter.Next()
		if !next {
			break
		}
	}
}

```

###### 更新聚合函数状态

对数据按group by表达式的值分组后，需要将数据更新进聚合函数状态中，即实质的聚合过程。

####### 聚合函数实现方案

支持的聚合函数：
- sum
- avg
- count
- max
- min

基础的概念。
- 状态。聚合函数的中间值。
- 聚合操作。对状态的动作。
	- init。聚合过程开始时，初始化状态。
	- update。新数据补充进状态。
	- combine。并行计算时，多个状态融合进一个状态。
	- finalize。从状态中取出结果值。

聚合过程实质是将聚合操作施加到状态上的过程。

重要模块：
- 状态。
	- State。存储状态。
	- StateOp。操作状态的包装接口。
		- 具体实现：SumStateOp，AvgStateOp，CountStateOp，MaxStateOp，MinStateOp
- 操作
	- AggrOp。聚合操作接口。
		- 具体实现：SumOp，AvgOp，CountOp，MinMaxOp
		- 最终落在StateOp的接口上
- 聚合流程：聚合操作的具体实现。基于状态和操作接口，完成聚合计算过程。
	- 入口：
		- GetXXXAggr。取某种聚合函数的某种数据类型的实现
		- UnaryAggregate。拼接聚合函数对象
	- 流程接口
		- aggrStateSize。取状态内存空间大小。
		- aggrInit。更新新数据
		- aggrCombine。复合另一个状态
		- aggrFinalize。取聚合结果值
		- aggrUpdate。聚合新数据
		- simpleUpdate。聚合新数据

**State**

- `_typ` 聚合类型。不同类型，值组成不同。支持sum，avg，count，max，min。
- `_value` 泛型值。某种数据类型。
- `_count` 个数。avg,count需要。
- 基本接口。
	- Init。按种类初始化。
	- Combine。复合另一个State。按种类有不同的复合方法。
	- SetIsset/GetIsset，GetValue/SetValue

```go
type State[T any] struct {
	_typ StateType // 聚合类型
	_isset bool // 是否已设置值
	_value T // 存储的值
	_count uint64 // 计数
}
```

**StateOp**

操作状态的包装接口。依据聚合种类，对State施加不同动作。
- Init。初始化state。内部实现用State.Init
- Combine。复合另一个State。按种类有不同的复合方法。
- AddValues。辅助接口。

Combine和AddValues，按聚合种类有不同的实现方法。

```go
type StateOp[T any] interface {
	Init(*State[T])
	Combine(*State[T], *State[T], *AggrInputData, TypeOp[T])
	AddValues(*State[T], int)
}
```

**Combine**的实现方案：
- 使用State.Combine。sum，avg，count是同一个实现。
- 单独实现。max，min是类似的实现。

```go
//sum，avg，count相同的实现
func (SumStateOp[T]) Combine(
	src *State[T],
	target *State[T],
	_ *AggrInputData,
	top TypeOp[T]) {
	src.Combine(target, top)
}

//max，min类似的实现
func (as *MaxStateOp[T]) Combine(
	src *State[T],
	target *State[T],
	_ *AggrInputData,
	top TypeOp[T]) {
	if !src._isset {
		return
	}
	
	if !target._isset {
		target._isset = src._isset
		target._value = src._value
	} else if top.Less(&target._value, &src._value) {
		target._value = src._value
	}
}
```


**AddValues**的实现方案：
- 更新count。avg，count
- 空。max,min

```go
func (as *CountStateOp[T]) AddValues(s *State[T], cnt int) {
	s._count += uint64(cnt)
}

func (as *MaxStateOp[T]) AddValues(s *State[T], cnt int) {
}
```

**AggrOp**
聚合操作接口。
- Init。初始化状态。内部实现用StateOp.Init
- Combine。复合另一个状态。内部实现用StateOp.Combine。
- Operation。聚合值。新数据聚合到状态上。
- ConstantOperation。聚合值。多个相同的新数据聚合到状态上。
- Finalize。从状态中取聚合结果值。
- IgnoreNull。忽略NULL。

Init，Combin和IgnoreNull的实现容易。

Operation和ConstantOperation的实现：
- sum, avg,count的实现相同。用StateOp添加新数据。
- min,max的实现相同。比较操作。新值与状态中的值比较，依据比较结果，进行更新。

```go
//sum,avg,count
func (s SumOp[ResultT, InputT]) Operation(
	s3 *State[ResultT],
	input *InputT,
	data *AggrUnaryInput,
	sop StateOp[ResultT],
	aop AddOp[ResultT, InputT],
	top TypeOp[ResultT]) {
		sop.AddValues(s3, 1)
		aop.AddNumber(s3, input, top)
}

  
func (s SumOp[ResultT, InputT]) ConstantOperation(
	s3 *State[ResultT],
	input *InputT,
	data *AggrUnaryInput,
	count int,
	sop StateOp[ResultT],
	aop AddOp[ResultT, InputT],
	top TypeOp[ResultT]) {
		sop.AddValues(s3, count)
		aop.AddConstant(s3, input, count, top)
}

func (MinMaxOp[ResultT, InputT]) Operation(
	s3 *State[ResultT],
	input *InputT,
	data *AggrUnaryInput,
	sop StateOp[ResultT],
	aop AddOp[ResultT, InputT],
	top TypeOp[ResultT]) {
	if !s3._isset {//第一次赋值
		aop.Assign(s3, input)
		s3._isset = true
	} else {//比较，再更新
		aop.Execute(s3, input, top)
	}
}  

func (MinMaxOp[ResultT, InputT]) ConstantOperation(
	s3 *State[ResultT],
	input *InputT,
	data *AggrUnaryInput,
	count int,
	sop StateOp[ResultT],
	aop AddOp[ResultT, InputT],
	top TypeOp[ResultT]) {
	
	if !s3._isset {//第一次赋值
		aop.Assign(s3, input)
		s3._isset = true
	} else {//比较，再更新
		aop.Execute(s3, input, top)
	}
}
```

Finalize的实现：
- count, min,max,sum。实现相似。从聚合结果中取值
- avg。计算平均值 = 聚合值 / 值个数。

```go
func (s SumOp[ResultT, InputT]) Finalize(
	s3 *State[ResultT],
	target *ResultT,
	data *AggrFinalizeData) {
	if !s3.GetIsset() {
		data.ReturnNull()
	} else {
		*target = s3.GetValue()
	}
}

func (AvgOp[ResultT, InputT]) Finalize(
	s3 *State[ResultT],	
	target *ResultT,	
	data *AggrFinalizeData) {
	
	if s3._count == 0 {
		data.ReturnNull()	
	} else {
		//计算平均值
		var rt = s3.GetValue()
		switch v := any(rt).(type) {
		case float64:
			c := float64(s3._count)
			r := v / c
			*target = any(r).(ResultT)
		...	
		}
	}
}
```

**聚合入口**
GetXXXAggr。依据数据类型、聚合函数类型（sum,count,...)调用UnaryAggregate封装聚合函数对象。
sum,min,max,count,avg都是类似的形式。

```go
func GetSumAggr(pTyp common.PhyType) *FunctionV2 {
	switch pTyp {
	case common.INT32:
		fun := UnaryAggregate[common.Hugeint, State[common.Hugeint], int32, SumOp[common.Hugeint, int32]](
			...
		)
		return fun
	...
	}
...
}
```

**UnaryAggregate**。拼接聚合函数对象
确定聚合流程接口的具体实现。
- aggrStateSize。取State的对象
- aggrInit。应用AggrOp.Init
- aggrCombine。应用Combine函数。
- aggrFinalize。应用Finalize函数
- aggrUpdate。应用UnaryScatter函数
- simpleUpdate。应用UnaryUpdate函数

```go
func UnaryAggregate[ResultT any, STATE State[ResultT], InputT any, OP AggrOp[ResultT, InputT]](	
	inputTyp common.LType,
	retTyp common.LType,
	aop AggrOp[ResultT, InputT],
	...
	) *FunctionV2 {
	var size aggrStateSize
	var init aggrInit
	var update aggrUpdate
	var combine aggrCombine
	var finalize aggrFinalize
	var simpleUpdate aggrSimpleUpdate
	
	size = func() int {
		var val State[ResultT]
		return int(unsafe.Sizeof(val))
	}
	
	init = func(pointer unsafe.Pointer) {
		aop.Init((*State[ResultT])(pointer), sop)
	}
	
	update = func(inputs []*chunk.Vector, data *AggrInputData, inputCount int, states *chunk.Vector, count int) {
		UnaryScatter[ResultT, STATE, InputT, OP](inputs[0], states, data, count,...)
	}
	
	combine = func(source *chunk.Vector, target *chunk.Vector, data *AggrInputData, count int) {
		Combine[ResultT, STATE, InputT, OP](source, target, data, count,...)
	}
	
	finalize = func(states *chunk.Vector, data *AggrInputData, result *chunk.Vector, count int, offset int) {
		Finalize[ResultT, STATE, InputT, OP](states, data, result, count, offset, ...)
	}
	
	simpleUpdate = func(inputs []*chunk.Vector, data *AggrInputData, inputCount int, state unsafe.Pointer, count int) {
		UnaryUpdate[ResultT, STATE, InputT, OP](inputs[0], data, state, count, ...)
	}
	
	return &FunctionV2{
			_funcTyp: AggregateFuncType,
			_args: []common.LType{inputTyp},
			_retType: retTyp,
			_stateSize: size,
			_init: init,
			_update: update,
			_combine: combine,
			_finalize: finalize,
			_simpleUpdate: simpleUpdate,		
		}
}
```


**Combine函数**：
对每个source state，应用AggrOp.Combine

```go
func Combine[ResultT any, STATE State[ResultT], InputT any, OP AggrOp[ResultT, InputT]](
	source *chunk.Vector,
	target *chunk.Vector,
	data *AggrInputData,
	count int,
	aop AggrOp[ResultT, InputT],
	...
	) {
	
	sourcePtrSlice := chunk.GetSliceInPhyFormatFlat[unsafe.Pointer](source)
	targetPtrSlice := chunk.GetSliceInPhyFormatFlat[unsafe.Pointer](target)
	for i := 0; i < count; i++ {
		//AggrOp.Combine
		aop.Combine(
			(*State[ResultT])(sourcePtrSlice[i]),
			(*State[ResultT])(targetPtrSlice[i]),
			...
		)
	}
}
```

**Finalize函数**:
对每个state，应用AggrOp.Finalize

```go
func Finalize[ResultT any, STATE State[ResultT], InputT any, OP AggrOp[ResultT, InputT]](
	states *chunk.Vector,
	data *AggrInputData,
	result *chunk.Vector,//agg结果
	count int,
	offset int,
	aop AggrOp[ResultT, InputT],
	...
	) {	
	statePtrSlice := chunk.GetSliceInPhyFormatFlat[unsafe.Pointer](states)
	resultSlice := chunk.GetSliceInPhyFormatFlat[ResultT](result)
	final := NewAggrFinalizeData(result, data)
	for i := 0; i < count; i++ {
		final._resultIdx = i + offset
		aop.Finalize((*State[ResultT])(
			statePtrSlice[i]), 
			&resultSlice[final._resultIdx], final)
	}
}
```

**UnaryScatter函数**：
根据新数据vector和state vector的物理表示，分情况处理。
- 都是constant表示。应用AggrOp.ConstantOperation
- 都是flat表示。应用UnaryFlatLoop
- 其他表示。统一转UnifiedFormat。应用UnaryScatterLoop

函数层次关系：
- UnaryScatter
	- AggrOp.ConstantOperation
	- UnaryFlatLoop
		- AggrOp.Operation
	- UnaryScatterLoop
		- AggrOp.Operation
```go
func UnaryScatter[ResultT any, STATE State[ResultT], InputT any, OP AggrOp[ResultT, InputT]](
		input *chunk.Vector,
		states *chunk.Vector,
		data *AggrInputData,
		count int,
		aop AggrOp[ResultT, InputT],
		...
	) {
	//constant
	if input.PhyFormat().IsConst() && states.PhyFormat().IsConst() {
		...
		aop.ConstantOperation((*State[ResultT])(statesPtrSlice[0]), &inputSlice[0], inputData, count,...)	
	//flat & flat
	} else if input.PhyFormat().IsFlat() && states.PhyFormat().IsFlat() {
		...
		UnaryFlatLoop[ResultT, STATE, InputT, OP](
			...
		)
	
	} else {//其它
		...
		UnaryScatterLoop[ResultT, STATE, InputT](
			...
		)
	}
}
```

**UnaryFlatLoop**
对每个新数据，应用AggrOp.Operation将新数据更新到state上.

```go
func UnaryFlatLoop[ResultT any, STATE State[ResultT], InputT any, OP AggrOp[ResultT, InputT]](
	inputSlice []InputT,	
	data *AggrInputData,	
	statesPtrSlice []unsafe.Pointer,
	mask *util.Bitmap,
	count int,
	aop AggrOp[ResultT, InputT],
	...
	) {	
	...
	input := NewAggrUnaryInput(data, mask)
	i := &input._inputIdx
	for *i = 0; *i < count; *i++ {
		aop.Operation((*State[ResultT])(statesPtrSlice[*i]), &inputSlice[*i], input, sop, addOp, top)
	}
}
```

**UnaryScatterLoop**
处理UnifiedFormat。对每个新数据，应用AggrOp.Operation将新数据更新到state上.
与UnaryFlatLoop的区别，取state的方式不同。

```go
func UnaryScatterLoop[ResultT any, STATE State[ResultT], InputT any](
	inputSlice []InputT,
	data *AggrInputData,
	statesPtrSlice []unsafe.Pointer,
	isel *chunk.SelectVector,
	ssel *chunk.SelectVector,
	mask *util.Bitmap,
	count int,
	aop AggrOp[ResultT, InputT],
	...
	) {
	...	
	input := NewAggrUnaryInput(data, mask)
	for i := 0; i < count; i++ {
		input._inputIdx = isel.GetIndex(i)
		sidx := ssel.GetIndex(i)
		aop.Operation((*State[ResultT])(statesPtrSlice[sidx]), &inputSlice[input._inputIdx], input, sop, addOp, top)
	}
}
```

**UnaryUpdate函数**
将新数据更新到单个state。而UnaryScatter是更新到一批state。

根据新数据vector物理表示，分情况处理。
- constant表示。应用AggrOp.ConstantOperation
- flat表示。应用UnaryFlatUpdateLoop
- 其他表示。统一转UnifiedFormat。应用UnaryUpdateLoop

函数层次关系：
- UnaryUpdate
	- AggrOp.ConstantOperation
	- UnaryFlatUpdateLoop
		- AggrOp.Operation
	- UnaryUpdateLoop
		- AggrOp.Operation

```go
func UnaryUpdate[ResultT any, STATE State[ResultT], InputT any, OP AggrOp[ResultT, InputT]](
	input *chunk.Vector,
	data *AggrInputData,
	statePtr unsafe.Pointer,
	count int,
	aop AggrOp[ResultT, InputT],
	...
	) {
	
	switch input.PhyFormat() {
	case chunk.PF_CONST://constant
		...
		aop.ConstantOperation((*State[ResultT])(statePtr), &inputSlice[0], inputData, count, sop, addOp, top)
	case chunk.PF_FLAT://flat
		...
		UnaryFlatUpdateLoop[ResultT, STATE, InputT, OP](
		...
		)
	
	default:
		var idata chunk.UnifiedFormat
		input.ToUnifiedFormat(count, &idata)
		UnaryUpdateLoop[ResultT, STATE, InputT, OP](
			...
		)
	}
}
```

**UnaryFlatUpdateLoop与UnaryUpdateLoop**
实现很接近。区别在于取新数据的方式不同。

```go
func UnaryFlatUpdateLoop[ResultT any, STATE State[ResultT], InputT any, OP AggrOp[ResultT, InputT]](
	inputSlice []InputT,
	data *AggrInputData,
	statePtr unsafe.Pointer,
	count int,
	mask *util.Bitmap,
	aop AggrOp[ResultT, InputT],
	...
	) {
	...
	for ; *baseIdx < next; *baseIdx++ {
		aop.Operation((*State[ResultT])(statePtr), &inputSlice[*baseIdx], input, sop,..)
	}
	...

}

func UnaryUpdateLoop[ResultT any, STATE State[ResultT], InputT any, OP AggrOp[ResultT, InputT]](
	inputSlice []InputT,
	data *AggrInputData,
	statePtr unsafe.Pointer,
	count int,
	mask *util.Bitmap,
	selVec *chunk.SelectVector,
	aop AggrOp[ResultT, InputT],
	sop StateOp[ResultT],
	...
	) {
	...	
	for i := 0; i < count; i++ {
		input._inputIdx = selVec.GetIndex(i)
		aop.Operation((*State[ResultT])(statePtr), &inputSlice[input._inputIdx], input, sop,...)
	}
}
```

####### 聚合过程

在确定新数据的分组后，要将新数据更新进每个聚合函数的状态。

过程：
- 对每个聚合函数，更新状态。函数UpdateStates
```go
func (aht *GroupedAggrHashTable) AddChunk(
	state *AggrHTAppendState,
	groups *chunk.Chunk,
	groupHashes *chunk.Vector,
	payload *chunk.Chunk,
	childrenOutput *chunk.Chunk,
	filter []int,
	) int {
	
	...
	//分组
	newGroupCount := aht.FindOrCreateGroups(
		...
	)
	//跳到行存中第一个状态的位置
	AddInPlace(state._addresses, int64(aht._layout.aggrOffset()), payload.Card())
	
	//对每个聚合函数，更新状态
	payloadIdx := 0	
	for i, aggr := range aht._layout._aggregates {
		...
		UpdateStates(
			aggr,
			state._addresses,
			payload,
			payloadIdx,
			payload.Card(),
		)
		//跳到一个聚合函数状态
		payloadIdx += aggr._childCount
		AddInPlace(state._addresses, int64(aggr._payloadSize), payload.Card())
	}
	
	return newGroupCount
}
```

**UpdateStates函数**：
目前只支持一元聚合函数。
应用聚合函数的aggrUpdate 将新数据更新进状态。

```go
func UpdateStates(
	aggr *AggrObject,
	addresses *chunk.Vector,
	payload *chunk.Chunk,
	argIdx int,
	cnt int,
	) {
	...
	if aggr._childCount != 0 {
		input = []*chunk.Vector{payload.Data[argIdx]}
	}
	//aggrUpdate
	aggr._func._update(
		input,
		...
		addresses,
		cnt,	
	)
}
```


##### distinct逻辑

处理步骤：
- 去重复阶段。每个distinct函数有个单独的hash表对象。数据先进入单独的hash表对象，按参数值去重复。
- 再聚合阶段。在结束构建hash表时，将distinct函数按参数去重后的数据，再次进入distinct函数的聚合逻辑，计算结果值。


###### 去重复阶段
注意：单独的hash表对象的key是聚合函数的参数值，而不是group by表达式的值。
除了hash表达对象不同，Sink的逻辑完全相同。

函数关系：
- HashAggr.Sink
	- HashAggr.SinkDistinct
		- HashAggr.SinkDistinctGrouping
			- RadixPartitionedHashTable.Sink

```go
func (haggr *HashAggr) SinkDistinct(chunk, childrenOutput *chunk.Chunk) {
	for i := 0; i < len(haggr._groupings); i++ {
		haggr.SinkDistinctGrouping(chunk, childrenOutput, i)
	}
}

func (haggr *HashAggr) SinkDistinctGrouping(
	data, childrenOutput *chunk.Chunk,
	groupingIdx int,
	) {
	distinctInfo := haggr._distinctCollectionInfo	
	distinctData := haggr._groupings[groupingIdx]._distinctData
	var tableIdx int
	dump := &chunk.Chunk{}
	
	for _, idx := range distinctInfo._indices {		
		...
		radixTable := distinctData._radixTables[tableIdx]
		...		
		radixTable.Sink(data, dump, childrenOutput, []int{})
		
	}
}
```

###### 再聚合阶段
在结束构建hash表时，触发distinct函数的聚合逻辑。

函数关系：
- HashAggr.Finalize 结束hash表构建
	- HashAggr.FinalizeInternal 结束hash表构建
		- HashAggr.FinalizeDistinct distinct函数的参数再聚合
			- HashAggr.DistinctGrouping 

**HashAggr.FinalizeInternal**函数
结束hash表（包括distinct的hash表）构建。
先做distinct函数的再聚合。
然后，结束group by表达式的聚合。

```go

func (haggr *HashAggr) Finalize() {
	haggr.FinalizeInternal(true)
}

func (haggr *HashAggr) FinalizeInternal(checkDistinct bool) {
	//distinct函数的再聚合
	if checkDistinct && haggr._distinctCollectionInfo != nil {
		haggr.FinalizeDistinct()
	}

	//结束group by表达式的聚合
	for i := 0; i < len(haggr._groupings); i++ {
		grouping := haggr._groupings[i]
		grouping._tableData.Finalize()
	}
}
```

**HashAggr.FinalizeDistinct函数**

先结束distinct函数的hash表对象。
再将distinct函数的hash表对象中的数据取出来再按group by表达式的值再次聚合

```go
func (haggr *HashAggr) FinalizeDistinct() {
	//结束distinct的hash表对象
	for i := 0; i < len(haggr._groupings); i++ {
		grouping := haggr._groupings[i]
		distinctData := grouping._distinctData
		for tableIdx := 0; tableIdx < len(distinctData._radixTables); tableIdx++{
			if distinctData._radixTables[tableIdx] == nil {
				continue
			}
			radixTable := distinctData._radixTables[tableIdx]		
			radixTable.Finalize()
		}
	}

	//distinct函数的hash表对象 => group by的hash表对象
	for i := 0; i < len(haggr._groupings); i++ {	
		grouping := haggr._groupings[i]
		haggr.DistinctGrouping(grouping, i)
	}
}

```


**HashAggr.DistinctGrouping函数** 

过程：
- 对每个distinct函数对象，对其hash表对象
	- 读取一批数据
	- 进入group by表达式hash表


```go
func (haggr *HashAggr) DistinctGrouping(
	groupingData *HashAggrGroupingData,	
	groupingIdx int,
	) {
	aggregates := haggr._distinctCollectionInfo._aggregates
	data := groupingData._distinctData
	...
	//每个distinct 函数
	for i := 0; i < len(haggr._groupedAggrData._aggregates); i++ {	
		aggr := aggregates[i]
		...
		//skip non distinct
		if !data.IsDistinct(i) {
			continue
		}
		
		
		//groupby + distinct payload
		outputChunk := &chunk.Chunk{}
		...
		
		//children output
		childrenChunk := &chunk.Chunk{}
		...
		
		scanState := &TupleDataScanState{}

		//读出每批数据，然后进入group by表达式的hash表
		for {
			...
			res := radixTable.GetData(scanState, outputChunk, childrenChunk)
			...
			//分离group by表达式值
			groupedAggrData := data._groupedAggrData[tableIdx]
			for groupIdx := 0; groupIdx < groupbySize; groupIdx++ {
				groupChunk.Data[groupIdx].Reference(outputChunk.Data[groupIdx])
			}
			groupChunk.SetCard(outputChunk.Card())
			
			  
			//分离distinct函数的输入参数值
			for childIdx := 0; childIdx < len(groupedAggrData._groups)-groupbySize; childIdx++ {
				aggrInputChunk.Data[payloadIdx+childIdx].Reference(
				outputChunk.Data[groupbySize+childIdx])
			}
				
			aggrInputChunk.SetCard(outputChunk.Card())
			//输入到group by表达式hash表
			groupingData._tableData.Sink(groupChunk, aggrInputChunk, childrenChunk, []int{i})
		}
	}
}
```
#### 取聚合结果

结果的内容：
- group by表达式值
- 聚合函数值
- 原始子节点的输出值

从多个维度理解聚合结果的组织结构：
- 上层：数据的空间组织层次。有分为多层:
	- TupleDataCollection
		- TupleDataSegment。存多个vector的数据。
			- TupleDataChunk。存1个vector，2048行数据
				- TupleDataChunkPart。1个block和溢出block。存多个行，小于2048行。
- 中层：行在block内，依次排列。
- 下层：TupleDataLayout决定行内部的数据格式。

读取聚合结果的过程：
- 扫所有的segment,chunk
- 扫chunk所有的block
- 扫block上的所有行
- 从行上取出数据

相应的，取聚合结果的函数接口也分为多层：
- 外部接口：取聚合结果API
	-  HashAggr.GetData
		- RadixPartitionedHashTable.GetData
			- GroupedAggrHashTable.Scan
				- TupleDataCollection.Scan
- 中部接口：读取一个chunk。
	-  TupleDataCollection.Scan
		- TupleDataCollection.NextScanIndex
		- TupleDataCollection.ScanAtIndex
			- TupleDataAllocator.InitChunkState
				- TupleDataAllocator.InitChunkStateInternal
			- TupleDataCollection.Gather
		- FinalizeStates
- 内部接口：从行中取数据
	- TupleDataCollection.Gather
		- TupleDataCollection.gather
			- TupleDataTemplatedGatherSwitch
				- TupleDataTemplatedGather

外部接口相对简单，不细讲
##### 中部接口

读取一个chunk的过程：
- 确定segment，chunk。函数NextScanIndex。
- 读取一个chunk。函数ScanAtIndex。
	- 确定每行的地址。函数InitChunkState
	- 读取每行中的数据。函数Gather。

TupleDataScanState记录了segment，chunk，block的信息。
在确定block后，借助TupleDataLayout确定数据在行的位置。

TupleDataScanState关键内容：
- 要读的列。
- 当前读到的segment,chunk的索引
- 被读取数据所在的block。TupleDataPinState
- 被读取数据的行首地址 以及 堆地址（可选）。TupleDataChunkState

TupleDataScanState在TupleDataCollection被取前初始化，并在读取过程中被更新。

**NextScanIndex函数**：
确定segment，chunk。当前chunk读完后，跳到下一个chunk。当前segment读完后，跳到下一个segment。

**ScanAtIndex函数：**

由InitChunkState确定行首地址。
由Gather读数据。

**InitChunkState函数：**
实质在InitChunkStateInternval中完成。

对每个TupleDataChunkPart（代表一个block）：
- 确定block首地址
- 确定行首地址= block首地址 + 行号 x 行宽。行宽由TupleDataLayout确定
- 如果有非定长字段，再确定堆地址

```go
func (alloc *TupleDataAllocator) InitChunkStateInternal(
	...
	offset uint64,
	...
	parts []*TupleDataChunkPart,
	) {
	
	rowLocSlice := chunk.GetSliceInPhyFormatFlat[unsafe.Pointer](chunkState._rowLocations)
	heapSizesSlice := chunk.GetSliceInPhyFormatFlat[uint64](chunkState._heapSizes)
	heapLocSlice := chunk.GetSliceInPhyFormatFlat[unsafe.Pointer](chunkState._heapLocations)
	
	rowWidth := alloc._layout.rowWidth()
	for _, part := range parts {
		next := part._count
	
		//block首地址	
		baseRowPtr := alloc.GetRowPointer(pinState, part)
		//确定行首地址	
		for i := uint32(0); i < next; i++ {
			rowLocSlice[offset+uint64(i)] =
			util.PointerAdd(baseRowPtr, int(i)*rowWidth)
		}
		
		。。。
  
		
		if initHeapPointers {
			//堆地址
			heapLocSlice[offset] = util.PointerAdd(
				part._baseHeapPtr,
				int(part._heapBlockOffset),
			)
			
			for i := uint32(1); i < next; i++ {
				idx := offset + uint64(i)
				heapLocSlice[idx] = util.PointerAdd(
					heapLocSlice[idx-1],
					int(heapSizesSlice[idx-1]),
				)
			}
		}
		offset += uint64(next)
	}
}
```

##### 内部接口

**Gather函数：**
读取行上的数据。

过程：
- 按列逐次读。Gather函数
- 按数据类型区分。TupleDataTemplatedGatherSwitch函数
- 读取行上数据。TupleDataTemplatedGather函数


```go
func (tuple *TupleDataCollection) Gather(
	layout *TupleDataLayout,
	rowLocs *chunk.Vector,
	scanSel *chunk.SelectVector,
	scanCnt int,
	colIds []int,
	result *chunk.Chunk,
	targetSel *chunk.SelectVector,
	) {
	//读取列
	for i := 0; i < len(colIds); i++ {
		tuple.gather(...)
	}
}

func (tuple *TupleDataCollection) gather(...) {
	TupleDataTemplatedGatherSwitch(
	...
	)
}

func TupleDataTemplatedGatherSwitch(
...
) {

	pTyp := target.Typ().GetInternalType()
	switch pTyp {
	case common.INT32:
		TupleDataTemplatedGather[int32](
		...
		)
	...
	}
}

func TupleDataTemplatedGather[T any](
	layout *TupleDataLayout,
	rowLocs *chunk.Vector,
	colIdx int,
	scanSel *chunk.SelectVector,
	scanCnt int,
	target *chunk.Vector,
	targetSel *chunk.SelectVector,
	) {
	
	srcLocs := chunk.GetSliceInPhyFormatFlat[unsafe.Pointer](rowLocs)
	targetData := chunk.GetSliceInPhyFormatFlat[T](target)
	targetBitmap := chunk.GetMaskInPhyFormatFlat(target)
	entryIdx, idxInEntry := util.GetEntryIndex(uint64(colIdx))
	//行内偏移
	offsetInRow := layout.offsets()[colIdx]
	for i := 0; i < scanCnt; i++ {
		...	
		if util.RowIsValidInEntry(
			rowMask.GetEntry(entryIdx),
			idxInEntry) {
			//读取行上指定位置的数据
			targetData[targetIdx] = util.Load[T](util.PointerAdd(base, offsetInRow))
		} else {
			targetBitmap.SetInvalid(uint64(targetIdx))
		}
	}

}

```


### order

概念：
- order by表达式。对应语法中order by子句。
- payload。order算子的输出表达式的值。order算子的结果。

一批输入数据会算出order by表达式的值和输出表达式的值（payload）。
order算子实质是依据order by表达式的值，对payload进行排序。

执行过程：
- 输入数据
	- 计算order by表达式的值和payload
	- 列转行。以行格式存储
- 排序
	- 内存排序。暂时不涉及外部排序
	- reorder。按排序结果，对非定长字段和payload重排列
- 读排序结果：sort算子的payload
	- 从行存中读结果

#### 初始化

参数：
- order by表达式。
- output 表达式。即payload

层次管理数据结构：从逻辑层到物理层
- 顶层：LocalSort。order算子管理结构。
- 中层：组织数据块。
	- RowDataCollection。多个block。存储输入数据，行存结构
		- RowDataBlock。单个block
	- SortedBlock 排序内存块。
		- SortedData 多个block
			- RowDataBlock
	- PayloadScanner 读排序结果
		- RowDataCollectionScanner 读多个block
			- RowDataCollection
- 物理层：
	- SortLayout。排序键的行存组织方式。
	- RowLayout。非定长字段，payload的行存组织方式。
	- RowDataBlock。单个block。entry个数，容量。

按阶段分：
- 输入数据阶段：
	- RowDataCollection。多个block。entry个数。
- 排序阶段：排序键的内存是单独的。
	- SortedBlock 排序键内存块。
		- SortedData 多个block
- 读排序结果阶段：
	- PayloadScanner 读排序结果
		- RowDataCollectionScanner 读多个block

##### 排序键行存结构
SortLayout定义order by表达式值的行存结构。规定的每行长度一定是定长的。非定长部分一定存储在堆中。

两部分构成：定长部分+非定长部分
- 定长部分。字节数固定。定长字段+非定长字段的固定长度prefix
- 非定长部分。字节数不定。单独行存结构。单独block存储。与定长部分的block分开。

从每个order by表达式中收集的信息：
- `_orderTypes`. 排序类型。asc,desc
- `_orderByNullTypes`. NULL值排序类型。默认是NULL值排前面
- `_logicalTypes`. 数据类型
- `_constantSize` . 是否是定长字段
- `_hasNull` . 是否有null值。
- `_columnSizes` . 列size。null byte（NULL字段）+字段size
- `_prefixLengths`. 前缀长度。varchar类型。在排序键中只存前缀。

内存形式：
```go
|null byte, col0|...|null byte,prefix|...|null byte,colN-1|
```

SortLayout除了上述信息外，还有整体信息：
- `_allConstant`. 是否全是定长字段。
- `_comparisonSize`。参与比较的字节数。
- `_entrySize`. entry长度。entry长度 = `_comparisonSize` + 行索引size(4字节)。
- `_blobLayout` 非定长字段的行存组织方式。由RowLayout表示。

##### 通用行存结构
RowLayout定义的行存结构服务payload，排序键中非定长字段。规定的每行长度一定是定长的。非定长部分一定存储在堆中。


内存形式：
```
|null bitmap|heap ptr offset|col 0|...|col i heap ptr|...|col n-1|
```


#### 输入数据

数据列转行后，会分成三部分：
- 排序键的定长部分。来自order by表达式。
- 排序键的非定长部分。来自order by表达式。
- payload。

三部分数据都是用RowDataCollection存储。
- 排序键的定长部分。一个RowDataCollection对象。长度一定是固定size。
- 排序键的非定长部分。两个RowDataCollection对象。一个放堆指针，固定size的行。一个放变长字段值。
- payload。两个RowDataCollection对象。一个放堆指针，固定size的行。一个放变长字段值。

输入阶段有5个RowDataCollection对象。

输入过程是将数据转换成这三部分。

过程：
- 计算order by表达式的值和payload
- 分配内存块
- 列转行
	- 排序键的定长部分 
	- 排序键的非定长部分
	- payload

函数关系：
- LocalSort.SinkChunk 输入数据入口
    - RowDataCollection.Build 分配内存
    - RadixScatter 转换排序键的定长部分
    - Scatter  转换排序键的非定长部分和payload

```go
func (ls *LocalSort) SinkChunk(sort, payload *chunk.Chunk) {
    dataPtrs := chunk.GetSliceInPhyFormatFlat[unsafe.Pointer](ls._addresses)
    
    //为排序键的定长部分 分配空间
    ls._radixSortingData.Build(sort.Card(), dataPtrs, nil, chunk.IncrSelectVectorInPhyFormatFlat())
    
    //转换排序键的定长部分
    for sortCol := 0; sortCol < sort.ColumnCount(); sortCol++ {
        ...
        //copy data from input to the block
        //only copy prefix for varchar
        RadixScatter(
          ...
        )
    }
    
    //排序键的非定长部分
    if !ls._sortLayout._allConstant {
        ...
        //分配空间
        ls._blobSortingData.Build(blobChunk.Card(), dataPtrs, nil, chunk.IncrSelectVectorInPhyFormatFlat())
        ...
        //转换
        Scatter(
        ...    
        )
    }
    //payload
    //分配空间
    ls._payloadData.Build(payload.Card(), dataPtrs, nil, chunk.IncrSelectVectorInPhyFormatFlat())
    ...    
    //转换
    Scatter(
    ...
    )

}
```

##### 分配内存块

分配block和entry的首地址。

RowDataCollection：组织多个block。
- RowDataBlock 单个block

RowDataCollection的字段
- `_count` entry个数
- `_blockCapacity` 每个block中entry个数
- `_entrySize` entry字节数
- `_blocks` 分配的内存block

RowDataBlock的字段
- `_ptr` 内存地址
- `_capacity` block中entry个数
- `_entrySize` entry字节数
- `_count` entry个数
- `_byteOffset` 变成entry的写入位置

分配过程：
- 分配block
	- 如果当前block空间足够，分配entry空间
	- 如果当前block空间不够，分配新的block。并重复上一步。
	- 直到所有行的block都确定。
- 计算entry地址
	- 遍历分配的block。计算block上每个entry的首地址


函数关系：
- RowDataCollection.Build 入口。分配内存，拿到每个entry的地址
	- RowDataCollection.CreateBlock 分配全新block
	- RowDataCollection.AppendToBlock 在block上分配连续entry空间。

这几个函数实现不复杂，不再细说。

##### 转换排序键的定长部分 

处理过程，对order by表达式的值：
- 对每列vector
	- 对每行：函数RadixScatter
		- 定序编码： 函数EncodeData/EncodeStringDataPrefix

函数关系：
- RadixScatter 入口
	- TemplatedRadixScatter 转换定长字段
		- EncodeData 定长字段定序编码
	- RadixScatterStringVector 转换字符串
		- EncodeStringDataPrefix 字符串定序编码

```go
func RadixScatter(
	v vector,
	...
	keyLocs []pointer,
	...){
	switch v.Typ().GetInternalType() {
	case common.INT32:
		TemplatedRadixScatter[int32](
		...
		keyLocs,
		...
		int32Encoder{},
		)
	
	case common.VARCHAR:
		RadixScatterStringVector(
		...
		keyLocs,
		...
		)
	...
	}
}

```

**函数TemplatedRadixScatter**：

对定长字段的每行定序编码。

要解决的问题：
- NULL值编码和顺序。默认NULL值排在前。
- NULL值存储。1个byte，排在字段编码前。
- 字段编码。编码后的二进制串保留值的有序性。
- asc/desc。升序/降序

在字段编码前，加1个byte空间表示NULL.
如果NULL值要排在非NULL值前面，NULL值的null byte = 0，非NULL值的null byte = 1。

```text
...| null byte| encoded field |...
```

定序编码接口：
```go
type Encoder[T any] interface {
	EncodeData(unsafe.Pointer, *T)
	TypeSize() int
}
```

int32的编码实现：
例如：value1 = 0x12345678, value2 = 0x12345679. value1 < value2
BSWAP32(value1) => 0x78563412 => FlipSign =>0xF8563412
BSWAP32(value2) =>0x79563412 => FlipSign =>0xF9563412
在二进制上，value1 < value2 (0xF8563412 < 0xF9563412)

```go
func (i int32Encoder) EncodeData(ptr unsafe.Pointer, value *int32) {
	util.Store[uint32](BSWAP32(uint32(*value)), ptr)
	util.Store[uint8](FlipSign(util.Load[uint8](ptr)), ptr)
}

func BSWAP32(x uint32) uint32 {
	return 
	((x & 0xff000000) >> 24) | 
	((x & 0x00ff0000) >> 8) | 
	((x & 0x0000ff00) << 8) | 
	((x & 0x000000ff) << 24)
}

func FlipSign(b uint8) uint8 {
	return b ^ 128	
}
```

如果desc 为true，降序排列。将编码后的二进制串取反即可。
例如，上面的例子。
0xF8563412 =>取反=> 0x07A9CBED
0xF9563412 =>取反=> 0x06A9CBED
在二进制上，value1 > value2 (0x07A9CBED >0x06A9CBED)。恰好与数值顺序相反。

再看函数实现，
- 对每行
	- 确定null byte值。
	- 编码
	- 如果desc，编码值取反
```go
func TemplatedRadixScatter[T any](
	vdata *chunk.UnifiedFormat,
	...
	keyLocs []unsafe.Pointer,
	desc bool,
	hasNull bool,
	nullsFirst bool,
	...
	enc Encoder[T],
	) {
	//字段有null值
	if hasNull {
		mask := vdata.Mask
		valid := byte(0)
		if nullsFirst {
			valid = 1
		}
		invalid := 1 - valid
		//对每行
		for i := 0; i < addCount; i++ {
			idx := sel.GetIndex(i)
			srcIdx := vdata.Sel.GetIndex(idx) + offset
			if mask.RowIsValid(uint64(srcIdx)) {
				//not null
				//first byte
				util.Store[byte](valid, keyLocs[i])
				//编码
				enc.EncodeData(util.PointerAdd(keyLocs[i], 1), &srcSlice[srcIdx])
				//desc , invert bits
				if desc {
					for s := 1; s < enc.TypeSize()+1; s++ {
						util.InvertBits(keyLocs[i], s)
					}
				}
			
			} else {
				util.Store[byte](invalid, keyLocs[i])
				util.Memset(util.PointerAdd(keyLocs[i], 1), 0, enc.TypeSize())
			}
			
			keyLocs[i] = util.PointerAdd(keyLocs[i], 1+enc.TypeSize())
		}
		
	} 	
	...
}

```

**函数RadixScatterStringVector**：

对字符串的每行定序编码。

对NULL值和desc的处理与上面的相同。区别在字符串的定序编码。剩余的处理也相同，实现代码就再讲了

字符串的定序编码。
- 最多赋值prefixLen个字节的前缀。
- 不够prefixLen的部分填0

```go
func EncodeStringDataPrefix(
	dataPtr unsafe.Pointer,
	value *common.String,
	prefixLen int) {
	l := value.Length()
	util.PointerCopy(dataPtr, value.DataPtr(), min(l, prefixLen))
	if l < prefixLen {
		util.Memset(util.PointerAdd(dataPtr, l), 0, prefixLen-l)
	}
}
```

##### 转换排序键的非定长部分和payload

这两块是同一套逻辑。
每块都有两个RowDataCollection对象。一个放堆指针，固定size的行。一个放变长字段值。

两个RowDataCollection对象关系：
```text
对象1，固定size的行:

	|null bitmap|heap ptr offset|col 0|...|col i heap ptr|...|col n-1|
                    |						|
					|						|
|--------------------                       |
|                                           |
|                                  |--------|
|	对像2，变长字段值，堆空间：         |
|                                 \|/
|--->|var len field |...|var len field i|

```

过程：
- 分配变长字段的堆空间
    - 计算每行所有变长字段空间总size，即每行堆空间size
    - 分配堆空间。准备对象2
    - 记录每行堆空间首地址。将对象2每行堆空间首地址记录到对象1 heap ptr offset处。组成上图关系
- 列转行
    - 对每列vector
    	- 对每行：函数TemplatedScatter/ScatterStringVector
    		- 填充字段 

函数关系：
- Scatter 入口
    - TemplatedScatter 转换定长字段
    - ScatterStringVector 转换字符串

```go
func Scatter(
    ...
    ) {
    ...
    //compute the entry size of the variable size columns
    dataLocs := make([]unsafe.Pointer, util.DefaultVectorSize)
    if !layout.AllConstant() {
        entrySizes := make([]int, util.DefaultVectorSize)
        util.Fill(entrySizes, count, common.Int32Size)
        //计算变长字段 堆空间size
        for colNo := 0; colNo < len(types); colNo++ {
            if types[colNo].GetInternalType().IsConstant() {
                continue
            }
            ...
            ComputeStringEntrySizes(col, entrySizes, sel, count, 0)
        }
        
        //分配堆空间
        stringHeap.Build(count, dataLocs, entrySizes, chunk.IncrSelectVectorInPhyFormatFlat())
        
        //将堆空间指针存储到dataLocs中，关联对象2和对象1
        heapPointerOffset := layout.GetHeapOffset()
        for i := 0; i < count; i++ {
            rowIdx := sel.GetIndex(i)
            rowPtr := ptrs[rowIdx]
            util.Store[unsafe.Pointer](dataLocs[i], util.PointerAdd(rowPtr, heapPointerOffset))
            util.Store[uint32](uint32(entrySizes[i]), dataLocs[i])
            dataLocs[i] = util.PointerAdd(dataLocs[i], common.Int32Size)
        }
    }
    
      
    //转换每列
    for colNo := 0; colNo < len(types); colNo++ {
        col := colData[colNo]
        colOffset := offsets[colNo]
        switch types[colNo].GetInternalType() {
        
        case common.INT32:    
            TemplatedScatter[int32](
            ...
            )
        case common.VARCHAR:
            ScatterStringVector(
            ...
            )
        ...
        }
    }

}
```

**函数TemplatedScatter**:

对每行，从vector取字段值，填到对象1的行中。不会存到对象2中。
```go
  

func TemplatedScatter[T any](
...
) {
    data := chunk.GetSliceInPhyFormatUnifiedFormat[T](col)
    ptrs := chunk.GetSliceInPhyFormatFlat[unsafe.Pointer](rows)
    ...
    //填每行
    for i := 0; i < count; i++ {
        idx := sel.GetIndex(i) 
        colIdx := col.Sel.GetIndex(idx)
        rowPtr := ptrs[idx]
        util.Store[T](data[colIdx], util.PointerAdd(rowPtr, colOffset))
    }
}
```

**函数ScatterStringVector**：

对每行，从vector取字段值，填到对象2的行中。再将其在对象2中的地址，存到对象1中。构成上面的两者关系图。

```go
func ScatterStringVector(
...
) {
    strSlice := chunk.GetSliceInPhyFormatUnifiedFormat[common.String](col) 
    ptrSlice := chunk.GetSliceInPhyFormatFlat[unsafe.Pointer](rows)

    nullStr := chunk.StringScatterOp{}.NullValue()    
    for i := 0; i < count; i++ {
        ...
        str := strSlice[colIdx]
        newStr := common.String{
            Len: str.Length(),
            Data: strLocs[i],
        }
        
        //copy varchar data from input chunk to
        //the location on the string heap
        util.PointerCopy(newStr.Data, str.DataPtr(), str.Length())
        
        //move strLocs[i] to the next position
        strLocs[i] = util.PointerAdd(strLocs[i], str.Length())

        //store new String obj to the row in the blob sort block        
        util.Store[common.String](newStr, util.PointerAdd(rowPtr, colOffset))
    }
}
```

#### 排序

过程：
- 分配排序内存。排序内存是大块连续内存。不同于存储输入数据的内存。
    - 排序键的定长部分
    - 排序键的非定长部分
    - payload
- 排序
    - 多维排序方案
        - 第一维：按列分组
        - 第二维：按Tie分行
        - 第三维：排序算法
- 重排列
    - 重排列排序键的非定长部分
    - 重排列payload

##### 分配排序内存

为三部分数据，准备排序内存。不包括堆内存。
- 排序键的定长部分
- 排序键的非定长部分
- payload

三部分做法一致。函数ConcatenateBlocks
- 分配足够大的内存块。能装下全部的entry
- 从输入数据的block中将数据复制到排序内存

函数ConcatenateBlocks的实现清晰：分配内存，复制内存。不细讲。

##### 排序

排序方案的层次：
- 逻辑层：组织方式
    - 按列分组。竖切
        - 排序键的定长部分
    - 按Tie分行。横切
        - 排序键的非定长部分
- 物理层：数据搬运
    - 选择合适的排序算法
###### 逻辑层

函数SortInMemory完成逻辑层的工作。

函数关系：部分函数会在后面介绍
- SortInMemory
    - RadixSort 排序算法
    - SubSortTiedTuples 借助Tie，对排序键继续排序
    - ComputeTies 计算tie
    - AnyTies 任一个Tie为true，结果为true
    - SortTiedBlobs 借助Tie，对不定长字段继续排序。

```go
func (ls *LocalSort) SortInMemory() {

    ...
    dataPtr := lastBlock._ptr
    //locate to the addr of the row index
    idxPtr := util.PointerAdd(dataPtr, ls._sortLayout._comparisonSize)
    
    //给每行分配序号
    for i := 0; i < count; i++ {
        util.Store[uint32](uint32(i), idxPtr)
        idxPtr = util.PointerAdd(idxPtr, ls._sortLayout._entrySize)
    }

  

    //radix sort
    sortingSize := 0//组k的字节数
    colOffset := 0//组k的开始位置
    var ties []bool
    containsString := false
    for i := 0; i < ls._sortLayout._columnCount; i++ {
        //组k的字节数
        sortingSize += ls._sortLayout._columnSizes[i]
        containsString = containsString ||
        ls._sortLayout._logicalTypes[i].GetInternalType().IsVarchar()
        //确定组k
        if ls._sortLayout._constantSize[i] && i < ls._sortLayout._columnCount-1 {
            //util a var len column or the last column
            continue
        }

        if ties == nil {            
            //first sort
            RadixSort(
            ...
            )
            //初始化tie
            ties = make([]bool, count)
            util.Fill[bool](ties, count-1, true)
            ties[count-1] = false
        } else {
            //在组k上，借助Tie，继续排序
            //sort tied tuples        
            SubSortTiedTuples(
            ...
            )
        
        }
        

        containsString = false
        //所有列都排序完了，排序结束。不用再关系Tie了
        if ls._sortLayout._constantSize[i] &&
            i == ls._sortLayout._columnCount-1 {
            //all columns are sorted
            //no ties to break due to
            //last column is constant size
            break
        
        }
        
          
        //计算tie
        ComputeTies(
            ...
            ties,
            ...
            )
        //Tie值全为false
        if !AnyTies(ties, count) {
            //no ties, stop sorting
            break
        }
        
          
        //不定长字段
        if !ls._sortLayout._constantSize[i] {
            //在组k上，借助Tie，对不定长字段排序
            SortTiedBlobs(
            ...
            )
            
            if !AnyTies(ties, count) {
                //no ties, stop sorting
                break
            }
        }
        

        colOffset += sortingSize        
        sortingSize = 0
    
    }
}
```

###### 按列分组

分组形式：竖切
- 连续的多个定长字段+变长字段 
- 连续的多个定长字段 直到列结束
- 单个变长字段

```text
组形式 0: |fix len field 0|,...,|var len field i|
组形式 1: |var len field i+1|
组形式 2: |fix len field j|,...,|var len field N-1|
组形式 3: |fix len field j|,...,|fix len field N-1|
```

分组后，组内排序：
- 数据比较的大小。当前组的字段长度之和
- 没有任何tie时（第一次排序时）
    - 将当前`[组k]`作为内容，对组内所有行，执行排序算法。得出所有行的顺序。
- 在有tie时
    - 按行分Tie。见下节
###### 按Tie分行

引入Tie的原因，在某次排序结束时，全局顺序关系已经确定。
而相邻排序键entry，在当前组上（见上面）的顺序关系情况有：
- 行的排序键`entry[组k]` < i+1 行的排序键`entry[组k]`，即`sork_key_entry[i][组k] < sort_key_entry[i+1][组k]`。此时这两个entry，无需再进行后续排序。
- 行的排序键`entry[组k]` == i+1 行的排序键`entry[组k]`，即`sork_key_entry[i][组k] == sort_key_entry[i+1][组k]`。这个两个entry，还需要进行在后续组上排序。

Tie的定义：
- 与数据行数相等的布尔数组。`Tie bool[0,...,N-1]`
- 初始值：`Tie[0 ~ N-2] = True, Tie[N-1] = false`
- 更新：
    - 如果i行的排序键`entry[组k]` 与 i+1 行的排序键`entry[组k]`相等，则`Tie[i] = true`
    - 即：`Tie[i] = true if Tie[i] is True and sort_key_entry[i][组k] == sort_key_entry[i+1][组k], i in [0,...,N-2]`

结论1: Tie用来挑选出需要再继续排序的行。`Tie[i]`为true行都要继续排序。
结论2: 当`Tie[i]`全为false时，排序结束。
结论3: `Tie[N-1]`不会变为true。

函数ComputeTies按Tie的定义计算Tie值:
```go
func ComputeTies(   
    dataPtr unsafe.Pointer,
    count int,
    colOffset int,//组k开始位置
    tieSize int,//组k的字节数
    ties []bool,
    layout *SortLayout) {

    //组k的首地址
    dataPtr = util.PointerAdd(dataPtr, colOffset)    
    for i := 0; i < count-1; i++ {
        ties[i] = ties[i] &&
        util.PointerMemcmp(
            dataPtr,//i行
            util.PointerAdd(dataPtr, layout._entrySize),//i+1行
            tieSize,//组k的字节数
        ) == 0
        dataPtr = util.PointerAdd(dataPtr, layout._entrySize)
    }
}
```

按连续的`Tie[i]`为true的行再分组，组内进行排序。
如下逻辑，`Tie[i]~Tie[j]`为一组。函数SubSortTiedTuples和SortTiedBlobs 利用此逻辑。
```go
for i := 0; i < count; i++ {
    if !ties[i] {
        continue
    }

    var j int
    for j = i; j < count; j++ {
        if !ties[j] {
            break
        }
    }
    //对Tie[i]~Tie[j]组的行再排序。
    ...
}
```

###### 排序算法

多种排序算法组合使用，选择的依据：
- 包含字符串。用快速排序。
- 元素个数 <=24。用插入排序。
- `[组k]`的排序字节数 <= 4。用基数排序LSD
- 其它情况。用基数排序MSD
####### 快速排序

快排的执行框架：
- 划分为左右两部分。
    - 挑pivot
    - 将比pivot大的元素放在pivot右边
    - 将比pivot小的元素放在pivot左边
    - 将pivot放置到其正确位置。并且pivot的位置为全局有序位置。
- 对左半递归
- 对右半递归

框架层面的改进：
- 元素个数 < 24时，换插入排序。
    - 如果是最左边的分区，普通插入排序
    - 否则，用改进版的插入排序（少了与begin比较的判断）。
- pivot的挑选方法：
    - 元素个数 > 128。9中选1.
    - 其它，3中选1
- 递归剪枝
    - 如果是非最左边的分区，并且位置begin和begin-1的值相等。
        - 此时，将分区`[begin,end)`中与pivot相等的元素，放入此分区的左子分区。并且左子分区一定有序。
        - 仅对右子分区排序。
- 划分的改进
    - 先做第一轮与pivot的比较。如果已经划分，不再继续比较
    - 块交换。一次交换多个元素.
    - 与pivot相等的元素，放左边或右边
- 非平衡的处理
    - 如果左边的size < 总size/8 或 右边的size < 总size/8，定义此时为不平衡态
    - shuffle一些元素。没有采用堆排序。
    - 对第一轮比较已经划分的分区，尝试用插入排序。如果插入排序，一轮扫描的元素个数超过8个，停止用插入排序。
- 消除尾递归
    - 对左子分区，递归排序。
    - 对右子分区，begin = pivot + 1，进入下一轮迭代。

快排实现：
```go
func pdqsortLoop(
    begin, end *PDQIterator,
    constants *PDQConstants,
    ...
    leftMost bool,
    ...
    ) {
    for {
        size := pdqIterDiff(end, begin)
        if size < 24 {
            插入排序
            return
        }
        挑pivot；//3元素 或 9元素
        //递归剪枝:
        if !leftmost && begin-1的值 == begin的值{
            //划分.与pivot相等的元素，放在左子分区
            begin = partitionLeft(begin,end) + 1
            //左子分区已经排序。
            //仅需处理右子分区
            continue
        }
        //划分。与pivot相等的元素，放在右子分区
        pivotPos, alreadyPartitioned = partitionRightBranchless(begin, end, constants)
        //非平衡
        lSize := pdqIterDiff(&pivotPos, begin)
        x := pivotPos.plusCopy(1)
        rSize := pdqIterDiff(end, &x)
        if lSize < size/8 || rSize < size/8 {
            shuffle
        }else {
            //第一轮比较已经划分的分区，尝试用插入排序
            if alreadyPartitioned {
                if partialInsertionSort(begin, &pivotPos, constants) {  
                    x = pivotPos.plusCopy(1)
                    if partialInsertionSort(&x, end, constants) {
                        return
                    }
                }
                
            }
        }
        //对左子分区递归排序
        pdqsortLoop(begin, &pivotPos, constants, badAllowed, leftMost, branchLess)
        //对右子分区迭代排序
        x = pivotPos.plusCopy(1)
        begin = &x
        leftMost = false
    }
}
```

划分方法：

**函数partitionLeft**：与pivot相等的元素放置在左子分区。
**函数partitionRightBranchless**：与pivot相等的元素放置在右子分区。并且使用块交换。

####### 插入排序

**常规实现**：函数insertSort。容易理解，不细说

**ungarded实现**：函数unguardedInsertSort。
在常规实现中，判断 sift != begin，确保未越界。

但是，在确保begin-1存在且begin-1的值 < begin的值前提下，可以将判断 sift != begin去掉。并且不会越界。

**部分插入排序**：函数partialInsertionSort。
在常规实现的基础上，限制每轮移动的元素个数。如果一轮移动的元素个数超过8个，提前结束，排序失败。

####### 基数排序LSD
在排序字节数 <= 4时，用基数排序LSD。
用的是常规实现。结合了桶排序。无需递归。从字节序列尾部向头部（逆序），在每个字节位置上，先分桶，再重排。

####### 基数排序MSD
除了快排，插入排序，基数LSD的情况外，用基数MSD。

从字节序列头部到尾部（正序），在每个字节位置上，结合桶排序，先分桶，再重排。
假设，在第k-1个字节上，已经排序完成。说明在区间0～k-1上，桶之间的相对顺序是确定的。
那么，只需在第k-1个字节上，对同一个桶中的序列，再对第k个字节进行递归基数MSD排序即可。注意：一定是对同一个桶中的序列递归。不同桶之间，相对顺序一定已经确定。

并且在递归过程中，当元素个数 <=24时。改用插入排序。


###### 重排序
对排序键的非定长部分和payload。

过程：
- 为要重排的固定size部分，分配大内存块，存储重排后的entry。
- 遍历排序键的定长部分。
    - 取每个entry的原始index。
    - 确定源内存地址
    - 从源内存复制数据到大内存块
- 为变长部分，分配大内存块，存储重排后的堆内存
    - 依据已经重排的entry，确定堆内存地址。heapPointerOffset
    - 从源堆内存复制数据重排后的堆内存

#### 读排序结果

遍历payload的数据块，取出每个entry上的对应列。

数据层次：
- PayloadScanner 入口
    - RowDataCollectionScanner 扫描数据集
        - ScanState 扫描位置：block idx，entry idx。

读取过程：
- 初始化。函数NewPayloadScanner
    - 确定payload的数据RowDataBlock。固定size部分和堆。
    - 初始化对象。
        - XXXScanner
        - ScanState。指向第一个block的，第一个entry
- scan过程：函数RowDataCollectionScanner.Scan
    - 计算要读的entry的首地址：entryIdx X rowWidth + block首地址
    - 读每个entry上的列。函数Gather.

函数关系：
- RowDataCollectionScanner.Scan 
    - Gather.

```go
func (scan *RowDataCollectionScanner) Scan(output *chunk.Chunk) {
    ...
    确定每个entry的首地址;
    ...
    //取出每列colIdx上的值
    for colIdx := 0; colIdx < scan._layout.CoumnCount(); colIdx++ {
        Gather(
            scan._addresses,
            ...
            output.Data[colIdx],
            ...
            count,
            scan._layout,
            colIdx,
            ...
        )
    }

    output.SetCard(count)
    scan._totalScanned += scanned
}

func Gather(
    rows *chunk.Vector,
    rowSel *chunk.SelectVector,
    col *chunk.Vector,
    colSel *chunk.SelectVector,
    count int,
    layout *RowLayout,
    colNo int,
    buildSize int,
    heapPtr unsafe.Pointer,
) {
    switch col.Typ().GetInternalType() {
    case common.INT32:
        TemplatedGatherLoop[int32](
        ...
        )
    ...
    case common.VARCHAR:
        GatherVarchar(
        ...
        )
    }
}

func TemplatedGatherLoop[T any](
    ...
    ) {
    ...
    for i := 0; i < count; i++ {
        rowIdx := rowSel.GetIndex(i)
        row := ptrs[rowIdx]
        colIdx := colSel.GetIndex(i)
        dataSlice[colIdx] = util.Load[T](util.PointerAdd(row, colOffset))
        rowMask := util.Bitmap{
        ...
        
        if !util.RowIsValidInEntry(
            rowMask.GetEntry(entryIdx), 
            idxInEntry) {
            ...
            colMask.SetInvalid(uint64(colIdx))
        }
    }
}
```

**函数Gather**：入口
- 函数TemplatedGatherLoop
    - 取出每个entry上的指定列
- 函数GatherVarchar。类似

### join

支持的join类型：cross, inner, mark, anti mark, semi, anti semi, left

#### 非cross join

对于非cross join，目前支持基于hash表的实现方式。左子节点的数据用于probe。
非cross join的执行过程：
- 输入数据
    - 列转行。右子节点的数据存为行存结构。并计算hash值。
    - build hash表。数据输入完成后，再在之上构建hash表（拉链法解决冲突）。不是边输入数据，边构建hash表。
- 执行join
    - probe阶段
        - 读左子节点的数据。计算hash值。从hash表中确定hash值相等的桶。
    - 构建join结果
        - 从桶中确定与probe数据相等的记录
        - 依据join类型，组合join的结果。

##### 初始化

非cross join的层次管理结构：
- 顶层：HashJoin。
- 中层：
    - JoinHashTable。列转行。构建hash表。
    - Scan。执行join
- 物理层：行存结构与agg节点的做法一致。
    - TupleDataCollection。行存存储右子节点数据。
    - TupleDataLayout。行存结构。

按其执行阶段分：
- build阶段：
    - JoinHashTable
    - TupleDataCollection
- probe阶段：
    - Scan

hash表的key：join on条件中右子表达式的值。
- 约束：
    - 在plan阶段，确保join on右子表达式的数据都来自join的右子节点。在允许交换join左右子节点的前提下，也会保持这种对应关系。
    - NULL不进入hash表
- join on条件可能不止一个。filter下推阶段，可能会将多个filter条件推到join节点，作为join on条件，并且满足上面的约束。这些join on条件中右子表达式的值都要作为hash表的key。最终的hash值是这些右子表达式值的复合结果。

与hash表的key对应，probe的key：为join on条件中左子表达式的值


行存的内容：用TupleDataLayout。
- hash key。probe阶段，需要用join on条件中左子表达式的值来查hash表。并且判断与hash key的值是否相等。
- payload。join右子节点的数据。probe阶段，依据join类型，组合不同的结果。
- hash值。

##### 输入数据

build阶段的两个阶段：
- 读数据
- 构建hash表。不是边读边构建

读数据：
- 从join右子节点读一批数据（payload数据）
    - 过滤NULL值
    - 计算hash key。
    - 计算hash key的hash值
    - hash key+payload+hash值存入TupleDataCollection。与agg节点中的做法一致，不细讲
    - 直到join右子节点无数据

此时数据读完，数据在TupleDataCollection中不再移动。只需将数据的地址依据hash值存入hash表。

hash表：
- 确定hash的size。比`2*size`大的最小的2的n次方值。
- hash表的结构简化为一个地址数组。每个元素是一个链表首节点的地址。
- 拉链法解决冲突。hash值相同时，用头插入法插入新值。并且下一个值的地址放置在行格式中，原先放置hash值的位置。因为hash值不再需要了。
- 构建过程：
    - 读出TupleDataCollection的所有数据
    - 按每个行的hash值，插入对应的桶，并解决冲突


##### 执行

prob阶段的过程
- 从join左子节点读一批数据
- probe: 探测hash表。函数JoinHashTable.Probe
    - 计算probe key。join on条件中左子表达式的值
    - 计算probe key的hash值。函数JoinHashTable.hash
    - 由hash值确定桶，取桶连表的首节点地址。注意：hash值相等，不代表链表中的每个节点值都与probe key相等。函数JoinHashTable.ApplyBitmask2
- scan：依据join类型组合数据。函数Scan.Next，入口函数
    - inner。函数Scan.NextInnerJoin
    - mark, anti mark。函数Scan.NextMarkJoin
    - semi。函数Scan.NextSemiJoin
    - anti semi。函数Scan.NextAntiJoin
    - left。函数Scan.NextLeftJoin

probe函数关系：
- JoinHashTable.Probe
    - JoinHashTable.hash。复合hash值
    - JoinHashTable.ApplyBitmask2。取桶连表的首节点地址。

```go
func (jht *JoinHashTable) Probe(keys *chunk.Chunk) *Scan {
    ...
    hashes := chunk.NewFlatVector(common.HashType(), util.DefaultVectorSize)
    jht.hash(keys, curSel, newScan._count, hashes)
    jht.ApplyBitmask2(hashes, curSel, newScan._count, newScan._pointers)
    ...
    return newScan
}
```


scan的函数关系：
- Scan.Next
    - Scan.NextInnerJoin。执行inner join
    - Scan.NextMarkJoin。执行mark，anti mark join
    - Scan.NextSemiJoin。执行semi join
    - Scan.NextAntiJoin。执行anti semi join
    - Scan.NextLeftJoin。执行left join

###### inner join

整体结构：
- 确定与probe key相等的行。函数Scan.InnerJoin
    - 每个probe key会对应一个桶链表。
    - 遍历桶链表，寻找相等的节点。hash值相等，probe key与hash key不见得相等。
        - 对每行probe key。函数Scan.resolvePredicates
            - 其每列与链表首节点的每列比较。
            - 如果每列都相等，则此行probe key匹配了一行
            - 直到所有probe key与对应的首节点比较结束
        - 如果有匹配行，进入拼接结果阶段
        - 如果没有匹配行，说明此时链表首节点都不匹配。
            - 所有链表首节点移动到下一个节点。
            - 重复上面的过程，直到链表都结束。
    - 直到找到hash key相等的节点，或者没有相等的节点。
- 拼接inner join的结果。
    - join左子节点的数据。
    - join右子节点的数据。数据位置在TupleDataCollection中。

函数关系：
- Scan.NextInnerJoin
    - Scan.InnerJoin
        - Scan.resolvePredicates

**函数Scan.NextInnerJoin**:
函数gatherResult2从TupleDataCollection中取数据。与agg算子中的取法一致。
```go

func (scan *Scan) NextInnerJoin(keys, left, result *chunk.Chunk) {
    ...
    resCnt := scan.InnerJoin(keys, resVec)
    //有匹配的行
    if resCnt > 0 {
        //left part result
        result.Slice(left, resVec, resCnt, 0)
        //right part result
        //拼接join右子节点的数据
        for i := 0; i < len(scan._ht._buildTypes); i++ {
            vec := result.Data[left.ColumnCount()+i]
            scan.gatherResult2(
            vec,
            resVec,
            resCnt,
            i+len(scan._ht._keyTypes))
        }
        //链表移动到下一个节点
        scan.advancePointers2()
    
    }

}

```

**函数Scan.InnerJoin:**
```go
func (scan *Scan) InnerJoin(keys *chunk.Chunk, resVec *chunk.SelectVector) int {
    for {
        //匹配probe key与首节点
        resCnt := scan.resolvePredicates(
        keys,
        resVec,
        nil,
        )
        //有匹配的行
        if resCnt > 0 {
            return resCnt
        }
        //无匹配的行，所有链表移动到下一个节点
        scan.advancePointers2()        
        //所有链表的都结束。停止
        if scan._count == 0 {
            return 0
        }
    }

}

```

**函数Scan.resolvePredicates:**
实质是Match函数。在agg算子时讲过。
```go
func (scan *Scan) resolvePredicates(    
    keys *chunk.Chunk,
    matchSel *chunk.SelectVector,
    noMatchSel *chunk.SelectVector,
    ) int {
    ...
    noMatchCount := 0
    return Match(
        ...
        matchSel,
        scan._count,
        noMatchSel,
        &noMatchCount,
    )
}
```

###### mark, anti mark join
EXISTS，NOT EXISTS通常转为mark，anti mark。
结果会多出mark列，布尔值，其表示某行匹配与否。join节点的父节点采用mark列值为true的行就是mark join。采用false的行就是anti mark join。

过程：
- 确定所有行的匹配情况。函数Scan.ScanKeyMatches
    - 遍历桶链表，寻找相等的节点。hash值相等，probe key与hash key不见得相等。
        - 对每行probe key，计算匹配的行。见函数Scan.resolvePredicates
        - 如果有匹配行。`_foundMatch`。记录匹配的行。
        - 没有匹配行的链表首节点移动到下一个节点。
        - 如此直到所有链表结束
- 构建结果
    - join左子节点的数据。
    - mark列。`_foundMatch`值为true的行为true。

**函数Scan.ScanKeyMatches**
```go
func (scan *Scan) ScanKeyMatches(keys *chunk.Chunk) {
    matchSel := chunk.NewSelectVector(util.DefaultVectorSize)
    noMatchSel := chunk.NewSelectVector(util.DefaultVectorSize)
    for scan._count > 0 {
        //匹配probe key与链表首节点
        matchCount := scan.resolvePredicates(keys, matchSel, noMatchSel)
        noMatchCount := scan._count - matchCount
        //记录匹配的行
        for i := 0; i < matchCount; i++ {    
            scan._foundMatch[matchSel.GetIndex(i)] = true
        }
        //不匹配的行，继续比较。链表移动到下一个节点
        scan.advancePointers(noMatchSel, noMatchCount)
    }
}
```

###### semi, anti semi join
IN，NOT IN通常转为semi, anti semi。
结果只来自join左子节点的数据。semi保留匹配的行。anti semi保留不匹配的行。

过程：
- 确定所有行的匹配情况。函数Scan.ScanKeyMatches，见上面
- 构建结果
    - join左子节点的数据。semi需要匹配的行。anti semi保留不匹配的行。
```go
func (scan *Scan) NextSemiOrAntiJoin(keys, left, result *chunk.Chunk, Match bool) {
    sel := chunk.NewSelectVector(util.DefaultVectorSize)
    resultCount := 0
    for i := 0; i < keys.Card(); i++ {
        //Match为true。semi join
        //Match为false。anti semi join
        if scan._foundMatch[i] == Match {
            sel.SetIndex(resultCount, i)    
            resultCount++
        }
    }

    if resultCount > 0 {
        result.Slice(left, sel, resultCount, 0)
    }
}
```

###### left join
结果中，join左子节点的数据完全保留。与inner join的区别，不匹配的行，右边用NULL填充。

过程：
- 先当inner join执行一遍。函数Scan.NextInnerJoin，见上面。
- 构建结果
    - 匹配的行。inner join的逻辑
        - join左子节点的数据。
        - join右子节点的数据。
    - 不匹配行。left join加的逻辑
        - join左子节点的数据。
        - 右边补充NULL

```go

func (scan *Scan) NextLeftJoin(keys, left, result *chunk.Chunk) {
    //执行inner join
    scan.NextInnerJoin(keys, left, result)
    if result.Card() == 0 {
        //此时检测，还有多少行未匹配
        remainingCount := 0
        sel := chunk.NewSelectVector(util.DefaultVectorSize)
        for i := 0; i < left.Card(); i++ {
            if !scan._foundMatch[i] {
                sel.SetIndex(remainingCount, i)
                remainingCount++
            }
        }
        //有未匹配的行
        if remainingCount > 0 {
            //join左子节点的数据
            result.Slice(left, sel, remainingCount, 0)
            //右边补充NULL
            for i := left.ColumnCount(); i < result.ColumnCount(); i++ {
                vec := result.Data[i]
                vec.SetPhyFormat(chunk.PF_CONST)
                chunk.SetNullInPhyFormatConst(vec, true)
            }
        }
        
        scan._finished = true   
    }
}
```
#### cross join

cross join的执行过程：
- 输入数据
    - 输入右子节点的数据，保持列存。
- 执行join
    - 读左子节点的数据。
    - 遍历右子节点的数据块。拼接结果。

##### 初始化

cross join的层次管理结构：
- 顶层：CrossProduct。cross join管理结构
    - ColumnDataCollection
    - CrossProductExec
- 中层：
    - CrossProductExec。 cross join执行器
- 物理层：
    - ColumnDataCollection。 存储列数据块

按其阶段划分：
- build阶段：
    - ColumnDataCollection
- probe阶段：
    - CrossProductExec
    - ColumnDataCollection


##### 输入数据

列式存储结构：ColumnDataCollection
- 存储格式
    - 列存。
    - Chunk数组。每个Chunk都是满的，除了最后一个可能装不满。
    - 每输入一份数据，尽可能填满最后一个Chunk。
- 接口
    - Append。追加新数据到集合中。
        - 尽可能填满最后一个Chunk。空间不够时，会分配新的Chunk。
    - Scan。从指定chunk的指定行，读取一个Chunk。
        - 每读完一个Chunk，切换到下一个Chunk。

##### 执行

过程：函数CrossProductExec.Execute
- 对每一块左子节点的数据（简称左边数据块）
    - 确定右子节点的Chunk（简称右边数据块）。`
        - 第一次时，从ColumnDataCollection读取第一个Chunk。
    - 对左边数据块的每一行。函数CrossProductExec.NextValue
        - 与右边数据块组合成一个输出块。
            - 左边部分是这一行的重复
            - 右边部分是右边数据块
        - 如此直到左边数据块的行用完。
            - 左边数据块回到第一行。
            - 从ColumnDataCollection读取下一个Chunk。
            - 如果还有Chunk，重复上面的逻辑
            - 如果没有Chunk，从左子节点读取下一个块
    - 直到左子节点的数据读完

```go
func (cross *CrossProductExec) Execute(input, output *chunk.Chunk) (OperatorResult, error) {
    ...
    //切换左边数据块的下一行。
    //如果左边数据块的行用完，从ColumnDataCollection读取下一个Chunk。
    if !cross.NextValue(input, output) {
        //右边数据块读完。
        //从左子节点读取下一个块
        cross._init = false
        //RHS is read over.
        //switch to the next Chunk on the LHS and reset the RHS
        return NeedMoreInput, nil
    
    }
    
    var constChunk *chunk.Chunk
    //scanning chunk. refer a single value
    var scanChunk *chunk.Chunk
    for i := 0; i < output.ColumnCount(); i++ {
        ...
        constChunk = cross._scanChunk
        ...
        scanChunk = input
        ... 
        if tblIdx == -2 {
            //拼接右边数据块
            output.Data[i].Reference(constChunk.Data[colIdx])
        } else if tblIdx == -1 {
            //拼接左边数据块的某一行。此行重复多次。
            chunk.ReferenceInPhyFormatConst(
                output.Data[i],
                scanChunk.Data[colIdx],
                cross._positionInChunk,
                scanChunk.Card(),
            )
        }
    }
    output.SetCard(constChunk.Card())
    return haveMoreOutput, nil
}
```

### 其它算子

scan、project、filter比前面介绍的算子简单，不再展开。topN算子暂时不支持。


# 第二部分 存储引擎
# 第六章 表的内存结构

## 简介
数据库以一张张表存储数据。本文介绍表在内存中的组织方式。
## 内存结构

表数据分成多层结构。从上到下，
第一层，由row group组成的二排序树。每个row group有122880行（120K）组成。
第二层，每个row group 由多个列的数据column data组成。每个列数据column data又由column segment组成的二叉排序树组成。
第三层，每个column segment对应一个内存连续block。block默认大小是256KB。每个column segment最多放置60个vector。vector在block上连续存储。
第四层，vector由2K个数据组成。为列存最小的运算、读写单元。

通俗理解，
先对表数据按行切成一个个row group。
每个row group 内部又按表的列切成一个个column segment。
每个column segment 再切成一个个vector。

为了支持MVCC，还需要事务版本数据。这里简要提一下，在讲事务时，再具体讲。
事务对行insert,delete时，列在逻辑上组成一行。行版本数据分成两层：
第一层，version node,记录在每个row group 上。每个row group一个。
第二层，chunk info 对应2048行版本数据。每个version node 由60个chunk info。


事务可以对不同的列进行不同的update。每个列column data记录列版本数据。列版本数据分成两层：
第一层：update node,记录在column data上。
第二层：update info 对应2048行版本数据。每个事务有单独的update info。不同事务的update info组成版本链表。每个update node由60个update info链表组成。

统计信息由null值、不同值个数、总数、最大最小值。每个列有独立的统计信息。分成三层：
第一层：表级别stats。记录每个列的stats. 记录row group集合上。
第二层：记录在每个column data上。整个column data的统计信息。
第三层：记录在每个column segment上。


简要逻辑结构：
```text
表数据:
	row group 0;
	...
	row group i;
		column data 0;
		...
		column data j;
			column segment 0;
			...
			column segment k;
				vector 0;
				...
				vector 59;
				...
				update node 0;
				...
				update node x;
					update info list 0;
					...
					update into list 2047;
				...
				update node 59;
				stats ;
			...
			column segment o-1;
			stats;
		...
		column data m-1;
		...
		version node
			chunk info 0;
			...
			chunk info 59;
	...
	row group n-1;

```


## 数据结构

### 表

用`DataTabe`表示一表的内存结构。
- 元信息：名称，列定义，约束，索引等
- 数据载体：row group集合。

### row group
row group 按续拼接成表的数据。

row group集合`RowGroupCollection`存表的所有内存数据、版本数据和stats。
- 总行数。表有多少行数据。
- row group树。row group组成的二叉排序树。

row group树`RowGroupSegmentTree`存储所有的row group。
- 按照每个row group的开始行号排序。

`RowGroup`
- 记录连续的120K行数据。
- 行版本信息
- 每列数据

```go
RowGroup {
	开始行 start
	列数据 []*ColumnData
	行版本信息 VersionNode
}
```


行版本信息VersionNode：
```go

VersionNode{
	[60]ChunkInfo
}

ChunkInfo{
	开始行
	//vector info
	[2048]insert id
	[2048]delete id
}
```
### column data

column data逻辑表达一个row group内部某一列数据。
- 元信息：开始行，数据类型等
- column segment树。
- 列版本信息

```go

ColumnData {
	开始行 start
	type
	*ColumnSegmentTree
	列版本信息 *UpdateSegment
}

```

column segment树`ColumnSegmentTree`存储所有的column segment。
- 按照开始行号排序

column segment
- 元信息：类型、读写数据接口等
- block信息：block id和offset

```go
ColumnSegment{
	开始行
	type
	读写数据接口 CompressFunction
	BlockId
	Offset
}
```

列版本信息外层包装在`UpdateSegment`中：
- 列版本信息。
- 读写列版本信息的接口

实际版本信息记录在`UpdateInfo`
- 版本号：事务ID
- 操作记录
- 链表指针
```go
UpdateSegment{
	列版本信息 UpdateNode
}

UpdateNode{
	[60]UpdateNodeData
}

UpdateNodeData{
	版本信息 UpdateInfo
	操作的行号 []rowid
}

UpdateInfo{
	版本号
	操作记录；
	prev,next UpdateInfo
}
```

### 统计信息

`BaseStats`记录zonemap、行数、不同值数。

在之上封装成`SegmentStats`记录column data和column segment的统计信息。

`ColumnStats`和`TaleStats`则是在表级别层面汇总的统计信息。记录在row group集合上。

`DistinctStats`统计不同值。
```go
BaseStats{
	null值；
	不同值数；
	行数；
	minmax值
}

SegmentStats{
	BaseStats
}

TableStats{
	[]ColumnStats
}

ColumnStats{
	BaseStats
	DistinctStats
}

DistinctStats{
	hyperloglog
	count
}
```

## 小结

简要介绍了表在内存中的数据组织方法。数据构成成分。引入概念row group、segment。

# 第七章 事务

## 简介
在事务数据库中，借助事务才能保证读写数据的正确性。本文介绍事务系统的设计

## 事务系统
简要的说，事务是对数据库数据的读写序列。
以事务生命周期为线索，串起相关模块，来理解事务系统的工作机制。
事务生命周期：
- 创建事务。为事务分配id和开始时间戳。
- 事务读数据。并发事务环境下，一个事务能读到哪些数据，并如何读到这些数据。
- 事务写数据。新增、删除、更新都属于写的范畴。生成undo log。冲突检测。
- 提交事务。为事务分配提交时间戳。生成redo log并落盘。有可能出发checkpoint。
- 撤销事务。回滚事务数据。
- GC事务。事务已经提交，但是事务的数据有可能被其他事务引用，还不能立即从系统删除事务对象。

设计了一些模块，共同完成事务功能。
- 事务管理器。创建、提交、销毁、GC事务。维护活跃事务队列。触发checkpoint.
- 事务对象。维护时间戳，记录undo log，事务写的数据。提交操作，回滚操作。
- walog。事务提交时，记录redo log。
- replay。存储引擎启动时，重放未checkpoint的redo log。
- checkpoint。checkpoint为动词时，表示打checkpoint的行为：redo log与表已有数据结合，生成最新事务修改后的数据。checkpoint为名词时，表示打checkpoint之后的结果。
- 数据多版本。多版本的生成、维护、销毁、可见性。

## 事务管理器

`TxnMgr`创建、提交、回滚事务。
维护以下状态：
- 当前开始时间戳。整数值。从2开始。每创建新事务后加1。小于`2^62`
- 当前事务id，整数值。从`2^62`开始。每创建新事务后加1。大于等于`2^62`
- 最低活跃事务id和最低活跃事务开始时间。不一定来自同一个活跃事务。
- 活跃事务队列。已经创建未commit或rollback的事务。
- 已经提交事务队列。已经commit但未GC的事务。
- 待GC事务队列。能GC但还未GC的事务。

```go
TxnMgr{
	currentStartTs uint64
	currentTxnId  uint64
	lowestActiveId  uint64
	lowestActiveStart  uint64
	activeTxns []Txn
	committedTxns []Txn
	oldTxns []Txn
}
```

`Txn`表示一个事务对象。
有以下状态：
- 名词。标识作用。
- 开始时间戳。
- id.
- commit时间戳。提交时更新。
- undo log。事务操作日志。
- local存储。事务写的但未提交的数据。
- 活跃query id. GC时用到。
- 最高活跃query id.GC时用到。

```go
Txn{
	name
	startTs
	id
	commitid
	undoBuffer UndoBuffer
	local storage
	active query id
	highest active query id
}
```

### 创建事务

初始化`Txn`对象
- 分配开始时间戳
- 分配事务id
- 提交id = 0
- 初始化undo log
- 初始化local 存储

并记录`Txn`对象到`TxnMgr`的活跃事务队列。

### 提交事务

checkpoint会在后面单独讲。这里只讲不带checkpoint的提交框架。
- 分配commit时间戳。也是从`TxnMgr.currentStartTs`分配。小于`2^62`。小于事务id。大于事务开始时间戳。
- `Txn`对象的提交操作。后续会单独讲。
- `TxnMgr`GC事务。

### 回滚事务
- `Txn`对象的回滚操作。后续会单独讲。
- `TxnMgr`GC事务。

### GC事务
- 计算最低活跃事务id、最低活跃事务开始时间、最低active query id。遍历活跃事务, 分别求三个值的最小值。
- 从活跃队列删除`Txn`对象
- 如果是提交事务，`Txn`对象进已经提交事务队列。
- 如果是回滚事务，`Txn`对象进GC队列。并记录此时的活跃query id.
- 清理已经提交事务队列，找出能可以去GC的`Txn`对象，并进入GC队列。并给`Txn`对象最高活跃query id赋值，用于后续GC。判断条件： commitId < 最低活跃事务开始时间
- 清理GC队列，找出能被GC的事务。判断条件：最高活跃query id < 最低active query id。

## 事务对象
与数据直接相关的组件：
- UndoBuffer。记录undo log.
- LocalStorage。local存储。事务已经写入但未提交的数据。

事务有insert、delete、update、catalog操作，一一对应有undo log entry。
UndoBuffer 是undo log entry的数组。不同的操作类型，会在不同的时机创建entry。这个在后面会具体讲。
```go
UndoBuffer{
	undo log entry []buffer ptr
}

```

LocalStorage记录事务对每张表写的数据。
```go
LocalStorage{
	txn
	tableStorage map<DataTable,LocalTableStorage>
}

LocalTableStorage{
	DataTable 对应的表
	RowGroupCollection 事务对此表写入的数据。
}
```

### 事务提交操作
`Txn`提交事务。
- LocalStorage提交操作
- UndoBuffer提交操作
- walog刷盘

#### LocalStorage提交操作

事务提交时，要先提交`LocalStorage`的数据。
实质是遍历每个表，将事务写的数据合并到表中去。并更新索引和生成undo log.

```go
func (LocalStorage) Commit() {
	for table,localTableStorage := LocalStorage.tableStorage {
		LocalStorage.Flush(table,localTableStorage)
	}
}

func(LocalStroage) Flush(table,localTableStorage){
	if （表为空 或者 批量append）且事务无删除操作 {
		//特殊情况
		更新索引;
		将localTableStorage的数据直接挪动到表中；
	}else{
		//一般情况
		将localTableStorage中的数据读出来，append到表中并更新索引
	}

	生成undo log insert entry = {start row，count,table}
}

```

其中`Flush`函数完成合并数据、更新索引、生成undo log。
- 合并数据。将`localTableStorage`中的数据读出来，append到表中。同时也能插入索引。表的append操作和索引的内容后续再讲。
- 生成undo log insert entry。记录insert的内容：开始rowid，数据总行数，目标表对象。

#### UndoBuffer提交操作

事务提交时，在`LocalStorage`提交后，提交`UndoBuffer`。
遍历每个undo log entry,依据entry类型，基于entry 生成redo log写入walog.

```go
func(UndoBuffer)Commit(walog,commitid){
	for undo log entry :=  UndoBuffer.logs{
		CommitEntry(entry type,entry buffer)
	}
}
```
`CommitEntry`对insert、delete、update、catalog类型的undo log entry，采用不同的做法生成redo log,并更新版本信息。

- insert entry
在`LocalStorage`提交时，已经将数据append表中，并且生成了insert entry={开始rowid,总行数，表}。
提交insert entry，实质是将表中由insert entry圈定的数据再读出来，写入walog. 这些再读出来的数据就是insert redo log。
写完walog后，更新insert entry圈定的数据的版本信息，即填充事务的commitid。
```go
//写walog
insert entry.table.WriteToLog(walog,start rowid,count){
	table.ScanTablesegment(start rowid, count,func(data){
		walog.WriteInsert(data)
	})
}

//更新版本信息，回填commitid
insert entry.table.CommitAppend(commitId,start rowid,count)
```

- delete entry
后续会讲delete entry是如何生成的。这里只介绍delete entry的提交方式。
delete entry={base row id,count,row offsets,table,ChunkInfo}，表示对表删除了哪些行、总行数。对应的ChunkInfo.
row offsets是相对于base row id的偏移。实际被删除的row id = base row id + row offset.
提交delete entry，是将实际被删除的row id写入walog.
更新版本信息ChunkInfo中每行的commitid。
```go
//算时间被删除row id
for i  < delete entry.count {
	row ids[i] = base row id + row offsets[i]
}
//写walog
walog.WriteDelete(row ids);

//更新版本信息
delete entry.ChunkInfo.CommitDelete(
	commitid,
	delete entry.rows,
	delete entry.count)
```

- update entry
后续会讲update entry是如何生成的。这里只介绍update entry的提交方式。
update entry = {UpdateSegment, vectorIndex, versionNumber,count,tuples,update entry ptr}，表示对RowGroup的某个列的某个Vector中的某些行做了更新操作。RowGroup可以存60个Vector,每个Vector 2048行。
提交update entry,将update后的新值和rowid读出来，写入walog。
更新ChunkInfo的versionNumber,给版本信息填commit.
```go

updateChunk {
	updated data;
	rowids;
}

//从版本链中取出update后的新值。实质是版本链表头结点中的值。
update entry.UpdateSegment.FetchCommitted(update entry.vectorIndex,updateChunk.updated data);

//计算row id
start rowid = column.start rowid + update entry.vectorIndex * 2048;
for i < update entry.count{
	updateChunk.rowids[update entry.tuples[i]] = start rowid + update entry.tuples[i];
}

//写walog
walog.WriteUpdate(updateChunk)

//更新版本信息
update entry.versionNumber= commitId
```

- catalog entry
先跳过，后续介绍catalog时再讲。


### 事务回滚操作
`Txn`回滚事务。
- LocalStorage回滚操作
- UndoBuffer回滚操作

#### LocalStorage回滚操作
事务对表的修改未提交，回滚时，只需要将`LocalTableStorage`删除即可。

#### UndoBuffer回滚操作
undo log相对复杂。undo log entry生成时，以追加方式进入UndoBuffer。回滚时，逆向遍历undo log entry，依据entry类型，回滚entry.

- insert entry
insert entry={开始rowid,总行数，表}。
回滚insert entry时，是将表中从`开始rowid`开始的行都删掉。也会删除索引中的数据。
通过`开始rowid`计算所属的RowGroup。将此之后的RowGroup全部删掉。此RowGroup内部，对每列数据ColumnData计算`开始rowid`所属的`ColumnSegment`。将此之后的所有`ColumnSegment`删掉。此`ColumnSegment`内部，清理掉block上`开始rowid`之后的数据即可。
同时删掉行版本信息。
```go
insert entry.table.RevertAppend(insert entry.start rowid,insert entry.count){
	table.rowGroupCollection.RevertAppend(start rowid,count)	
}

table.rowGroupCollection.RevertAppend(start rowid,count){
	segIdx :=计算start rowid所在的RowGroup;
	删掉从segIdx+1开始的所有RowGroup;
	
	所属RowGroup.RevertAppend(start rowid);
}

RowGroup.RevertAppend(start rowid){
	删除版本信息
	for columnData in RowGroup{
		columnData.RevertAppend(start rowid);
	}
}

columnData.RevertAppend(start rowid){
	segIdx := 计算start rowid所在的columnSegment;
	删掉从segIdx+1开始的所有ColumnSegment;
	
	所属ColumnSegment.RevertAppend(start rowid);
}

ColumnSegment.RevertAppend(start rowid){
	调整count即可清理block上的数据
}
```

- delete entry
delete entry={base row id,count,row offsets,table,ChunkInfo}，表示对表删除了哪些行、总行数。对应的ChunkInfo.
row offsets是相对于base row id的偏移。实际被删除的row id = base row id + row offset.
回滚delete entry,是对行版本信息，打上特殊的标记，使删除无效。

```go
ChunkInfo.CommitDelete(-1,delete entry.row offsets,delete entry.count){
	for i < count{
		ChunkInfo.deleted[row offsets[i]] = -1;
	}
}

```

- update entry
update entry = {UpdateSegment, vectorIndex, versionNumber,count,tuples,update entry ptr}，表示对RowGroup的某个列的某个Vector中的某些行做了更新操作。RowGroup可以存60个Vector,每个Vector 2048行。
回滚update entry,是将最新的列版本信息中，此事务update的最新值 恢复到此事务update的旧值。最新的列版本信息存在于版本链表头结点中。
再将此事务产生的版本从版本链表中删掉。

```go
update entry.UpdateSegment.RollbackUpdate(update entry){
	//将列版本信息恢复到旧值。
	//实质是将update entry的中的旧值，更新到版本链表头结点中。
	head := updateSegment.UpdateNode.Info[update entry.vectorIndex].UpdateInfo
	for i < update entry.count {
		head.Data[j] = update entry.data[i]
	}

	从版本链表中删除此版本；
}

```

- catalog entry
先跳过，后续介绍catalog时再讲。

## walog
walog参与了事务系统的多个环节
- 事务提交时，将redo log存入walog;
- replay时，基于未checkpoint的redo log构建版本数据
- checkpoint时，将未checkpoint的redo log与表中数据合并落盘

walog管理redo log。物理上是文件，顺序存储redo log entry. 写与读redo log entry. 
写redo log entry实质是redo log entry的序列化。读redo log entry实质是redo log entry的反序列化。
不同的redo log entry有不同的序列化和反序列化的接口。

redo log entry分类
- insert,delete,update。事务不同的写操作产生的。
- flush。表示一个事务提交结束。两个flush之间entry表示一个独立事务产生的。
- checkpoint。在checkpoint entry之前的entry都已经应用到表上了，不再需要了。
- create table, create schema,use table。创建表、schema和用表，后续catalog时再讲。

`WriteAheadLog`是walog对象。
每种redo log entry类型，有单独的接口。
- WriteInsert,WriteDelete,WriteUpdate
- Flush
- WriteCheckpoint
- WriteCreateTable,WriteCreateSchema,WriteSetTable

## replay

存储引擎启动时，先加载元信息。基于这些元信息，加载checkpoint。之后再读redo log，并replay redo log entry.
replay操作，实际是顺序读取每个entry，重新对表执行entry对应的操作，形成表的版本数据。

replay分两阶段：
- 扫描walog,找到checkpoint entry，拿到checkpoint block id. 正常情况下，做多个checkpoint entry。
此阶段不会应用每个entry.
如果checkpoint block id 与 元数据中的block id相同，说明walog已经应用到表上了。此时replay结束。
- 扫描walog,将每个entry应用到表上。

每种redo log entry类型，有不用的应用方法。
- insert，delete，update。对entry中的数据，分别insert,delete,update到当前表对象中。
- flush。提交当前事务。并创建下一个新事务。
- checkpoint。记录checkpoint block id.
- create table。创建一个新表。
- create schema。创建一个新schema.
- use table。从catalog取当前操作的表对象。

replay过程中事务对表对象的操作，不会再生成redo log，也不会触发checkpoint. replay 成功后，walog被清空。

## checkpoint
checkpoint是将未checkpoint的redo log与表中数据合并落盘。
`TxnMgr`在提交事务时，会检测是否能在此事务提交成功后，进行checkpoint.
checkpoint需要满足一定的条件。
- 同时只有一个checkpoint操作。
- 已经提交的事务是否都GC了。
- 此事务的redo log 大小 + walog size 是否超过阈值
- 此事务是否提交成功

在此事务提交成功后，再去做checkpoint的操作。要明确的是checkpoint不需要事务参与，期间也没有活跃事务会影响到系统数据。

分几步理解checkpoint过程。
- checkpoint整体操作流程是怎么样的。
- 被checkpoint的数据有哪些。
- 数据持久化后的layout是怎么样
- 存储引擎启动后，怎么使用checkpoint数据。

### checkpoint执行框架

数据库的内存数据是多层次的
- schema。至少一个schema. 每个schema由多个表组成。
- 表。
- RowGroup集合。
- RowGroup
- ColumnData
- ColumnSegment
- Vector
- 行版本数据和列版本数据
- stats

简洁的说，checkpoint就是按层次关系持久化这些数据。
在程序框架上，checkpoint是多层循环。

```go
for sch := schemas {
	持久化schema元数据；
	for tab := sch.tables {
		for rowGroup := tab.RowGroups{
			for columnData := rowGroup.Columns{
				for columnSegment := columnData.ColumnSegments{
					for  vector := columnSegment.vectors{
						读block数据;
						读版本数据；
						持久化；
					}
				}
			}
		}
		持久化RowGroup元数据和行版本数据；
	}
}
```

### 持久化数据
从循环内层向外层介绍持久化。
分多个方面讲每层的持久化：
- 要持久化的数据有哪些，在哪儿，怎么读取它们
- 持久化数据的方法是什么
- 数据被持久化后，放哪儿了。形成了哪些元数据。
- 元数据该放哪儿

#### 列的持久化

对应最内层的循环。也是最复杂的层次。

```go
for columnSegment := columnData.ColumnSegments{
	for  vector := columnSegment.vectors{
		读block数据;
		读版本数据；
		持久化；
	}
}
```

相关的数据有：
- 每个ColumnSegment中block上的数据。直接读每个vector即可。
- 列版本数据。在ColumnData.UpdateSegment上。版本链头结点就是最新的数据。

要持久化的数据 = vector+列版本数据。即用版本数据中对应此vector的最新数据替换vector中行。

分配一些新的ColumnSegment。要持久化的数据会追加到这些新ColumnSegment的block. 
最终每个新ColumnSegment会从内存中写入存储，同时获得存储位置={blockid,offset}. 这些新的ColumnSegment会有一组存储位置={blockid,offset}。

最终用这些新的ColumnSegment替换原先ColumnData中的ColumnSegment。

```go

func(ColumnData)Checkpoint(){
	nodes := ColumnData.ColumnSegments;
	ColumnDataCheckpointer.Checkpoint(nodes)
	ColumnData.ColumnSegments = newNodes;
	返回元数据；
}

func ColumnDataCheckpointer.Checkpoint(nodes){
	WriteToDisk(){
		分配新的ColumnSegment 
		ScanSegments(){
	        for 旧ColumnSegment := nodes{
		        for rowIdx := 旧ColumnSegment.Count {
			        CheckpointScan(rowIdx,count){
				        vector = 读旧ColumnSegment.block；
				        vector = vector + 列版本数据更新；
			        }
			        vector 追加到 新ColumnSegment ;
		        }
	        }
        }
        这些新的ColumnSegment 写入存储，获取存储位置;
        元数据 = 存储位置{blockid,offset}的数组；
        newNodes = 这些新的ColumnSegment
	}
}
```

#### RowGroup的持久化
RowGroup的持久化过程分为：
- 每一列先持久化。并拿到持久化后的列元数据数组。就是上面环节。
- 每个列元数据再持久化，并得到存储位置。又获得列元数据的存储位置的数组。类似二级指针。
```text

列元数据的存储位置的数组
	列0元数据的存储位置;
	...
	列i元数据的存储位置;
		ColumnSegment 0 的存储位置；
		...
		ColumnSegment M-1 的存储位置；
	...
	列N-1元数据的存储位置;

```

 RowGroup的元数据 = 行版本信息 + 列元数据的存储位置的数组。

```go
func(RowGroup) Checkpoint(){
	列元数据数组=WriteToDisk(){
		for columnData := rowGroup.Columns{
			列元数据=columnData.Checkpoint()
		}
	}

	for 列元数据 := 列元数据数组{
		列元数据的位置 = WriteDataPointer(){
			WriteColumnDataPointers(){
				for ColumnSegment位置 := 列元数据{
					将ColumnSegment位置写入存储
				}
			}
		}
	}
	返回RowGroup元数据；
}
```


#### 表的持久化
处理过程：
- 持久化每个RowGroup,得到RowGroup元数据数组
- 存储RowGroup元数据数组。并得到存储位置。
- 将RowGroup元数据数组的存储位置 再次 存储到meta block.
- 持久化索引的数据。相对简单，不再细说。

```text
RowGroup元数据数组的存储位置：
	RowGroup 0 的元数据;
	...
	RowGroup x-1 的元数据;

```

表的元数据 = RowGroup元数据数组的存储位置。

```go

func(DataTable) Checkpoint(){
	for rowGroup := tab.RowGroups{
		RowGroup元数据 = rowGroup.Checkpoint()
	}
	FinalizeTable(){
		for RowGroup元数据 := RowGroup元数据数组{
			for 列元数据的存储位置 := RowGroup元数据.列元数据的存储位置的数组 {
				写入存储
			}
			行版本信息 写入存储
		}
		RowGroup元数据数组的存储位置 存储到meta block;
		持久化索引；
	}
}

```

#### Schema的持久化
在本文中schema实质是database的含义，包含至少一张表。
- 每个schema的每个表逐一持久化。schema的定义和表的定义一并持久化。
- walog写入checkpoint entry,flush entry。标记checkpoint.
- 持久化database header。记录meta block. 相对简单，不细说。
- 清空walog.
```go

func(CheckpointWriter)CreateCheckpoint(){
	for sch := schemas {
		WriteSchema(sch){
			schema定义持久化；
			for tab := sch.tables{
				WriteTable(tab){
					table定义持久化；
					table.Checkpoint()
				}
			}
		}
	}

}
```


### 数据layout
在物理存储上，数据是按block组织的。block上的数据是什么，由元数据指定。
元数据分为：
- 固定元数据。database header在文件的开头。
- 动态元数据。schema和表定义。RowGroup元数据、列元数据的元数据、列元数据。行和列版本。
表的非元数据和元数据在block层面上是紧挨着的、分散的、连续的。这是难以说清楚的。
ColumnSegment 可能会横跨多个block。这些block不保证连续排列。 
依据数据逻辑关系，从顶层元数据往下直到列数据。
```text
database header:
	pointer to metablock;

metablock:
	schema count;
	schema i 定义;
		table count；
		table j 定义；
		table j RowGroup元数据数组的地址；
		table j 索引数据的地址个数；
		table j 索引数据的地址数组；
			table j 索引 x的地址；

某个block：
	table j RowGroup元数据数组；
		RowGroup count；
		RowGroup k 元数据；
			列元数据数组的地址；
			行版本信息；


某个block：
	RowGroup K 的列元数据数组：
		列 m 元数据；
			列 m 的数据占据block的地址count；
			列 m 的第n个block的地址；

某个block：
	列 m 的第n个block 的数据；

某个block：
	table j 索引 x的数据；
```


### 读取checkpoint
依据layout,存储引擎启动时，先读database header,拿到meta block的数据。
从metablock中，依次能拿到schema定义。每个表的定义和RowGroup元数据数组的地址。
之后，依次读每个RowGroup，每个ColumnSegment 读到表的所有数据。

## 小结
详细介绍了事务系统的`TxnMgr`，`Txn`对象，walog。解释了walog基础作用。着重讲解了replay、checkpoint工作机制。它们有机结合支撑事务的有序、安全、原子、持久化的运行。

# 第八章 插入数据

## 简介
通过更新类语句（insert，copy等）向表插入数据。表需要提供插入数据的接口。本文介绍这些接口以及数据插入表的过程。

插入数据涉及的组件：
- 表对象。数据要存入的表。
- 事务系统。
- 内存结构：RowGroup集合、RowGroup、ColumnData和ColumnSegment等。

插入数据的特征：
- 只追加。逻辑上是在表的尾部插入。数据在表中不是有序的。
- 分成两个阶段：事务未提交时，新数据在事务local storage中。提交时，会与表对象中的已有数据合并。
- 用状态记录追加操作的进展。

以从抽象到具体的方式来理解。RowGroup在逻辑上表示120K行数据。120K行数据不是全在一起的。内部又按列做了一层划分。列内部又按物理block再做一层划分。数据本身是记录在的block内存上的。ColumnSegment是物理block的逻辑抽象。
## 状态
列的数据类型可能不同、ColumnSegment的block上的空间可能不同。决定了Append状态不可能是单一状态，而是层次结构。多个状态组织共同构成了Append状态。

状态的层次结构：
- 数据先进事务local storage。事务生命周期内，可能会向多个表写入数据。写每个表时都需要单独的状态。最顶层是LocalAppendState。
- 内存结构层次。
	- 表级别：TableAppendState
	- row group级别：RowGroupAppendState
	- 列数据级别：ColumnAppendState。
	- 块级别：CompressAppendState。内存block。

状态层次关系：
```go
LocalAppendState{
	TableAppendState{
		RowGroupAppendState{
			[]ColumnAppendState{
				CompressAppendState{
					
				}
			}
		}
	}
}

```

每个状态会有一些字段，在不同阶段需要不同的字段。先理解每字段的含义，在后序讲插入的过程时，会再讲这些字段。


| 状态                  | 字段                | 含义                                             | 初始值                                               | 作用阶段     | 变更                                   | 备注  |
| ------------------- | ----------------- | ---------------------------------------------- | ------------------------------------------------- | -------- | ------------------------------------ | --- |
| TableAppendState    | _rowStart         | 已有数据的总行数 或者新数据的开始行号。                           | 已有数据的总行数                                          | 初始化阶段    | 初始化一次，后续不变                           |     |
| TableAppendState    | _currentRow       | 新数据的开始行号。_currentRow - _rowStart 表示已经插入数据的总行数。 | _rowStart                                         | 执行阶段     | 每插入成功一批数据会更新。                        |     |
| TableAppendState    | _totalAppendCount | 成功插入的总行数                                       | 0                                                 | 执行阶段     | 每插入成功一批数据会更新。                        |     |
| TableAppendState    | _startRowGroup    | 要插入的第一个RowGroup                                | 插入的第一个RowGroup                                    | 初始化+结束阶段 | 初始化后不再变更                             |     |
| TableAppendState    | _remaining        | 剩余的数据量                                         | 向事务local storage 插入数据阶段，值为0；同表中数据合并阶段，为要插入数据的总行数。 | 初始化；执行阶段 | 每插入成功一批数据会减掉一批的值。                    |     |
| RowGroupAppendState | _rowGroup         | 要插入数据的RowGroup                                 | 插入的第一个RowGroup                                    | 初始化+执行   | 每次要更新RowGroup时，换成新RowGroup           |     |
| RowGroupAppendState | _offsetInRowGroup | RowGroup中已有的数据量                                | 插入的第一个RowGroup的数据量                                | 初始化+执行   | 每插入成功一批数据会更新。换新的RowGroup时，也会更新       |     |
| ColumnAppendState   | _current          | 要插入的ColumnSegment                              | 要插入的第一个ColumnSegment                              | 初始化+执行   | ColumnSegment装满时，要换新的ColumnSegment   |     |
| ColumnAppendState   | _appendState      | 指向要插入数据的block                                  | ColumnSegment.block                               | 初始化+执行   | 一个ColumnSegment满时，要换新的ColumnSegment。 |     |

## 插入数据过程
分为几步：
- 初始化阶段。给状态赋初值。
- 插入阶段。数据逐层进入并最终到达ColumnSegment的block上的过程。
- 结束阶段。数据插入完成时，更新版本信息。

### 初始化

1，分配局部存储`LocalTableStorage`。
- 表对象。要写入的表对象。
- RowGroup集合。数据先存入此处。
- 删除的行数。
- 索引信息。

2，初始化TableAppendState
- `_rowStart`。用RowGroup集合的数据行数做初始值。在向局部存储插入时，值应该是0.
- `_currentRow`。用_rowStart初始化。新数据的行号从此值开始。
- `_totalAppendCount`。总插入数据量。
- `_startRowGroup`。新数据要插入的第一个RowGroup。事务向表第一次插入数据时，需要先创建新的RowGroup，再给_startRowGroup赋值。
- `_remaining`。事务向表第一次插入数据时，值为0.

3，初始化RowGroupAppendState
- `_rowGroup`。当前正要插入的RowGroup。
- `_offsetInRowGroup`。新数据在RowGroup中的偏移。RowGroup有120K行的总限制。
4，初始化ColumnAppendState
- `_current`。要插入的ColumnSegment。事务向表第一次插入数据时，需要先创建新的ColumnSegment。
- `_appendState`。block的内存。

### 插入
数据从最外层的接口到最终ColumnSegment的block内存上，经过多个内存层次结构。在每层，状态确定数据的流向。在每层接口，基于状态的分流逻辑，分流完成后，再状态。

从最外层接口到最内层接口，数据经过的接口：

| 接口                        | 数据形式          | 状态                  |
| ------------------------- | ------------- | ------------------- |
| DataTable.LocalAppend     | chunk         | LocalAppendState    |
| LocalStorage.Append       | chunk         | LocalAppendState    |
| RowGroupCollection.Append | chunk         | TableAppendState    |
| RowGroup.Append           | chunk         | RowGroupAppendState |
| ColumnData.Append         | vector        | ColumnAppendState   |
| ColumnData.AppendData     | UnifiedFormat | ColumnAppendState   |
| ColumnSegment.Append      | UnifiedFormat | ColumnAppendState   |
| CompressAppend            | UnifiedFormat | CompressAppendState |
- DataTable.LocalAppend。验证数据符合表的约束：主键，唯一健，not null（目前只支持这些）。
- LocalStorage.Append。数据先插入索引。要为每行数据计算rowid。先计算第一行的rowid，之后每行累加。
- RowGroupCollection.Append。
	- 计算当前RowGroup还能插入多少行。120K行上限 减去 当前RowGroup中已经插入的数据行数。
	- 为剩余数据创建新的RowGroup。变更RowGroupAppendState指向新RowGroup。
- RowGroup.Append。数据按列分别插入到每个列上。
- ColumnData.Append。vector转UnifiedFormat。
- ColumnData.AppendData。
	- 尽可能将数据插入到当前ColumnSegment。
	- block内存空间不够时，分配新ColumnSegment。并指向新ColumnSegment的block内存。
- ColumnSegment.Append。数据存入block内存的指定位置。
- CompressAppend。数据在block内存上写入的具体实现方法。根据数据类型有不同实现。这里不赘述。

### 结束

结束阶段是发生在一批数据插入结束。反应插入成功的结果信息。结束阶段与事务提交阶段是不同概念。结束阶段一定发生在事务提交前。不代表事务要提交。
- 完结状态。
- 更新版本信息。

从外层到内层，接口相对简单。

| 接口                                | 状态               |
| --------------------------------- | ---------------- |
| DataTable.FinalizeLocalAppend     | LocalAppendState |
| LocalStorage.FinalizeAppend       | LocalAppendState |
| RowGroupCollection.FinalizeAppend | TableAppendState |
- RowGroupCollection.FinalizeAppend
遍历新数据所在的所有RowGroup（从_startRowGroup开始），给它们增加行版本信息。

## 小结
介绍了相关的状态、分流逻辑。内存的层次结构、分层的状态增加了理解插入过程的难度。

# 第九章 update数据

## 简介
将表的列从旧值换成新值。表对象提供update接口。本文介绍update的逻辑过程。

update的特点：
- 输入：rowid、列索引、新值。
- 多个事务能同时更新一张表。更新的行列可能交叉。
- 旧值可以在表对象上 或 在事务的local storage 中。如果在表对象上，需要版本信息。如果在事务的local storage中，只有此事务可见，无需版本信息。

## update过程
- 用rowid定位旧值所在的RowGroup、ColumnData。
- 用列索引确定要更新的列
- 在列数据上加版本信息

从外层到内层涉及多个接口：

| 接口                        | 参数           | 说明                     |
| ------------------------- | ------------ | ---------------------- |
| DataTable.Update          | rowid，列索引，新值 | update的入口              |
| LocalStorage.Update       | rowid，列索引，新值 | local storage的update入口 |
| RowGroupCollection.Update | rowid，列索引，新值 | RowGroup集合的update入口    |
| RowGroup.Update           | rowid，列索引，新值 | RowGroup的update接口      |
| ColumnData.Update         | rowid，列索引，新值 | 列数据 update接口           |
| ColumnData.Fetch          | rowid        | 取旧值                    |
| UpdateSegment.Update      | rowid，列索引，新值 | 列版本 update接口           |
- DataTable.Update按rowid对数据分流。rowid属于事务local storage范围内的，进入LocalStorage.Update，在此事务内部存储中进行更新操作。rowid在表对象上，进入RowGroup集合的update接口。
- LocalStorage.Update。事务local storage的update接口。事务为每张表关联的局部存储`LocalTableStorage`，其内部也是RowGroup集合。最终也用了RowGroup集合的update接口。
- RowGroupCollection.Update。表对象和事务局部存储最终都用到此update接口。
- RowGroup.Update。更新在此RowGroup上的列。
- ColumnData.Update。用rowid取旧值。版本信息需要保存旧值。
- UpdateSegment.Update。构建版本链。

### 确定RowGroup

 RowGroupCollection.Update 完成rowid拆分。
一批rowid。某些rowid在同个RowGroup。另外一些rowid在其它RowGroup。 将同属一个RowGroup的rowid收集起来，再分为2K行一组（vector大小），一组组的交由RowGroup update。分属于多个RowGroup，就执行多次。

### 取旧值

事务undo时，恢复旧值。旧值要记录在列版本系统中。在update时，只有rowid和新值。必须取旧值。
ColumnData.Fetch 读取旧值，读取rowid所属的vector。读取过程，简要得说，确定rowid所在的ColumnSegment，再从block内存中读取vector。详细的读取过程，在讲读数据时再讲。

### 构建版本信息
多个事务可能对同一个vector中的数据行进行update。产生了数据的多个版本。事务只能读到它可见的版本。

每个RowGroup 120K行，分成60个vector（2K行）。每个vector有一个版本链，表示关联的版本信息。

UpdateSegment.Update完成版本信息，是最复杂的环节。

分为几步：
- 对rowid递增排序。
- 如果对应的vector，没有版本链，要创建版本链，并加入此事务的版本信息。
- 如果对应的vector，有版本链表。
	- 版本链表上，无此事务的版本信息。
	- 版本链表上，有此事务的版本信息。

#### 创建版本链表

没有版本链表，要创建版本链表，并为此事务创建版本节点。每个vector有一个版本链表。同一个vector中的行共享同一个版本链表。一个RowGroup有60个vector，每个列就有对应的60个版本链表。

版本链表的结构：
- 头节点：永远放置新值。即使有多个事务更新同一个vector，也放置每个事务update的新值。
- 非头节点：每个事务都有一个唯一节点，记录事务update前的旧值。

```text
_______     __________    __________
|头节点| ->  |事务i版本 |-->|事务j版本 |->....
-------     ----------    ----------

```

版本节点：
- `_versionNumber`。版本号（事务id）
- `_vectorIndex`。所属的vector索引
- `_N`。更新的行数(< 2K)。
- `_tuples`。vector内部的下标 = rowid - 此vector首行rowid 。
```go
UpdateInfo{
	_versionNumber uint64 
	_vectorIndex int
	_N int
	_tuples []int
	_prev,_next *UpdateInfo
}
```

头节点初始化过程：
- 将事务update的新值填入`_tuples`
- 更新`_N`
- 更新`_versionNumber` = 特殊值。

为事务创建版本节点：
- 将旧值记录到节点中。
- `_versionNumber` = 事务id

InitUpdateData完成这一过程。
```go
func InitUpdateData(
	baseInfo *UpdateInfo,  //事务版本节点
	baseData *chunk.Vector,  //旧值
	updateInfo *UpdateInfo,  //头节点
	update *chunk.Vector,//新值
){
	update -> updateInfo._tuples //新值 -> 头节点
	baseData -> baseInfo //旧值 -> 事务版本节点
}
```

#### 有版本链表
考虑几个问题：
- 是否有其它事务与此事务冲突。修改同一行同一个列。
- 链表上有没有此事务版本节点。没有得先创建版本节点。
- 更新头节点和事务版本节点。放置新值和旧值。

不同的事务对同个vector进行update时，会出现更新同一个值的情况。需要机制来检测事务WW冲突。
检测原理：遍历版本链表，每个版本号 大于 当前事务的节点（已经提交或未提交）。当前事务修改的行号如果在此节点上，说明已经有事务update此行了，出现了WW冲突。
冲突处理：当前事务abort。
```go
func CheckForConflicts(
	info *UpdateInfo,
	txn *Txn,
	rowIds []RowType){
	if info.versionNumber  == txn.id {
		//同个事务不检查
	}else if info.versionNumber > txn.id {
		for rid := rowIds {
			if rid in info.tuples {
				"ww conflicts"
			}
		}
	}
	return CheckForConflicts(info.Next,txn,rowIds);
}
```


确定事务版本节点。遍历版本链表，节点版本号 等于 此事务的节点，即为此事务版本节点。如果没有找到，需要为事务创建版本节点，并插入到头节点之后。

更新版本信息。
- 复杂性在于确定旧值的位置。既要在头节点中填新值，又要在事务版本节点中填旧值。
- 旧值有两部分：当前事务本次要update的值。当前事务之前update的值。本次与之前update的值可能不重叠。
- 准备新值。

旧值的位置：
- 在表中。第一次修改此值。
- 在事务版本节点中。当前事务已经改过此值。

确定旧值位置的方法：
- 对每个要update的rowid。先在事务版本节点中查找，如果存在的话，说明旧值在事务版本节点中。事务已经update过此值。如果不存在，再去头节点中查找。
- 如果存在于头节点，说明旧值在头节点中。别的事务已经update此值，并且已经提交。
- 如果不存在于头节点，说明旧值在表中 并且 是第一次修改此值。

收集旧值并重填入事务版本节点中，构成修改后的旧值。
- 本次update的旧值，在确定了位置后读取。
- 本次update未涉及，但是之前update过的旧值，已经在事务版本节点中。

准备新值：将新值填入头节点中。只将本次update涉及的新值填入头节点。实质是二路归并的过程。

## 小结
数据多版本是理解的难点。多版本的生成方式理解update逻辑的关键点。


# 第十章 delete数据

## 简介
从表中删除数据行。

delete的特点：
- 区分数据在事务local storage 还是 在表对象中。最终都会走到RowGroup集合Delete接口。
- 处理到RowGroup层。不需到ColumnSegment层。因为行版本信息记录在RowGroup上。
- 行版本信息也按vector分组。

## delete过程

外层接口到内层接口：

| 接口                        | 参数     | 含义                   |
| ------------------------- | ------ | -------------------- |
| DataTable.Delete          | rowids | 表delete接口            |
| LocalStorage.Delete       | rowids | 事务局部存储delete接口       |
| RowGroupCollection.Delete | rowids | RowGroup集合delete接口   |
| RowGroup.Delete           | rowidx | RowGroup delete接口    |
| VersionDeleteState.Delete | rowid  | 删除某一个行               |
| VersionDeleteState.Flush  | rowids | 同一个vector的行批量更新行版本信息 |
| ChunkInfo.Delete          | rowids | 设置行版本号               |
- RowGroupCollection.Delete。先确定rowid所在的RowGroup。同一个RowGroup的row一起删除。
- RowGroup.Delete。循环删除每个行。同一个vector的行，先收集。再一次性更新版本信息。
- VersionDeleteState.Delete。收集同一个vector的行，有可能要创建对应的版本信息。
- VersionDeleteState.Flush。检测冲突：同一行是否已经被其它事务删掉。更新同一个vector的版本信息。

## 小结
delete相对插入、update容易理解。没有复杂的状态也没有版本链。

# 第十一章 读数据与MVCC

## 简介
从表中读数据。在事务框架下，又支持MVCC，读数据过程复杂。
复杂性来自多个方面：
- 涉及内存结构，从RowGroup集合到ColumnSegment。需要多个状态支撑读数据过程。
- 数据可能在事务的local storage中，也可能在表中。
- 数据可见与否。事务只能基于版本信息读取其可见的数据。用行版本和列版本过滤的处理方式不同。

## 状态

多层的内存结构，决定多层的状态。每层状态维护其内的读取位置。

层次状态：
- TableScanState。表级别
- CollectionScanState。 RowGroup集合
- ColumnScanState。 列级别
- SegmentScanState。ColumnSegment级别

```go
TableScanState{
	CollectionScanState{
		ColumnScanState{
			SegmentScanState{
				
			}
		}
	}
}
```

| 状态                  | 字段              | 含义                 | 备注  |
| ------------------- | --------------- | ------------------ | --- |
| TableScanState      | _tableState     | 读表对象的状态            |     |
| TableScanState      | _localState     | 读local storage的状态  |     |
| TableScanState      | _columnIds      | 读取的列               |     |
| CollectionScanState | _rowGroup       | 当前RowGroup         |     |
| CollectionScanState | _vectorIdx      | 当前vector下标         |     |
| CollectionScanState | _maxRowGroupRow | RowGroup最多能读的行数    |     |
| CollectionScanState | _columnScans    | 列的读状态              |     |
| CollectionScanState | _maxRow         | RowGroup集合中能读的最大行号 |     |
| ColumnScanState     | _current        | 要读的列segment        |     |
| ColumnScanState     | _rowIdx         | 列的第一个行号            |     |
| ColumnScanState     | _scanState      | block              |     |

## 读数据过程
分为几步：
- 初始化阶段。给状态赋初值。
- 读数据。

### 初始化
1，初始化TableScanState
- 记录要读的列。
- 初始化表对象的读状态
- 初始化事务局部存储的读状态

2，初始化CollectionScanState
表对象的读状态 和 事务局部存储的读状态 都需要RowGroup集合的读状态。
- `_maxRow` RowGroup集合中能读的最大行号 = 开始行号 + 总行数。
- 寻找第一个有数据的RowGroup。
	- `_vectorIdx`  = 0
	- `_maxRowGroupRow`  RowGroup能读的行数

3，初始化ColumnScanState
初始化每个列的读状态。
- `_current` 列数据的第一个ColumnSegment
- `_rowIdx` 列的第一个行号
- `_internalIdx`  = `_rowIdx`

### 读过程
通过多层接口，从外层直到最内层，读到数据。每层又依据状态进行分流。读取成功又更新状态。

| 接口                                   | 状态                  |
| ------------------------------------ | ------------------- |
| DataTable.Scan                       | TableScanState      |
| LocalStorage.Scan                    | CollectionScanState |
| CollectionScanState.Scan             | CollectionScanState |
| RowGroup.Scan,RowGroup.TemplatedScan | CollectionScanState |
RowGroup.TemplatedScan完成实质的读过程。先概要的理解此函数，再细说每个组件。
整体逻辑：
- 确定要读的vector
- 行版本信息过滤。vector中，事务读其可见的数据。（MVCC）
- 如果vector中，事务一行都读不到。要跳过这个vector。
- 对需要读的vector，要么全读，要么部分读。对每个列都读一次。
	- 全读，接口ColumnData.Scan（或ColumnData.ScanCommitted）。
	- 部分读，接口ColumnData.FilterScan（或ColumnData.FilterScanCommitted）。

```go
func (RowGroup)TemplatedScan(
		txn,state,result,scanTyp,
	){
	//读一个vector
	for{
		确定vector的开始行号和可读行数；
		行版本过滤；事务读可见的行；
		if vector全过滤了 {
			跳过此vector;
			continue
		}
		if vector全读 {
			for 列i {
				ColumnData.Scan
				（或ColumnData.ScanCommitted）
			}
		}else{//部分读
			for 列i {
				ColumnData.FilterScan
				（或ColumnData.FilterScanCommitted）
			}
		}
	}
}
```

#### 行版本过滤
RowGroup上有行版本信息。分60组，每组2K行。对应vector个数，和vector中的行数。

行版本信息有两类：
- insert操作。此行被事务插入。
- delete操作。此行被事务删除。

行被事务可见的含义：
- insert操作。被事务看见，结果是看到这行数据。
- delete操作。被事务看见，结果是看**不**到这行数据。与insert操作的结果相反。

行版本过滤原理：
- 输入1：行版本信息：insert操作的事务id。delete操作的事务id。
- 输入2：读取此行的事务id和事务startTime。
- 判断逻辑：依据事务可见性含义。
	- insert操作。insertId < startTime || insertId == txnId。insert操作的事务已经提交或是读事务插入的。读事务能看到这行数据。
	- delete操作。!(deleteId < startTime || deleteId == txnId)。delete操作的事务已经提交或是读事务删除的。数据已经删除了。读事务看不到这行数据。

```go

//看到insert操作。看到insert后的数据行
func (op TxnVersionOp) UseInsertedVersion(  
    startTime, txnId, id TxnType) bool {  
    return id < startTime || id == txnId  
}  

//看到delete操作。数据已经删除了。事务看不到这行数据。
func (op TxnVersionOp) UseDeletedVersion(  
    startTime, txnId, id TxnType) bool {  
    return !op.UseInsertedVersion(startTime, txnId, id)  
}

```

#### 跳过vector
vector的所有数据行都不需要读。跳过需要读的所有列的`_vectorIdx`对应的vector。
跳过逻辑的层次接口：

| 接口                           | 状态                  |
| ---------------------------- | ------------------- |
| RowGroup.NextVector          | CollectionScanState |
| ColumnData.Skip              | ColumnScanState     |
| ColumnScanState.Next         | ColumnScanState     |
| ColumnScanState.NextInternal | ColumnScanState     |

跳过逻辑：
- `_vectorIdx`++。指向下一个vector。
- 每个列跳过2K行。
	- `_rowIdx` 下一个vector的第一行的行号。
	- 如果当前ColumnSegment读完了，即`_rowIdx`超过当前ColumnSegmet的范围，需要切换到下一个ColumnSegment。
	- 

```go
func (RowGroup)NextVector(state *CollectionScanState){
	state._vectorIdx++
	for colid {
		ColumnData.Skip(scanState,count){
			ColumnScanState.Next(count){
				ColumnScanState.NextInternal(count){
					state._rowIdx += count;
					if state._rowIdx 超过当前ColumnSegment的范围 {
						切换到下一个ColumnSegment;
					}
				}
			}
		}
	}
}

```

#### 读vector
读取vector内的全部行或部分行。
读取步骤：
- 从ColumnSegment的block内存中读取数据。这些数据不一定是最新的。
- 列版本过滤。列版本链表头节点是新值，但是事务可见的版本，不一定这些新值。有可能是旧值。这需要结合列版本信息来过滤。
- 筛选需要的行。（部分行的情况）

读vector的接口，从外层到内层：

| 接口                                            | 状态              |
| --------------------------------------------- | --------------- |
| ColumnData.Scan                               | ColumnScanState |
| ColumnData.ScanVector,ColumnData.ScanVector2  | ColumnScanState |
| ColumnSegment.Scan                            | ColumnScanState |
| ColumnSegment.Scan2,ColumnSegment.ScanPartial | ColumnScanState |
| UpdateSegment.FetchUpdates                    |                 |
| UpdateMergeFetch                              |                 |
| UpdatesForTransaction                         |                 |
- ColumnData.ScanVector2。从block内存读取vector数据。
	- ColumnSegment.ScanScan2（ScanPartial）。读完整vector，或vector的部分
	- 如果当前ColumnSegment的数据不够，切换到下一个ColumnSegment。
- UpdateSegment.FetchUpdates。列版本过滤。

回顾下列版本相关的内容：
- 每个vector有对应的版本链表。头节点记录vector的update后的新值。非头节点--事务版本节点，记录事务修改前的旧值。
- 列版本信息。此行此列被事务update过。
- 列版本事务可见。update操作被当前事务可见。当前事务只能读旧值。

列版本过滤逻辑：
- 输入1：从block内存读取的vector数据。
- 输入2：列版本链。
- 遍历版本链表：如果列版本事务可见，要取旧值。
	- 列版本事务可见的判断条件：列版本_versionNumber > startTime && 列版本_versionNumber != txnId。
	- 头节点一定满足此条件。一定能从头节点中取新值。
	- 当前事务版本节点一定不满足此条件。

```go

func UpdateMergeFetch(
	startTime,
	txnId,
	info,
	result,
	){
	UpdatesForTransaction(){
		for info != nil{
			if info._versionNumber > startTime && info._versionNumber != txnId {
				MergeUpdateInfo(){
					info.旧值 => result
				}
			}
			info = info.next
		}
	}
}

```

如果是读vector中的部分行，需要再筛选。筛选的依据是行版本过滤得出的选择器（SelectVector)。

#### 读已经提交过程
4种读模式：
- 常规。读当前事务可见的数据。就是上面说的读过程。
- 读已经提交。读所有行，包括删除的行。并且合并已经提交的updates。
- 读已经提交但不要updates。读所有行，包括删除的行。不要未提交的updates。
- 读已经提交但不要永久删除的行。

读已经提交，与上面讲的常规读过程区别：
- 常规读过程中，当前事务可能修改了部分数据，且一定没提交。
- 读已经提交。这个过程是由特殊事务去做的，当前事务是特殊构建的，具有最小活跃事务id 和 最小活跃事务startTime，且只读。

在场景上，常规读就是一般从表中读数据。提交事务时，事务有插入数据时，用读已经提交，读取数据并写入walog。另一处，在事务回滚时，用读已经提交，读取数据并从索引中删除。

与常规读过程相比，接口有些重合。入口不同。
从外层到内层的接口：

| 接口                                           | 状态                  |
| -------------------------------------------- | ------------------- |
| DataTable.ScanTableSegment                   | TableScanState      |
| CollectionScanState.ScanCommitted            | CollectionScanState |
| RowGroup.ScanCommitted                       | CollectionScanState |
| RowGroup.TemplatedScan                       | CollectionScanState |
| ColumnData.ScanCommitted/FilterScanCommitted | ColumnScanState     |
| UpdateSegment.FetchCommitted                 |                     |
- DataTable.ScanTableSegment，从表对象中读取行号区间[rowStart, rowStart + count]中的数据。内部先确定RowGroup，再用读已提交模式读数据。
- CollectionScanState.ScanCommitted。读完一个RowGroup，切换到下一个。
- RowGroup.ScanCommitted。构建新事务：具有最小活跃事务id 和 最小活跃事务startTime。用此事务再去读数据。
- RowGroup.TemplatedScan。读列数据接口用ScanCommitted和FilterScanCommitted。
- ColumnData.ScanCommitted/FilterScanCommitted。先从ColumnSegment的block内存读数据。再合并版本链表头节点的最新已经提交的数据。
- UpdateSegment.FetchCommitted。头节点就是最新已经提交的数据。需要注意的是：在提交事务时，事务有插入数据时，用读已经提交，读取数据并写入walog。在这个场景下，新数据对应的头节点中最新值一定是当前事务插入的。

```go

func (DataTable) ScanTableSegment(
	rowStart,
	count,
){
	end := rowStart + count
	state :=TableScanState{}
	table.InitScanWithOffset(state, colIds, rowStart, rowStart+count)
	for currentRow < end {
		state._tableState.ScanCommitted(data, TableScanTypeCommittedRows){
			for rowGroup {
				_rowGroup.ScanCommitted(state, result){
					//具有最小活跃事务id 和 最小活跃事务startTime
					id, start := GTxnMgr.Lowest()  
					txn, err := GTxnMgr.NewTxn2("lowest", id, start)
					RowGroup.TemplatedScan(txn,state,result)
				}
			}
		}
		...
	}
}

func (RowGroup)TemplatedScan(
		txn,state,result,scanTyp,
	){
	//读一个vector
	for{
		确定vector的开始行号和可读行数；
		行版本过滤；事务读可见的行；
		if vector全过滤了 {
			跳过此vector;
			continue
		}
		if vector全读 {
			for 列i {
				ColumnData.ScanCommitted
			}
		}else{//部分读
			for 列i {
				ColumnData.FilterScanCommitted
			}
		}
	}
}
```

#### checkpoint读

checkpoint时，对每个RowGroup中，每个列数据中，依次读取ColumnSegment的每个vector。并写入新的ColumnSegment。
读取checkpoint也分为两步：
- 从block内存读取数据
- 从版本链头节点读取最新数据。

从外层到内层接口：

| 接口                                  | 状态              |
| ----------------------------------- | --------------- |
| ColumnDataCheckpointer.WriteToDisk  |                 |
| ColumnDataCheckpointer.ScanSegments |                 |
| ColumnData.CheckpointScan           | ColumnScanState |
| ColumnSegment.Scan                  | ColumnScanState |
| ColumnSegment.Scan2/ScanPartial     | ColumnScanState |
| UpdateSegment.FetchCommittedRange   |                 |
- ColumnDataCheckpointer.WriteToDisk。checkpoint实质写数据的接口。
- ColumnDataCheckpointer.ScanSegments。读所有ColumnSegment，读出数据并存入新ColumnSegment。
- ColumnData.CheckpointScan。先读vector数据，再读版本链表头节点的最新数据。
- ColumnSegment.Scan2/ScanPartial。读vector数据。
- UpdateSegment.FetchCommittedRange。读版本链表头节点的最新数据。

版本链表头节点的最新数据一定是已经提交的数据。原因是：
- 能checkpoint的条件
	- 已经提交的事务都被GC了。
	- 活跃事务只有当前事务（当前事务正在提交，并触发checkpoint）。
## 小结
行版本和列版本过滤支持事务MVCC特性。准确理解版本可见性的含义和判断条件是理解事务读逻辑的基础，也是难点。

# 第十二章 catalog

## 简介
catalog记录数据库中schema和表的元信息。catalog中数据的组织方式与表不同。
具有以下特点：
- 用entry表示元信息的某个版本。分为几类：schema，table等。
- 简要理解，用entry的集合表示所有元信息。
- 事务对元信息修改产生新版本。可以回滚到旧版本。创建entry时，会记录undo log。提交事务时，会写walog。
- 元信息分层：
	- catalog层：schema的entry集合
	- schema层：table的entry集合
	- table层：表相关的entry集合。
- 维护元信息之间的依赖关系。例如：table与schema关联。

## entry
entry有两层含义：
- 具体类型的元数据。schema，table等。由`CatalogEntry`表示。
- 在放入entry集合时，在`CatalogEntry`之上又再套一层。由`EntryValue`，`EntryIndex`表示。

`CatalogEntry`的关键信息：
- `_typ`。类型。schema，table等。
- `_name`。schema名称，或 table名称。
- `_timestamp`。创建时，事务的id。提交事务时，commitid。
- `_child`， `_parent`。entry被修改后产生新版本。`_child`指向旧版本，`_parent`指向新版本，组成版本链。
- 附加信息。
	- 对schema，有表的entry集合。
	- 对table，有表对象，表的属性。

`EntryValue`的关键信息：
- `_entry *CatalogEntry`。元信息。

`EntryIndex`的关键信息：
- `_index`。对entry的序号或下标。

## entry集合
`CatalogSet`表示entry集合。依据要表达的元信息类型，entry集合里面就放什么。
- catalog：schema的entry集合
- schema：table的entry集合
- table：表相关的entry集合

`CatalogSet`的关键信息：
- `_entries`：entryIdx -> `*EntryValue`。从entry idx到entry链表。`CatalogEntry`可以指向旧版本。
- `_mapping`：name -> `*MappingValue`链表。从名称到entry idx链表。`MappingValue`可以指向旧版本。

`MappingValue`的关键信息：
- `_index`：entry idx
- `_timestamp`：创建时的事务id
- `_child`，`_parent`：`_child`指向旧版本。版本链表。

`CatalogSet`需要的entry接口：
- 创建entry
- 读取entry
- entry依赖关系维护

## 创建entry
创建schema和表时，要创建entry。
分两步：
- 创建元信息的CatalogEntry。这一步相对简单，不再细说。
- 创建EntryValue

创建EntryValue的过程相对复杂
- 用名称取entry idx。如果没有，分配新的entry idx。记录映射关系：名称->entry idx。同个名称会对应多个版本的entry idx。用链表维护。
	- 需要版本可见性。
- 维护依赖关系。entry 与其它entry之间的关联。
- 记录映射关系：entry idx -> entry value。同个entryIdx 也可能对应多个entry value，用链表维护。
- 记录undo log。讲旧entry记录到undo log。旧entry的parent是新entry。

接口层次：

| 接口                     | 含义                                           |
| ---------------------- | -------------------------------------------- |
| CatalogSet.CreateEntry | 创建entry入口                                    |
| CatalogSet.GetMapping  | 用名称取entry idx                                |
| CatalogSet.PutEntry    | 记录映射关系（覆盖已有的）：entry idx -> entry value       |
| CatalogSet.PutMapping  | 记录映射关系：名称->entry idx。插入链表头部。                 |
| DependMgr.AddObject    | 维护依赖关系                                       |
| CatalogSet.PutEntry2   | 记录映射关系：entry idx -> entry value。新entry插入链表头部 |
| Txn.PushCatalogEntry   | 记录undo log                                   |
- CatalogSet.GetMapping。在取entry idx时，需要版本过滤。当前事务只能看到自己修改的或已经提交事务的 entry idx。

```go

func(CatalogSet) CreateEntry(
	txn,name,value,list,
){
	mapping :=GetMapping(txn,name){
		ent := _mapping[name];
		for ent._child != nil{
			if ent 对 txn可见 {
				返回ent;
			}
		}
	}

	if mapping 无效{
		PutEntry(new entry idx,dummy catalog entry);
		PutMapping(txn,name,new entry idx);//记录新映射关系。名称->entry idx。
	}else{
		用mapping._entryidx从_entries取最新的CatalogEntry;
		if txn 与 catalogEntry冲突{
			w-w conflicts;
		}
	}
	DependMgr.AddObject(txn,value,list)
	CatalogSet.PutEntry2(entryidx,value);//记录映射关系：entry idx -> entry value。
	Txn.PushCatalogEntry(...)
}

```

### 取CatalogEntry
从`CatalogSet`取entry 分为两类：
- 取当前事务可见的有效CatalogEntry。
	- 从名称取entryIdx。用GetMapping
	- 由entryIdx取得Entry链表。遍历链表取事务可见的entry。
- 取已经提交的有效CatalogEntry。
	- 遍历entry idx -> entry value。对每个entry 链表。遍历链表取事务可见的entry。

### 维护依赖关系
例如：schema由多个表组成，每个表只属于唯一一个schema。删除schema必须先删除所有的表。
用图来表达entry之间的依赖关系。
`DependMgr`实现依赖关系图：
- 内部记录两层关系：每个entry是要知道，我依赖了谁 和 谁依赖了我。
- 接口1: `AddObject(ent,dependList)`添加依赖关系。
- 接口2: `EraseObject(ent)` 删除ent以及与之相关的依赖关系。

### commit操作
在创建entry时，会记录undo log，并且记录的是旧entry（旧entry的parent是新entry）。
在事务提交时，catalog操作也要写walog。
- 设置新entry的提交时间戳
- 必要时，设置旧entry的提交时间戳
- 将新entry序列化写入walog。

### undo操作
创建了entry后，回归事务，需要撤销对catalog的修改。
创建entry简要逻辑：
- 记录映射关系：名称到entryidx。链表方式。
- 记录映射关系：entryidx到entry的映射。链表方式。
- 维护依赖关系

那么撤销操作，逆向操作恢复原样：
- 删除依赖关系
- 删除映射关系：entryidx到entry的映射。实质是将新entry从链表删除掉。
- 删除映射关系：名称到entryidx。实质是entryidx从链表中删掉。

## 小结
catalog维护entry集合，方式与表不同。创建entry和undo操作相对复杂。理解两层映射关系有助于理解这一点。

# 第十三章 索引

## 简介
索引工作期间数据都在内存中。在checkpoint时，会持久化到外部存储上。与基于磁盘的索引结构不同。
目前索引用于维护表的约束：not null，唯一索引和主键。索引查询还未做。

在表的单个列或多个列上建索引，来满足某种约束。可以建多个索引。实质上是索引列的数据组织成索引键记录在索引结构中。
索引涉及到多方面：
- 索引键和值。索引列数据的序列化方法。
- 索引存储结构。用B+树，ART
- 数据插入索引
- 从索引删除数据
- 索引序列化和反序列化。

索引应用的具体场景：
- 事务临时存储需要索引维护表的约束。在事务未提交时，数据是插入在临时存储中的。
- 表对象。事务提交时，事务临时存储的数据最终需要插入表对象。表对象需要用索引维护约束。
- 删除数据。也要从索引删除数据。
## 索引结构

索引键：索引列的数据序列化成字节串。
索引值：rowid

索引存储结构：用开源内存版本B+树。

索引结构关键信息：
- 约束类型。唯一，主键等
- 索引列信息。类型。
- B+树
- 列数据的序列化/反序列化方法。

```go
type IndexKey struct {  
    _data unsafe.Pointer  //索引键
    _len  uint32  
    _val  uint64  //索引值。rowid
}

type Index struct {  
    _columnIds             []IdxType  //索引列
    _types                 []common.PhyType  //索引数据类型
    _logicalTypes          []common.LType  //索引数据类型
    _constraintType        uint8  //约束类型
    _btree   *btree.BTreeG[*IndexKey]  //B+树
}

```

## 插入数据
- 事务未提交时，数据进入临时存储。数据插入索引。用索引维持约束。
- 事务提交时，数据从临时存储进入表对象，依然要插入表对象的索引。用索引维持约束。

数据按chunk进入索引。

分几步：
- 构建索引键。索引列数据的序列化。
- 插入B+
- 插入失败后，已经插入的数据需要删除掉。

序列化方法：按chunk批量序列化。第一个索引列所有行序列化，然后第二个索引列所有行序列化，并与第一列序列化结果拼接起来。如此，知道全部索引列都拼接好。

## 删除数据
- 构建索引键。与插入时，索引列数据的序列化完成相同。
- 从B+树删除索引键。

## 查询数据 

索引查询暂时未支持。

## 序列化和反序列化
在checkpoint时，对索引序列化。存储引擎加载时，索引反序列化。
与上面的索引列数据序列化成索引键不同。

遍历每个索引，索引中的每个值序列化到磁盘上。反序列化，从block中反序列化出所有数据重新构建索引结构。

## 小结
聚焦在索引结构的整体应用。未细讲B+树是如何设计的。索引查询还未实现也没讲。

# 第十四章 stats

## 简介
介绍表的统计信息的构成、更新和使用。
统计信息构成：
- 表级别，列级别
- 列级别：zonemap(最大值，最小值)。不同值个数。

在插入新数据时，要更新列级别的统计信息。
在查询优化、checkpoint等都会用到统计信息。

## 统计信息结构
前面介绍过内存层次结构。
- 表对象
- RowGroup集合
- RowGroup
- 列数据ColumnData
- ColumnSegment

统计信息的分层与内存层次结构相关，但不完全相同。

| 内存结构          | 统计信息          | 说明            |
| ------------- | ------------- | ------------- |
| 表对象           | 无             | 无             |
| RowGroup集合    | TableStats    | 表的统计信息。       |
| RowGroup      | 无             | 无             |
| 列数据ColumnData | SegmentStats  | 每个列上的统计信息     |
| ColumnSegment | SegmentStats  | 每个block上的统计信息 |
|               | BaseStats     | zonemap信息     |
|               | DistinctStats | 不同值统计信息       |
数据结构层次关系：
```go
type TableStats struct {  
    _columnStats []*ColumnStats  
}

type ColumnStats struct {  
    _stats         BaseStats  
    _distinctStats *DistinctStats  
}

type SegmentStats struct {  
    _stats BaseStats  
}

```


zonemap信息收集、不同值统计（hyperloglog）这里都不再细说。

## 更新
更新统计信息的过程是从下到上的。
- ColumnSegment。在向block内存块，追加数据时，同时更新列的统计信息（SegmentStats：zonemap信息）。
- 列数据ColumnData。更新完成ColumnSegment上的统计信息会merge到ColumnData中的统计信息。
- RowGroup集合。
	- RowGroup插入数据后，所有列的统计信息合并到RowGroup集合的表统计信息上。
	- 更新每个列的不同值个数。

## 使用

### 查询

1, filter下推，zonemap过滤。
目前filter下推到scan节点。但是不支持zonemap过滤，不能跳过不需要读的block。完整支持需要完善filter的能力。

2，join定序。
用到表的总行数 和 列的不同值个数。

### checkpoint
完整的checkpoint过程请看事务章节。简要的说，checkpoint过程是每个RowGroup以及其中每个ColumnData逐个持久化。
checkpoint过程中统计信息的收集、存储。从checkpoint的下层向上层：
- 列数据ColumnData
	- 每个ColumnSegment的统计信息都会聚合到每个列。每个列会有一个整体统计信息。
	- RowGroup在持久化每列元信息后，会持久化每个ColumnSegment的统计信息。
	- 每个列的整体统计信息的去处 会聚合到外层表的统计信息。因为表有多个RowGroup。
- 外层表级统计信息在表元信息序列化时序列化。排在RowGroup信息序列化之前。

从统计信息序列化过程看，有这些特点：
- block的级的统计信息会序列化
- RowGroup级别没有序列化统计信息
- 列统计信息最终在表级统计信息序列化中体现

## 小结
统计信息的收集和序列化比较容易理解，操作过程比较繁琐。统计信息的使用目前讲得概要。join定序相关的在优化器部分会讲。zonemap过滤等支持后再讲了。
